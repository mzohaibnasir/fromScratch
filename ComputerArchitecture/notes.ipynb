{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lecture :1\n",
    "## Computer Architecture\n",
    "Computer Architecture is Science and art of designing computing platforms(hardware, interface, system software and programming model)\n",
    "levels of transformations of command( from high level to low lvl instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### levels of transformations of command( from high level to low lvl instructions)\n",
    "Problem -> algorithm's written in programing language -> \n",
    "\n",
    "executed on system software -> compiled down to low level instructions)-> \n",
    "\n",
    "digital logics -> transistors -> transistors are based on principles of electrons\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ISA (Instruction Set Architectire): An abastract model that generally defines how software controls CPU\n",
    "`Micro architecture` is implementation of ISA\n",
    "\n",
    "Microarchitecture it refers to the implementation of the ISA (Instruction Set Architecture) at the hardware level. Instructions are executed by the microarchitecture. it's the design of the processor that executes the compiled instructions.\n",
    "\n",
    "\n",
    "\n",
    "System software -- VM, OS, Memory manager : It manages the execution of programs, interacts with hardware, and provides an environment for running application software.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](lvls_of_transformation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Problem**: A problem is defined, and an algorithm is designed to solve it.\n",
    "- **Algorithm**: The algorithm is written in a programming language.\n",
    "- **Programming Language**: The code is compiled by a compiler into machine code or low-level instructions.\n",
    "- **Instruction Set Architecture (ISA)**: The compiled code corresponds to the ISA, which defines how instructions control the CPU.\n",
    "- **Microarchitecture**: The microarchitecture implements the ISA and determines how the CPU processes the instructions.\n",
    "- **Digital Logic**: The microarchitecture is built using digital logic circuits.\n",
    "- **Transistors**: Digital logic is realized using transistors.\n",
    "- **Physics of Transistors**: Transistors operate based on principles of electron flow.\n",
    "\n",
    "**System Software**:\n",
    "- **System Software**: Includes components like the OS, virtual machine (VM), and memory manager, which manage hardware resources and provide an interface for running application software.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Axiom\n",
    "To achieve the highest energy efficiency and performance, it's essential to adopt a holistic approach to computer architecture. This involves considering not just the core processing elements but also the entire system's design, including memory hierarchies, interconnects, power management strategies, and workload optimization.\n",
    "\n",
    "1. **Heterogeneous Computing**: Leveraging specialized processors, like GPUs, FPGAs, and AI accelerators, tailored to specific tasks can greatly enhance efficiency and performance.\n",
    "\n",
    "2. **Memory Hierarchy Optimization**: Efficient memory access patterns, caching strategies, and the use of non-volatile memory technologies can reduce power consumption and latency.\n",
    "\n",
    "3. **Power Management**: Dynamic voltage and frequency scaling (DVFS), power gating, and other techniques help in adjusting power usage based on workload demands, optimizing energy efficiency.\n",
    "\n",
    "4. **Workload-Specific Architectures**: Designing architectures that are optimized for specific workloads, like AI or data analytics, can result in better performance and energy efficiency.\n",
    "\n",
    "5. **Data Movement**: Reducing the movement of data between processing units and memory (often referred to as \"data locality\") minimizes energy usage and enhances performance.\n",
    "\n",
    "6. **Parallelism**: Exploiting parallelism at various levels, including instruction-level, data-level, and task-level, can significantly improve performance while maintaining or even reducing energy consumption.\n",
    "\n",
    "7. **Software-Hardware Co-Design**: Collaborative design of hardware and software ensures that both layers are optimized together, leading to more efficient and performant systems.\n",
    "\n",
    "By considering these aspects and adopting a broad perspective on computer architecture, it's possible to strike an optimal balance between energy efficiency and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The Apple M1 Ultra system is an advanced System on a Chip (SoC) that integrates multiple components into a single chip, designed to deliver high performance and energy efficiency. Here's a breakdown of its architecture:\n",
    "\n",
    "- **System on a Chip (SoC)**: The M1 Ultra combines various components, including CPU cores, GPU cores, Neural Engine, and more, into a single chip, allowing for efficient data transfer and reduced latency.\n",
    "\n",
    "- **Compute Cache**: The M1 Ultra features substantial on-chip caches that play a critical role in speeding up computation. These caches store frequently accessed data close to the CPU and GPU cores, reducing the need to access slower off-chip memory. This helps in achieving high computation speeds, as data can be processed more quickly when it's available in these caches.\n",
    "\n",
    "- **Unified Memory Architecture (UMA)**: Instead of separate memory pools for different components (CPU, GPU, etc.), the M1 Ultra uses a unified memory system. All parts of the chip share the same memory, which reduces the need for data duplication and allows for faster data access and more efficient use of memory.\n",
    "\n",
    "- **Data Storage in Memory Devices**: In the M1 Ultra, the main data storage occurs in external memory devices, such as DRAM. The unified memory is used for storing the working data required by the CPU, GPU, and other processors within the SoC. This approach ensures that large datasets can be accessed efficiently by different parts of the SoC without unnecessary copying or delays.\n",
    "\n",
    "**Summary**:\n",
    "- **Computation**: Primarily happens within the SoC, leveraging the large compute caches for high-speed processing.\n",
    "- **Data Storage**: Occurs in the unified memory, allowing for efficient data access and management across the entire system.\n",
    "\n",
    "This architecture enables the M1 Ultra to deliver exceptional performance while maintaining energy efficiency, suitable for demanding tasks such as video editing, 3D rendering, and machine learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# DATA MOVEMENT VS COMPUTATION ENERGY:\n",
    "COMPUTATION IS VERY CHEAP BUT ACCESSING THE DATA EVEN FROM MAIN MEMORY(RAM) IS EXPENSIVE. FOR A SIJMPLE INTEGER ADDITION, A SINGLE MAIN MEMORY (RAM) ACCESS CONSUMES `6400x` MORE ENERGY THAN THAT COMPUTATION,, Imagine getting data from secondary storage.\n",
    "\n",
    "## How can we reduce the amount/length of data movementa?\n",
    "that's why people combine storage on same chip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data-Centric** and **Compute-Centric** architectures represent two different approaches to designing computing systems, each with its own focus and trade-offs.\n",
    "\n",
    "### **Compute-Centric Architectures**\n",
    "\n",
    "**Focus**: \n",
    "- The primary focus is on maximizing the processing power of the system.\n",
    "- Most traditional computing systems fall under this category, where the central processing unit (CPU) or GPU is the heart of the system, and everything else, including memory and I/O, is designed to support the CPU's needs.\n",
    "\n",
    "**Key Characteristics**:\n",
    "1. **Centralized Computation**: The majority of the computation is performed by powerful CPUs or GPUs. Data is fetched from memory, processed, and then stored back.\n",
    "2. **Memory and Storage**: These are designed to serve the CPU, often as bottlenecks since data must be moved to the CPU for processing.\n",
    "3. **Latency and Bandwidth**: In compute-centric architectures, memory latency and bandwidth are critical as they directly impact the CPU's ability to perform tasks.\n",
    "4. **Examples**: Traditional PCs, servers, and many high-performance computing systems.\n",
    "\n",
    "**Challenges**:\n",
    "- **Data Movement Overhead**: A significant amount of time and energy is spent moving data between memory and the CPU, which can become a bottleneck.\n",
    "- **Inefficiency in Data-Intensive Tasks**: When dealing with large datasets, the overhead of moving data to and from the CPU can reduce overall efficiency.\n",
    "\n",
    "### **Data-Centric Architectures**\n",
    "\n",
    "**Focus**: \n",
    "- These architectures prioritize the efficient handling, movement, and processing of data, especially for data-intensive applications like big data analytics, AI, and machine learning.\n",
    "\n",
    "**Key Characteristics**:\n",
    "1. **Distributed Computation**: Rather than relying solely on a central processor, data-centric architectures often involve multiple processing units located closer to where data is stored (e.g., processing-in-memory or near-data processing).\n",
    "2. **Memory-Centric**: The design emphasizes reducing data movement by processing data where it resides, minimizing the need for large data transfers.\n",
    "3. **Scalability**: Data-centric systems are often designed to scale out horizontally, allowing for distributed computing across large datasets with minimal data movement.\n",
    "4. **Examples**: Systems like Google’s Tensor Processing Units (TPUs), specialized hardware accelerators, and edge computing devices.\n",
    "\n",
    "**Advantages**:\n",
    "- **Reduced Data Movement**: By processing data closer to where it’s stored, data-centric architectures reduce latency and energy consumption.\n",
    "- **Better Performance in Data-Intensive Workloads**: These architectures are particularly well-suited for tasks where large amounts of data need to be processed, such as in AI and machine learning.\n",
    "\n",
    "**Challenges**:\n",
    "- **Complexity in Design**: Designing systems that efficiently handle and process data near where it is stored can be more complex.\n",
    "- **Specialized Hardware**: Often requires specialized hardware or custom solutions, which can increase costs and development time.\n",
    "\n",
    "### **Comparison**\n",
    "\n",
    "| Aspect                | Compute-Centric                           | Data-Centric                            |\n",
    "|-----------------------|-------------------------------------------|-----------------------------------------|\n",
    "| **Focus**             | Maximizing compute power                  | Efficient data handling and processing  |\n",
    "| **Computation**       | Centralized in CPU/GPU                    | Distributed, often near data storage    |\n",
    "| **Data Movement**     | Significant overhead, can be a bottleneck | Minimized, processed where data resides |\n",
    "| **Memory Role**       | Supports CPU, often a bottleneck          | Integral part of processing             |\n",
    "| **Latency**           | Dependent on memory access times          | Reduced due to localized processing     |\n",
    "| **Suitability**       | Traditional computing tasks               | Big data, AI, machine learning          |\n",
    "| **Examples**          | PCs, servers, HPC systems                 | TPUs, edge computing, processing-in-memory |\n",
    "\n",
    "### **Conclusion**\n",
    "- **Compute-Centric Architectures** are well-suited for tasks that require intense processing power but can struggle with data-intensive workloads due to the overhead of data movement.\n",
    "- **Data-Centric Architectures** offer significant advantages for applications that need to handle large amounts of data efficiently, reducing the overhead of data movement and often providing better performance in these scenarios.\n",
    "\n",
    "As computing needs evolve, especially with the rise of big data and AI, data-centric architectures are becoming increasingly important, complementing or even replacing traditional compute-centric designs in certain applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory is row of cells where each cell stores one bit\n",
    "The statement \"Memory is a row of cells where each cell stores one bit\" is a simplified description of how memory is organized in a computing system. Here's a more detailed explanation:\n",
    "\n",
    "### **Memory Organization**\n",
    "\n",
    "- **Memory Cells**: \n",
    "  - A memory cell is the basic unit of storage in a memory device. Each cell is capable of storing one bit of information, which can be either 0 or 1. \n",
    "  - In modern memory devices, these cells are often arranged in a grid of rows and columns.\n",
    "\n",
    "- **Rows and Columns**: \n",
    "  - Memory is typically organized in a 2D array of cells, where each cell is located at the intersection of a row and a column. This grid structure allows for efficient access to data.\n",
    "  - Each row in the memory grid represents a collection of memory cells that can be accessed simultaneously. A row might represent a word, where multiple bits are read or written in parallel.\n",
    "\n",
    "- **Addressing**:\n",
    "  - Each memory cell is identified by a unique address, which is used to access or modify the data stored in that cell. The address is typically divided into two parts: the row address and the column address.\n",
    "  - This addressing scheme allows the system to locate and access specific bits or bytes within the memory.\n",
    "\n",
    "- **Memory Types**:\n",
    "  - **Volatile Memory (e.g., RAM)**: Memory that requires power to maintain the stored information. Once the power is turned off, the data is lost.\n",
    "  - **Non-Volatile Memory (e.g., ROM, Flash Memory)**: Memory that retains data even when the power is off.\n",
    "\n",
    "### **Summary**\n",
    "- **Row of Cells**: Refers to the organization of memory where multiple cells are arranged in rows and columns.\n",
    "- **One Bit per Cell**: Each cell in the memory stores a single bit, which is the smallest unit of data in computing.\n",
    "\n",
    "This basic structure underlies all types of memory, whether it's the RAM in your computer or the flash memory in a USB drive.\n",
    "\n",
    "## AND WE ACCESS ONE ROW AND READ SOME DATA BY APPLYING HIGH VOLTAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noManEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

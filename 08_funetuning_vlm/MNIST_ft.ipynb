{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# LoRA implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make torch deterministic\n",
    "_ = torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we will be training a nn to classify MNIST digigts and then finetune on a particular digit on which it doesn't perform well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    ")\n",
    "\n",
    "\n",
    "# load the datasete\n",
    "mnist_trainset = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "# create dataloader\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
    "\n",
    "\n",
    "# load the datasete\n",
    "mnist_testset = datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "# create dataloader\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an overly expensive nn for classification\n",
    "\n",
    "\n",
    "class RichBoyNet(nn.Module):\n",
    "    def __init__(self, hidden_size_1=1000, hidden_size_2=2000):\n",
    "        super(RichBoyNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(28 * 28, hidden_size_1)\n",
    "        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
    "        self.linear3 = nn.Linear(hidden_size_2, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = img.view(-1, 28 * 28)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = RichBoyNet().to(device)\n",
    "net.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 6000/6000 [03:58<00:00, 25.15it/s, loss=0.238]\n"
     ]
    }
   ],
   "source": [
    "def train(train_loader, net, epochs=5, total_iterations_limit=None):\n",
    "    cross_el = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    total_iterations = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "\n",
    "        loss_sum = 0\n",
    "        num_iterations = 0\n",
    "\n",
    "        data_iterator = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "        if total_iterations_limit is not None:\n",
    "            data_iterator.total = total_iterations_limit\n",
    "        for data in data_iterator:\n",
    "            num_iterations += 1\n",
    "            total_iterations += 1\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = net(x.view(-1, 28 * 28))\n",
    "            loss = cross_el(output, y)\n",
    "            loss_sum += loss.item()\n",
    "            avg_loss = loss_sum / num_iterations\n",
    "            data_iterator.set_postfix(loss=avg_loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (\n",
    "                total_iterations_limit is not None\n",
    "                and total_iterations >= total_iterations_limit\n",
    "            ):\n",
    "                return\n",
    "\n",
    "\n",
    "train(train_loader, net, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linear1.weight',\n",
       " 'linear1.bias',\n",
       " 'linear2.weight',\n",
       " 'linear2.bias',\n",
       " 'linear3.weight',\n",
       " 'linear3.bias']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.named_parameters()),\n",
    "[name for name, params in net.named_parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keep a copy of the original weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['linear1.weight', 'linear1.bias', 'linear2.weight', 'linear2.bias', 'linear3.weight', 'linear3.bias'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_weights = {}\n",
    "for name, param in net.named_parameters():\n",
    "    original_weights[name] = param.clone().detach()\n",
    "\n",
    "original_weights.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:02<00:00, 421.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.955\n",
      "wrong counts for the digit 0: 12\n",
      "wrong counts for the digit 1: 30\n",
      "wrong counts for the digit 2: 44\n",
      "wrong counts for the digit 3: 106\n",
      "wrong counts for the digit 4: 28\n",
      "wrong counts for the digit 5: 21\n",
      "wrong counts for the digit 6: 32\n",
      "wrong counts for the digit 7: 37\n",
      "wrong counts for the digit 8: 9\n",
      "wrong counts for the digit 9: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# The the performance of the pretrained network. As we can see, the network performs poorly on the digit 9. Let's fine-tune it on the digit 9\n",
    "\n",
    "\n",
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    wrong_counts = [0 for i in range(10)]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader, desc=\"Testing\"):\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            output = net(x.view(-1, 784))\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == y[idx]:\n",
    "                    correct += 1\n",
    "                else:\n",
    "                    wrong_counts[y[idx]] += 1\n",
    "                total += 1\n",
    "    print(f\"Accuracy: {round(correct/total, 3)}\")\n",
    "    for i in range(len(wrong_counts)):\n",
    "        print(f\"wrong counts for the digit {i}: {wrong_counts[i]}\")\n",
    "\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize  how many parameters are in the original network, before introducing LoRA matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: W: torch.Size([1000, 784]) + B: torch.Size([1000])\n",
      "Layer 2: W: torch.Size([2000, 1000]) + B: torch.Size([2000])\n",
      "Layer 3: W: torch.Size([10, 2000]) + B: torch.Size([10])\n",
      "Total number of parameters: 2,807,010\n"
     ]
    }
   ],
   "source": [
    "# Print the size of the weights matrices of the network\n",
    "# Save the count of the total number of parameters\n",
    "total_parameters_original = 0\n",
    "for index, layer in enumerate([net.linear1, net.linear2, net.linear3]):\n",
    "    total_parameters_original += layer.weight.nelement() + layer.bias.nelement()\n",
    "    print(f\"Layer {index+1}: W: {layer.weight.shape} + B: {layer.bias.shape}\")\n",
    "print(f\"Total number of parameters: {total_parameters_original:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the LoRA parameterization as described in the paper. \n",
    "\n",
    "The full detail on how PyTorch parameterizations work is here: https://pytorch.org/tutorials/intermediate/parametrizations.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We illustrate our reparametrization in Figure 1. We use a random Gaussian initialization for A and zero for B, so ∆W = BA is zero at the beginning of training. We then scale ∆Wx by α/r , where α is a constant in r. When optimizing with Adam, tuning α is roughly the same as tuning the learning rate if we scale the initialization appropriately. As a result, we simply set α to the first r we try and do not tune it. This scaling helps to reduce the need to retune hyperparameters when we vary r. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down this explanation in the context of **LoRA (Low-Rank Adaptation)** for training large models more efficiently. The goal here is to modify the weights of a pretrained model (\\( W \\)) in a way that’s efficient and doesn’t require retraining all parameters.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Terms in Context:\n",
    "1. **\\( \\Delta W = BA \\):**  \n",
    "   - \\( B \\) and \\( A \\) are low-rank matrices that approximate the updates to \\( W \\).  \n",
    "   - Instead of updating \\( W \\) directly, LoRA expresses changes (\\( \\Delta W \\)) in terms of these smaller matrices.  \n",
    "   - Initially, \\( \\Delta W \\) is zero to avoid interfering with the pretrained model's performance before training begins.\n",
    "\n",
    "2. **Random Gaussian Initialization for \\( A \\):**  \n",
    "   - The matrix \\( A \\) is initialized with random values drawn from a Gaussian distribution. This provides a starting point for optimization.\n",
    "\n",
    "3. **Zero Initialization for \\( B \\):**  \n",
    "   - \\( B \\) starts as a zero matrix, meaning that the initial contribution of \\( \\Delta W \\) is zero. This ensures the model behaves exactly like the pretrained version at the start.\n",
    "\n",
    "4. **Scaling \\( \\Delta W \\) by \\( \\alpha/r \\):**  \n",
    "   - **\\( \\alpha \\):** A scaling constant to control the magnitude of \\( \\Delta W \\).  \n",
    "   - **\\( r \\):** The rank of the low-rank factorization, i.e., the number of columns in \\( A \\) and \\( B \\).  \n",
    "   - Scaling by \\( \\alpha/r \\) ensures that \\( \\Delta W \\) doesn’t dominate the original \\( W \\) when \\( r \\) is small.  \n",
    "\n",
    "---\n",
    "\n",
    "### Why Scaling Matters\n",
    "1. **Consistent Magnitude Across \\( r \\):**  \n",
    "   Without scaling, \\( \\Delta W \\) might become disproportionately large or small when \\( r \\) changes, which would require retuning hyperparameters (like the learning rate) every time \\( r \\) is adjusted.  \n",
    "   Scaling by \\( \\alpha/r \\) ensures that the overall contribution of \\( \\Delta W \\) remains consistent, regardless of \\( r \\).\n",
    "\n",
    "2. **Reduced Hyperparameter Tuning:**  \n",
    "   - Scaling simplifies optimization by making the impact of \\( r \\) predictable.  \n",
    "   - This is why \\( \\alpha \\) can often be set to the same value for the first \\( r \\) tried, avoiding the need for extensive hyperparameter tuning.\n",
    "\n",
    "---\n",
    "\n",
    "### Connection to Adam Optimizer\n",
    "- **Adam Optimizer:** Adjusts learning rates dynamically for each parameter.  \n",
    "- By scaling \\( \\Delta W \\) with \\( \\alpha/r \\), the effective step size during optimization is kept consistent, making \\( \\alpha \\) behave like a proxy for the learning rate.  \n",
    "- Proper scaling ensures smooth training dynamics, even if \\( r \\) changes.\n",
    "\n",
    "---\n",
    "\n",
    "### Why \\( A \\) and \\( B \\) Initialization is Designed This Way:\n",
    "1. **Zero Initialization for \\( B \\):**  \n",
    "   - Prevents \\( \\Delta W \\) from contributing anything initially. This avoids disturbing the pretrained model at the start of fine-tuning.  \n",
    "   - \\( B \\) will learn to contribute meaningful changes during training.\n",
    "\n",
    "2. **Random Gaussian Initialization for \\( A \\):**  \n",
    "   - Introduces randomness to \\( A \\), which provides diversity in the directions that \\( \\Delta W \\) can explore during training.  \n",
    "   - This randomness allows \\( \\Delta W \\) to adapt effectively as \\( B \\) updates.\n",
    "\n",
    "---\n",
    "\n",
    "### Practical Impact\n",
    "- The combination of scaling and initialization strategies makes LoRA efficient and robust:  \n",
    "  - Efficient because \\( \\Delta W \\) is parameterized using smaller matrices \\( A \\) and \\( B \\).  \n",
    "  - Robust because the scaling ensures that the magnitude of updates remains stable, minimizing the need for extensive hyperparameter tuning.\n",
    "\n",
    "Would you like further clarification on any of these points or a more concrete example of how this works in practice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s work through an **example** to see how LoRA's initialization and scaling work in practice. We'll build up the intuition step by step.\n",
    "\n",
    "---\n",
    "\n",
    "### **Setup:**\n",
    "We have a pretrained weight matrix \\( W \\) and we want to fine-tune it using LoRA. Instead of directly updating \\( W \\), we decompose the update as:\n",
    "\n",
    "\\[\n",
    "W' = W + \\Delta W \\quad \\text{where} \\quad \\Delta W = BA\n",
    "\\]\n",
    "\n",
    "Here:\n",
    "- \\( W \\): Original weights (e.g., \\( 768 \\times 768 \\)).\n",
    "- \\( \\Delta W \\): Low-rank update matrix (\\( 768 \\times 768 \\)).\n",
    "- \\( B \\): Low-rank matrix (\\( 768 \\times r \\)).\n",
    "- \\( A \\): Low-rank matrix (\\( r \\times 768 \\)).\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 1: Initialization**\n",
    "- **Initialize \\( A \\):**  \n",
    "  \\( A \\) is randomly initialized using a Gaussian distribution (e.g., mean = 0, std = 0.02). This ensures that the directions of updates are diverse.\n",
    "\n",
    "- **Initialize \\( B \\):**  \n",
    "  \\( B \\) is initialized as a zero matrix. This ensures that \\( \\Delta W = 0 \\) at the start, meaning no changes are applied to \\( W \\) initially.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2: Scaling \\( \\Delta W \\)**\n",
    "We scale \\( \\Delta W \\) by \\( \\alpha / r \\), where:\n",
    "- \\( \\alpha \\): A constant controlling the magnitude of updates.\n",
    "- \\( r \\): The rank of the decomposition.\n",
    "\n",
    "This scaling ensures that the size of \\( \\Delta W \\) doesn’t explode or vanish when \\( r \\) changes.\n",
    "\n",
    "---\n",
    "\n",
    "### **Code Example**\n",
    "Let’s implement this step-by-step in Python.\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "# Step 1: Initialize W (pretrained weights) and define dimensions\n",
    "W = torch.randn(768, 768)  # Original weights\n",
    "r = 4                      # Rank of decomposition\n",
    "alpha = 16                 # Scaling constant\n",
    "\n",
    "# Initialize A and B\n",
    "A = torch.randn(r, 768) * 0.02  # Gaussian initialization for A\n",
    "B = torch.zeros(768, r)         # Zero initialization for B\n",
    "\n",
    "# Compute initial Delta W (should be zero)\n",
    "Delta_W = B @ A  # Shape: (768, 768)\n",
    "print(f\"Initial Delta_W: {Delta_W.norm():.4f}\")  # Should be close to 0\n",
    "\n",
    "# Step 2: Scale Delta W by alpha / r\n",
    "scaled_Delta_W = (alpha / r) * Delta_W\n",
    "print(f\"Scaled Delta_W: {scaled_Delta_W.norm():.4f}\")  # Still 0, as B = 0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3: Training**\n",
    "During training, \\( A \\) and \\( B \\) are updated by the optimizer (e.g., Adam). Let’s simulate one training step to show how \\( \\Delta W \\) evolves.\n",
    "\n",
    "```python\n",
    "# Define a simple optimizer\n",
    "optimizer = torch.optim.Adam([A, B], lr=1e-3)\n",
    "\n",
    "# Simulate a training step\n",
    "loss = (W + (alpha / r) * (B @ A)).norm()  # Example loss\n",
    "loss.backward()  # Compute gradients\n",
    "optimizer.step()  # Update A and B\n",
    "\n",
    "# Compute updated Delta W\n",
    "Delta_W = B @ A\n",
    "scaled_Delta_W = (alpha / r) * Delta_W\n",
    "print(f\"Updated Delta_W: {scaled_Delta_W.norm():.4f}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Scaling Helps**\n",
    "1. **Consistent Magnitude:**  \n",
    "   The scaling ensures that \\( \\Delta W \\)'s magnitude remains controlled regardless of \\( r \\). For example:\n",
    "   - If \\( r = 4 \\): Scaling factor is \\( \\alpha / 4 = 4 \\).\n",
    "   - If \\( r = 16 \\): Scaling factor is \\( \\alpha / 16 = 1 \\).  \n",
    "   This prevents \\( \\Delta W \\) from dominating \\( W \\) as \\( r \\) changes.\n",
    "\n",
    "2. **No Hyperparameter Retuning:**  \n",
    "   Since the effective step size is scaled consistently, you don’t need to retune the learning rate or other hyperparameters when adjusting \\( r \\).\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary of Key Insights**\n",
    "1. **Initialization:**  \n",
    "   \\( B = 0 \\) ensures \\( \\Delta W = 0 \\) initially, so the pretrained model starts unchanged.  \n",
    "   \\( A \\) is randomly initialized to allow flexibility in updates.\n",
    "\n",
    "2. **Scaling by \\( \\alpha / r \\):**  \n",
    "   Controls the magnitude of \\( \\Delta W \\) and ensures stability across different \\( r \\).\n",
    "\n",
    "3. **Efficiency:**  \n",
    "   By keeping \\( r \\) small (e.g., 2–16), LoRA reduces the number of trainable parameters while still capturing meaningful updates to \\( W \\).\n",
    "\n",
    "Would you like to dive deeper into how this impacts specific use cases, such as fine-tuning large language models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s clarify why **scaling by \\( \\alpha / r \\)** ensures that \\( \\Delta W \\)’s magnitude remains controlled, regardless of \\( r \\).\n",
    "\n",
    "---\n",
    "\n",
    "### **What is happening?**\n",
    "- \\( \\Delta W = BA \\): This is the low-rank update matrix.\n",
    "- Scaling by \\( \\alpha / r \\): This adjusts the overall magnitude of \\( \\Delta W \\), depending on the rank \\( r \\).\n",
    "\n",
    "Without scaling, \\( \\Delta W \\)’s size could vary significantly as \\( r \\) changes. For example:\n",
    "- A larger \\( r \\) (more components in \\( B \\) and \\( A \\)) would make \\( \\Delta W \\) larger, potentially overwhelming \\( W \\).\n",
    "- A smaller \\( r \\) would make \\( \\Delta W \\) too small, reducing its impact.\n",
    "\n",
    "By introducing the factor \\( \\alpha / r \\), we ensure that \\( \\Delta W \\)’s **overall contribution** is consistent.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example with Numbers**\n",
    "Let’s say:\n",
    "- \\( W \\) is the original weight matrix, initialized with a norm of \\( \\|W\\| = 10 \\).\n",
    "- \\( \\Delta W \\) is the update matrix we compute using \\( B \\) and \\( A \\).\n",
    "- \\( \\alpha = 16 \\): A constant that controls the overall scaling.\n",
    "\n",
    "#### Case 1: \\( r = 4 \\)\n",
    "- Scaling factor: \\( \\alpha / r = 16 / 4 = 4 \\).\n",
    "- Without scaling, \\( \\| \\Delta W \\| \\) might be, say, \\( 0.5 \\).\n",
    "- After scaling:  \n",
    "  \\[\n",
    "  \\| \\Delta W \\| = 4 \\times 0.5 = 2\n",
    "  \\]\n",
    "\n",
    "#### Case 2: \\( r = 16 \\)\n",
    "- Scaling factor: \\( \\alpha / r = 16 / 16 = 1 \\).\n",
    "- Without scaling, \\( \\| \\Delta W \\| \\) might be larger due to the increased rank, say \\( 2 \\).\n",
    "- After scaling:  \n",
    "  \\[\n",
    "  \\| \\Delta W \\| = 1 \\times 2 = 2\n",
    "  \\]\n",
    "\n",
    "---\n",
    "\n",
    "### **Why This Matters**\n",
    "The scaling ensures:\n",
    "1. **Consistent Magnitude:**  \n",
    "   Regardless of the rank \\( r \\), the effective size of \\( \\Delta W \\) stays controlled. This prevents \\( \\Delta W \\) from overshadowing \\( W \\) (or becoming negligible).\n",
    "\n",
    "2. **Hyperparameter Stability:**  \n",
    "   Since \\( \\Delta W \\)’s magnitude doesn’t depend on \\( r \\), you don’t need to retune hyperparameters like the learning rate when changing \\( r \\).\n",
    "\n",
    "---\n",
    "\n",
    "### **Takeaway**\n",
    "Scaling \\( \\Delta W \\) by \\( \\alpha / r \\) ensures that the low-rank updates are balanced and don’t overwhelm the original model’s weights. It’s a way to keep fine-tuning stable and predictable, regardless of how many low-rank components (\\( r \\)) you choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRAParameterization(nn.Module):\n",
    "    def __init__(self, features_in, features_out, rank=1, alpha=1, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        # section 4.1 of the paper:\n",
    "        #   we use a random Gaussian initialization for A and B, so ∆W = BA is zero at the beginning of training.\n",
    "        self.lora_A = nn.Parameter(torch.zeros((rank, features_out))).to(device)\n",
    "        self.lora_B = nn.Parameter(torch.zeros((features_in, rank))).to(device)\n",
    "\n",
    "        nn.init.normal_(self.lora_A, mean=0, std=1)  # initialize gaussuan distribution\n",
    "\n",
    "        # section 4.1 of the paper:\n",
    "        #  we scale ∆Wx by α/r , where α is a constant in r.\n",
    "        # when optimizing with adam, tuning α is roughly same as tuning the learning rate  if we scale the initilization appropriately\n",
    "        # as a result, we simply set to the first r  and try to not tune it.\n",
    "        # this scaling helps to reduce  the need to retune hyperparameters when we vary r\n",
    "        self.scale = alpha / rank  # alpha is fixed and we only try rank\n",
    "        self.enabled = True  # if lora is enabled.. we only run loRA on weights\n",
    "\n",
    "    def forward(self, original_weights):\n",
    "        if self.enabled:\n",
    "            # return X + (B*A)*scale\n",
    "            return (\n",
    "                original_weights\n",
    "                + torch.matmul(self.lora_B, self.lora_A).view(original_weights.shape)\n",
    "                * self.scale\n",
    "            )\n",
    "        else:\n",
    "            return original_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the parameterization to our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.parametrize as parametrize\n",
    "\n",
    "\n",
    "def linear_layer_parametrization(layer, device, rank=1, lora_alpha=1):\n",
    "    # only add the parameterization to the weight matrix, ignore the bias\n",
    "\n",
    "    # from section 4.2\n",
    "    # we limit our study to only adapting the attention weights for downstream tasks and freeze the MLP modules(as they are not trained in downstream taks)\n",
    "\n",
    "    features_in, features_out = layer.weight.shape\n",
    "    return LoRAParameterization(features_in, features_out, rank, lora_alpha, device)\n",
    "\n",
    "\n",
    "parametrize.register_parametrization(\n",
    "    net.linear1,\n",
    "    \"weight\",\n",
    "    linear_layer_parametrization(\n",
    "        net.linear1, device=device\n",
    "    ),  # replace weight matrix of linear1 layer with `linear_layer_parametrization(net.linear1, device=device)` fn`\n",
    ")  # we will get original weights and we will just alter them\n",
    "\n",
    "parametrize.register_parametrization(\n",
    "    net.linear2, \"weight\", linear_layer_parametrization(net.linear2, device=device)\n",
    ")\n",
    "\n",
    "parametrize.register_parametrization(\n",
    "    net.linear3, \"weight\", linear_layer_parametrization(net.linear3, device=device)\n",
    ")\n",
    "\n",
    "\n",
    "def enable_disable_lora(enabled=True):\n",
    "    for layer in [net.linear1, net.linear2, net.linear3]:\n",
    "        layer.parametrizations[\"weight\"][0].enabled = enabled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the number of parameters added by LoRA.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: W: torch.Size([1000, 784]) + B: torch.Size([1000]) + Lora_A: torch.Size([1, 784]) + Lora_B: torch.Size([1000, 1])\n",
      "Layer 2: W: torch.Size([2000, 1000]) + B: torch.Size([2000]) + Lora_A: torch.Size([1, 1000]) + Lora_B: torch.Size([2000, 1])\n",
      "Layer 3: W: torch.Size([10, 2000]) + B: torch.Size([10]) + Lora_A: torch.Size([1, 2000]) + Lora_B: torch.Size([10, 1])\n",
      "Total number of parameters (original): 2,807,010\n",
      "Total number of parameters (original + LoRA): 2,813,804\n",
      "Parameters introduced by LoRA: 6,794\n",
      "Parameters incremment: 0.242%\n"
     ]
    }
   ],
   "source": [
    "total_parameters_lora = 0\n",
    "total_parameters_non_lora = 0\n",
    "for index, layer in enumerate([net.linear1, net.linear2, net.linear3]):\n",
    "    total_parameters_lora += (\n",
    "        layer.parametrizations[\"weight\"][0].lora_A.nelement()\n",
    "        + layer.parametrizations[\"weight\"][0].lora_B.nelement()\n",
    "    )\n",
    "    total_parameters_non_lora += layer.weight.nelement() + layer.bias.nelement()\n",
    "    print(\n",
    "        f'Layer {index+1}: W: {layer.weight.shape} + B: {layer.bias.shape} + Lora_A: {layer.parametrizations[\"weight\"][0].lora_A.shape} + Lora_B: {layer.parametrizations[\"weight\"][0].lora_B.shape}'\n",
    "    )\n",
    "# The non-LoRA parameters count must match the original network\n",
    "assert total_parameters_non_lora == total_parameters_original\n",
    "print(f\"Total number of parameters (original): {total_parameters_non_lora:,}\")\n",
    "print(\n",
    "    f\"Total number of parameters (original + LoRA): {total_parameters_lora + total_parameters_non_lora:,}\"\n",
    ")\n",
    "print(f\"Parameters introduced by LoRA: {total_parameters_lora:,}\")\n",
    "parameters_incremment = (total_parameters_lora / total_parameters_non_lora) * 100\n",
    "print(f\"Parameters incremment: {parameters_incremment:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze all the parameters of the original network and only fine tuning the ones introduced by LoRA. Then fine-tune the model on the digit 9 and only for 100 batches.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linear1.bias',\n",
       " 'linear1.parametrizations.weight.original',\n",
       " 'linear1.parametrizations.weight.0.lora_A',\n",
       " 'linear1.parametrizations.weight.0.lora_B',\n",
       " 'linear2.bias',\n",
       " 'linear2.parametrizations.weight.original',\n",
       " 'linear2.parametrizations.weight.0.lora_A',\n",
       " 'linear2.parametrizations.weight.0.lora_B',\n",
       " 'linear3.bias',\n",
       " 'linear3.parametrizations.weight.original',\n",
       " 'linear3.parametrizations.weight.0.lora_A',\n",
       " 'linear3.parametrizations.weight.0.lora_B']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name, params in net.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='linear1.bias'\n",
      "Freezing non-LoRA parameter linear1.bias\n",
      "name='linear1.parametrizations.weight.original'\n",
      "Freezing non-LoRA parameter linear1.parametrizations.weight.original\n",
      "name='linear1.parametrizations.weight.0.lora_A'\n",
      "name='linear1.parametrizations.weight.0.lora_B'\n",
      "name='linear2.bias'\n",
      "Freezing non-LoRA parameter linear2.bias\n",
      "name='linear2.parametrizations.weight.original'\n",
      "Freezing non-LoRA parameter linear2.parametrizations.weight.original\n",
      "name='linear2.parametrizations.weight.0.lora_A'\n",
      "name='linear2.parametrizations.weight.0.lora_B'\n",
      "name='linear3.bias'\n",
      "Freezing non-LoRA parameter linear3.bias\n",
      "name='linear3.parametrizations.weight.original'\n",
      "Freezing non-LoRA parameter linear3.parametrizations.weight.original\n",
      "name='linear3.parametrizations.weight.0.lora_A'\n",
      "name='linear3.parametrizations.weight.0.lora_B'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  99%|█████████▉| 99/100 [00:00<00:00, 121.39it/s, loss=0.11] \n"
     ]
    }
   ],
   "source": [
    "# Freeze the non-Lora parameters\n",
    "for name, param in net.named_parameters():\n",
    "    print(f\"{name=}\")\n",
    "    if \"lora\" not in name:\n",
    "        print(f\"Freezing non-LoRA parameter {name}\")\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Load the MNIST dataset again, by keeping only the digit 9\n",
    "mnist_trainset = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "exclude_indices = mnist_trainset.targets == 9\n",
    "mnist_trainset.data = mnist_trainset.data[exclude_indices]\n",
    "mnist_trainset.targets = mnist_trainset.targets[exclude_indices]\n",
    "# Create a dataloader for the training\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Train the network with LoRA only on the digit 9 and only for 100 batches (hoping that it would improve the performance on the digit 9)\n",
    "train(train_loader, net, epochs=1, total_iterations_limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the fine-tuning didn't alter the original weights, but only the ones introduced by LoRA.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the frozen parameters are still unchanged by the finetuning\n",
    "assert torch.all(\n",
    "    net.linear1.parametrizations.weight.original == original_weights[\"linear1.weight\"]\n",
    ")\n",
    "assert torch.all(\n",
    "    net.linear2.parametrizations.weight.original == original_weights[\"linear2.weight\"]\n",
    ")\n",
    "assert torch.all(\n",
    "    net.linear3.parametrizations.weight.original == original_weights[\"linear3.weight\"]\n",
    ")\n",
    "\n",
    "enable_disable_lora(enabled=True)\n",
    "# The new linear1.weight is obtained by the \"forward\" function of our LoRA parametrization\n",
    "# The original weights have been moved to net.linear1.parametrizations.weight.original\n",
    "# More info here: https://pytorch.org/tutorials/intermediate/parametrizations.html#inspecting-a-parametrized-module\n",
    "assert torch.equal(\n",
    "    net.linear1.weight,\n",
    "    net.linear1.parametrizations.weight.original\n",
    "    + (\n",
    "        net.linear1.parametrizations.weight[0].lora_B\n",
    "        @ net.linear1.parametrizations.weight[0].lora_A\n",
    "    )\n",
    "    * net.linear1.parametrizations.weight[0].scale,\n",
    ")\n",
    "\n",
    "enable_disable_lora(enabled=False)\n",
    "# If we disable LoRA, the linear1.weight is the original one\n",
    "assert torch.equal(net.linear1.weight, original_weights[\"linear1.weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the network with LoRA enabled (the digit 9 should be classified better)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:03<00:00, 281.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.941\n",
      "wrong counts for the digit 0: 21\n",
      "wrong counts for the digit 1: 33\n",
      "wrong counts for the digit 2: 59\n",
      "wrong counts for the digit 3: 145\n",
      "wrong counts for the digit 4: 137\n",
      "wrong counts for the digit 5: 29\n",
      "wrong counts for the digit 6: 63\n",
      "wrong counts for the digit 7: 63\n",
      "wrong counts for the digit 8: 23\n",
      "wrong counts for the digit 9: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with LoRA enabled\n",
    "enable_disable_lora(enabled=True)\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the network with LoRA disabled (the accuracy and errors counts must be the same as the original network)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:02<00:00, 404.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.955\n",
      "wrong counts for the digit 0: 12\n",
      "wrong counts for the digit 1: 30\n",
      "wrong counts for the digit 2: 44\n",
      "wrong counts for the digit 3: 106\n",
      "wrong counts for the digit 4: 28\n",
      "wrong counts for the digit 5: 21\n",
      "wrong counts for the digit 6: 32\n",
      "wrong counts for the digit 7: 37\n",
      "wrong counts for the digit 8: 9\n",
      "wrong counts for the digit 9: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with LoRA disabled\n",
    "enable_disable_lora(enabled=False)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of RichBoyNet(\n",
       "  (linear1): ParametrizedLinear(\n",
       "    in_features=784, out_features=1000, bias=True\n",
       "    (parametrizations): ModuleDict(\n",
       "      (weight): ParametrizationList(\n",
       "        (0): LoRAParameterization()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear2): ParametrizedLinear(\n",
       "    in_features=1000, out_features=2000, bias=True\n",
       "    (parametrizations): ModuleDict(\n",
       "      (weight): ParametrizationList(\n",
       "        (0): LoRAParameterization()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear3): ParametrizedLinear(\n",
       "    in_features=2000, out_features=10, bias=True\n",
       "    (parametrizations): ModuleDict(\n",
       "      (weight): ParametrizationList(\n",
       "        (0): LoRAParameterization()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (relu): ReLU()\n",
       ")>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Here’s a detailed, **command-by-command** explanation of the code, broken into its key sections:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Creating the Neural Network (`RichBoyNet`)**\n",
    "```python\n",
    "class RichBoyNet(nn.Module):\n",
    "    def __init__(self, hidden_size_1=1000, hidden_size_2=2000):\n",
    "        super(RichBoyNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(28 * 28, hidden_size_1)  # Input layer: 28x28 (image flattened) to hidden layer 1\n",
    "        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2)  # Hidden layer 1 to hidden layer 2\n",
    "        self.linear3 = nn.Linear(hidden_size_2, 10)  # Hidden layer 2 to output layer (10 classes)\n",
    "        self.relu = nn.ReLU()  # ReLU activation function\n",
    "```\n",
    "\n",
    "- **Purpose:** Define an unnecessarily large neural network (hidden layers with 1000 and 2000 units) for classifying MNIST images into 10 classes (digits 0–9).\n",
    "- `nn.Linear`: A fully connected (dense) layer.\n",
    "- `ReLU`: Rectified Linear Unit activation introduces non-linearity.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "def forward(self, img):\n",
    "    x = img.view(-1, 28 * 28)  # Flatten the input (batch_size, 28x28 -> batch_size, 784)\n",
    "    x = self.relu(self.linear1(x))  # Apply linear1 and ReLU\n",
    "    x = self.relu(self.linear2(x))  # Apply linear2 and ReLU\n",
    "    x = self.linear3(x)  # Final layer (no activation since CrossEntropyLoss will handle softmax)\n",
    "    return x\n",
    "```\n",
    "\n",
    "- **Purpose:** Define how the data flows through the network. Each layer applies its operation sequentially.\n",
    "- `img.view(-1, 28 * 28)`: Flattens the image tensor for input to `linear1`.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Training the Model**\n",
    "```python\n",
    "def train(train_loader, net, epochs=5, total_iterations_limit=None):\n",
    "    cross_el = nn.CrossEntropyLoss()  # Loss function: Cross-entropy for classification\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)  # Adam optimizer\n",
    "```\n",
    "\n",
    "- **Purpose:** Define a training loop.\n",
    "- `nn.CrossEntropyLoss`: Combines `Softmax` and negative log-likelihood, suitable for multi-class classification.\n",
    "- `torch.optim.Adam`: Adaptive learning rate optimizer.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "    for epoch in range(epochs):  # Iterate through epochs\n",
    "        net.train()  # Set the model to training mode\n",
    "        loss_sum = 0\n",
    "        num_iterations = 0\n",
    "        for data in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):  # Iterate over batches\n",
    "            x, y = data  # Extract input (x) and labels (y)\n",
    "            x, y = x.to(device), y.to(device)  # Move to device (CPU/GPU)\n",
    "            optimizer.zero_grad()  # Clear gradients from previous step\n",
    "            output = net(x.view(-1, 28 * 28))  # Forward pass\n",
    "            loss = cross_el(output, y)  # Compute loss\n",
    "            loss_sum += loss.item()  # Accumulate loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update parameters\n",
    "```\n",
    "\n",
    "- **Purpose:** Train the model over multiple epochs, calculate loss, and optimize weights using backpropagation.\n",
    "- `tqdm`: Progress bar for visualization.\n",
    "- `optimizer.zero_grad()`: Clears gradients to avoid accumulation.\n",
    "- `loss.backward()`: Computes gradients for each parameter.\n",
    "- `optimizer.step()`: Updates model parameters based on gradients.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Testing the Model**\n",
    "```python\n",
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    wrong_counts = [0 for i in range(10)]  # Track misclassifications for each digit\n",
    "```\n",
    "\n",
    "- **Purpose:** Evaluate model performance on test data and identify digits that are often misclassified.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "    with torch.no_grad():  # Disable gradient computation for inference\n",
    "        for data in tqdm(test_loader, desc=\"Testing\"):  # Iterate through test data\n",
    "            x, y = data\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = net(x.view(-1, 784))  # Forward pass\n",
    "            for idx, i in enumerate(output):  # Iterate over predictions\n",
    "                if torch.argmax(i) == y[idx]:  # Correct prediction\n",
    "                    correct += 1\n",
    "                else:  # Incorrect prediction\n",
    "                    wrong_counts[y[idx]] += 1\n",
    "                total += 1\n",
    "```\n",
    "\n",
    "- **Purpose:** Loop through the test dataset, compute predictions, and count correct and incorrect classifications.\n",
    "- `torch.no_grad`: Saves memory and speeds up computation by disabling gradient tracking.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. LoRA Parameterization**\n",
    "LoRA (Low-Rank Adaptation) introduces a parameter-efficient method to fine-tune large models by only modifying a subset of the model's weights.\n",
    "\n",
    "```python\n",
    "class LoRAParameterization(nn.Module):\n",
    "    def __init__(self, features_in, features_out, rank=1, alpha=1, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.lora_A = nn.Parameter(torch.zeros((rank, features_out))).to(device)\n",
    "        self.lora_B = nn.Parameter(torch.zeros((features_in, rank))).to(device)\n",
    "        nn.init.normal_(self.lora_A, mean=0, std=1)  # Gaussian initialization\n",
    "        self.scale = alpha / rank  # Scaling factor\n",
    "        self.enabled = True  # Enable/disable LoRA\n",
    "```\n",
    "\n",
    "- **Purpose:** Define low-rank matrices (`lora_A`, `lora_B`) that adapt the original weight matrix during fine-tuning.\n",
    "- `rank`: Controls the low-rank approximation. Lower ranks reduce memory usage.\n",
    "- `alpha`: A scaling factor to adjust the update's magnitude.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "def forward(self, original_weights):\n",
    "    if self.enabled:\n",
    "        return (\n",
    "            original_weights\n",
    "            + torch.matmul(self.lora_B, self.lora_A).view(original_weights.shape)\n",
    "            * self.scale\n",
    "        )\n",
    "    else:\n",
    "        return original_weights\n",
    "```\n",
    "\n",
    "- **Purpose:** Add the low-rank update (`B @ A * scale`) to the original weights during forward passes when LoRA is enabled.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Registering LoRA Parameterization**\n",
    "```python\n",
    "parametrize.register_parametrization(\n",
    "    net.linear1, \"weight\", linear_layer_parametrization(net.linear1, device=device)\n",
    ")\n",
    "```\n",
    "\n",
    "- **Purpose:** Apply the LoRA parameterization to specific layers (`linear1`, `linear2`, `linear3`) by replacing their weights with the LoRA-adjusted weights.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Training with LoRA**\n",
    "```python\n",
    "for name, param in net.named_parameters():\n",
    "    if \"lora\" not in name:\n",
    "        param.requires_grad = False  # Freeze original weights\n",
    "```\n",
    "\n",
    "- **Purpose:** Fine-tune only the LoRA parameters (`lora_A`, `lora_B`) while freezing the original weights.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Results and Assertions**\n",
    "```python\n",
    "assert torch.all(\n",
    "    net.linear1.weight == original_weights[\"linear1.weight\"]\n",
    "    + (net.linear1.parametrizations.weight[0].lora_B @ net.linear1.parametrizations.weight[0].lora_A)\n",
    "    * net.linear1.parametrizations.weight[0].scale\n",
    ")\n",
    "```\n",
    "\n",
    "- **Purpose:** Verify that the LoRA-adjusted weights match the expected values.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Summary**\n",
    "This code:\n",
    "1. Creates a large neural network (`RichBoyNet`).\n",
    "2. Trains and tests the network on MNIST.\n",
    "3. Introduces LoRA to efficiently fine-tune the model with minimal additional parameters.\n",
    "4. Demonstrates LoRA's utility by training only on the digit \"9\" while freezing most parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Base Neural Network (RichBoyNet)\n",
    "\n",
    "```python\n",
    "class RichBoyNet(nn.Module):\n",
    "    def __init__(self, hidden_size_1=1000, hidden_size_2=2000):\n",
    "        super(RichBoyNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(28 * 28, hidden_size_1)\n",
    "        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
    "        self.linear3 = nn.Linear(hidden_size_2, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "```\n",
    "- Inherits from `nn.Module`, PyTorch's base class for neural networks\n",
    "- Takes two parameters for hidden layer sizes (default 1000 and 2000)\n",
    "- Creates three linear layers:\n",
    "  - Input layer: 784 (28×28 flattened MNIST image) → 1000 neurons\n",
    "  - Hidden layer: 1000 → 2000 neurons\n",
    "  - Output layer: 2000 → 10 neurons (one per digit)\n",
    "- Uses ReLU activation function between layers\n",
    "\n",
    "```python\n",
    "def forward(self, img):\n",
    "    x = img.view(-1, 28 * 28)  # Flatten image\n",
    "    x = self.relu(self.linear1(x))  # First layer + ReLU\n",
    "    x = self.relu(self.linear2(x))  # Second layer + ReLU\n",
    "    x = self.linear3(x)  # Output layer (no ReLU)\n",
    "    return x\n",
    "```\n",
    "- Defines forward pass through network\n",
    "- Flattens input image to 784 dimensions\n",
    "- Applies linear transformations with ReLU between layers\n",
    "- Returns raw logits (no softmax needed with CrossEntropyLoss)\n",
    "\n",
    "# 2. Training Function\n",
    "\n",
    "```python\n",
    "def train(train_loader, net, epochs=5, total_iterations_limit=None):\n",
    "    cross_el = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "```\n",
    "- Sets up CrossEntropyLoss for classification\n",
    "- Uses Adam optimizer with learning rate 0.001\n",
    "- Can limit total training iterations if specified\n",
    "\n",
    "```python\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        loss_sum = 0\n",
    "        num_iterations = 0\n",
    "        \n",
    "        data_iterator = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "        if total_iterations_limit is not None:\n",
    "            data_iterator.total = total_iterations_limit\n",
    "```\n",
    "- Loops through specified number of epochs\n",
    "- Sets network to training mode\n",
    "- Creates progress bar with tqdm\n",
    "- Handles iteration limit if specified\n",
    "\n",
    "```python\n",
    "        for data in data_iterator:\n",
    "            num_iterations += 1\n",
    "            total_iterations += 1\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "```\n",
    "- Processes each batch of data\n",
    "- Moves data to specified device (CPU/GPU)\n",
    "\n",
    "```python\n",
    "            optimizer.zero_grad()\n",
    "            output = net(x.view(-1, 28 * 28))\n",
    "            loss = cross_el(output, y)\n",
    "            loss_sum += loss.item()\n",
    "            avg_loss = loss_sum / num_iterations\n",
    "            data_iterator.set_postfix(loss=avg_loss)\n",
    "```\n",
    "- Zeroes gradients before each backward pass\n",
    "- Forward pass through network\n",
    "- Calculates loss\n",
    "- Updates progress bar with average loss\n",
    "\n",
    "```python\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if total_iterations_limit is not None and total_iterations >= total_iterations_limit:\n",
    "                return\n",
    "```\n",
    "- Backpropagates gradients\n",
    "- Updates weights\n",
    "- Checks iteration limit\n",
    "\n",
    "# 3. LoRA Implementation\n",
    "\n",
    "```python\n",
    "class LoRAParameterization(nn.Module):\n",
    "    def __init__(self, features_in, features_out, rank=1, alpha=1, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.lora_A = nn.Parameter(torch.zeros((rank, features_out))).to(device)\n",
    "        self.lora_B = nn.Parameter(torch.zeros((features_in, rank))).to(device)\n",
    "```\n",
    "- Creates LoRA matrices A and B\n",
    "- A is rank × output_features\n",
    "- B is input_features × rank\n",
    "- Both initialized as zero tensors\n",
    "\n",
    "```python\n",
    "        nn.init.normal_(self.lora_A, mean=0, std=1)  # initialize gaussian distribution\n",
    "        self.scale = alpha / rank\n",
    "        self.enabled = True\n",
    "```\n",
    "- Initializes A matrix with normal distribution\n",
    "- Sets scaling factor (alpha/rank as per LoRA paper)\n",
    "- Enables LoRA by default\n",
    "\n",
    "```python\n",
    "    def forward(self, original_weights):\n",
    "        if self.enabled:\n",
    "            return original_weights + torch.matmul(self.lora_B, self.lora_A).view(original_weights.shape) * self.scale\n",
    "        else:\n",
    "            return original_weights\n",
    "```\n",
    "- Implements LoRA update rule: W = W₀ + BA × (α/r)\n",
    "- Returns original weights if LoRA disabled\n",
    "\n",
    "# 4. LoRA Application\n",
    "\n",
    "```python\n",
    "def linear_layer_parametrization(layer, device, rank=1, lora_alpha=1):\n",
    "    features_in, features_out = layer.weight.shape\n",
    "    return LoRAParameterization(features_in, features_out, rank, lora_alpha, device)\n",
    "```\n",
    "- Creates LoRA parametrization for a linear layer\n",
    "- Extracts input/output dimensions from layer\n",
    "- Returns LoRA module with specified rank and alpha\n",
    "\n",
    "```python\n",
    "parametrize.register_parametrization(\n",
    "    net.linear1, \"weight\", linear_layer_parametrization(net.linear1, device=device)\n",
    ")\n",
    "```\n",
    "- Registers LoRA parametrization for each linear layer\n",
    "- Uses PyTorch's parametrization system\n",
    "- Applies to weight matrices only (not biases)\n",
    "\n",
    "# 5. Parameter Management\n",
    "\n",
    "```python\n",
    "def enable_disable_lora(enabled=True):\n",
    "    for layer in [net.linear1, net.linear2, net.linear3]:\n",
    "        layer.parametrizations[\"weight\"][0].enabled = enabled\n",
    "```\n",
    "- Toggles LoRA on/off for all layers\n",
    "- Allows switching between original and LoRA-modified weights\n",
    "\n",
    "```python\n",
    "# Freeze the non-Lora parameters\n",
    "for name, param in net.named_parameters():\n",
    "    if \"lora\" not in name:\n",
    "        param.requires_grad = False\n",
    "```\n",
    "- Freezes original network parameters\n",
    "- Only LoRA parameters will be updated during training\n",
    "\n",
    "# 6. Parameter Counting and Verification\n",
    "\n",
    "```python\n",
    "total_parameters_lora = 0\n",
    "total_parameters_non_lora = 0\n",
    "for index, layer in enumerate([net.linear1, net.linear2, net.linear3]):\n",
    "    total_parameters_lora += (\n",
    "        layer.parametrizations[\"weight\"][0].lora_A.nelement() +\n",
    "        layer.parametrizations[\"weight\"][0].lora_B.nelement()\n",
    "    )\n",
    "    total_parameters_non_lora += layer.weight.nelement() + layer.bias.nelement()\n",
    "```\n",
    "- Counts parameters in original network and LoRA additions\n",
    "- Verifies parameter counts match expectations\n",
    "- Calculates parameter increase percentage\n",
    "\n",
    "# 7. Fine-tuning Setup\n",
    "\n",
    "```python\n",
    "# Load the MNIST dataset again, by keeping only the digit 9\n",
    "mnist_trainset = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "exclude_indices = mnist_trainset.targets == 9\n",
    "mnist_trainset.data = mnist_trainset.data[exclude_indices]\n",
    "mnist_trainset.targets = mnist_trainset.targets[exclude_indices]\n",
    "```\n",
    "- Creates dataset with only digit 9\n",
    "- Used for specialized fine-tuning\n",
    "\n",
    "# 8. Verification Steps\n",
    "\n",
    "```python\n",
    "assert torch.all(\n",
    "    net.linear1.parametrizations.weight.original == original_weights[\"linear1.weight\"]\n",
    ")\n",
    "```\n",
    "- Verifies original weights unchanged after fine-tuning\n",
    "- Checks LoRA weight computation correctness\n",
    "- Confirms proper enabling/disabling of LoRA\n",
    "\n",
    "This implementation demonstrates how LoRA can be used to efficiently fine-tune a neural network by:\n",
    "1. Adding few trainable parameters (LoRA matrices)\n",
    "2. Preserving original weights\n",
    "3. Allowing easy switching between original and adapted behavior\n",
    "4. Maintaining model performance while reducing memory requirements\n",
    "\n",
    "The code follows the principles outlined in the LoRA paper while providing a practical PyTorch implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet demonstrates how **LoRA (Low-Rank Adaptation)** can be implemented using PyTorch's parameterization utilities (`torch.nn.utils.parametrize`). Here's a detailed explanation:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. What is happening here?**\n",
    "\n",
    "- **LoRA Concept**: \n",
    "  Instead of updating the entire weight matrix during training, LoRA modifies only a low-rank update (\\( \\Delta W = BA \\)) while keeping the original weights frozen. This reduces the number of trainable parameters and computational cost.\n",
    "\n",
    "- **Parameterization**: \n",
    "  PyTorch's `parametrize` module lets you modify how parameters are represented without directly altering the original parameter. Here, the weight matrix of a linear layer is \"parameterized\" with LoRA, meaning it gets split into a low-rank approximation \\( \\Delta W \\).\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Code Breakdown**\n",
    "\n",
    "#### **(a) `linear_layer_parametrization` function**\n",
    "```python\n",
    "def linear_layer_parametrization(layer, device, rank=1, lora_alpha=1):\n",
    "    features_in, features_out = layer.weight.shape\n",
    "    return LoRAParameterization(features_in, features_out, rank, lora_alpha, device)\n",
    "```\n",
    "\n",
    "- **Purpose**: This function creates a custom parameterization for a linear layer’s weight matrix using the `LoRAParameterization` class (assumed to be defined elsewhere).\n",
    "- **Parameters**:\n",
    "  - `rank`: The rank of the low-rank decomposition (\\( \\Delta W = BA \\), where \\( B \\in \\mathbb{R}^{m \\times r} \\) and \\( A \\in \\mathbb{R}^{r \\times n} \\)).\n",
    "  - `lora_alpha`: A scaling factor to control the magnitude of \\( \\Delta W \\) relative to the original weight matrix.\n",
    "  - `device`: Specifies where the parameterization will reside (e.g., GPU or CPU).\n",
    "\n",
    "---\n",
    "\n",
    "#### **(b) Registering Parameterizations**\n",
    "```python\n",
    "parametrize.register_parametrization(\n",
    "    net.linear1, \"weight\", linear_layer_parametrization(net.linear1, device=device)\n",
    ")\n",
    "```\n",
    "\n",
    "- **What happens here?**\n",
    "  - The `weight` parameter of `net.linear1` is replaced with a parameterized version defined by `linear_layer_parametrization`.\n",
    "  - The original `weight` is preserved, and any changes made by LoRA (\\( \\Delta W \\)) are added to it during the forward pass.\n",
    "\n",
    "- **Why?**\n",
    "  - This approach allows you to train only the low-rank components (\\( B \\) and \\( A \\)) while freezing the original weights.\n",
    "  - It’s efficient and keeps the changes modular.\n",
    "\n",
    "---\n",
    "\n",
    "#### **(c) Enabling/Disabling LoRA**\n",
    "```python\n",
    "def enable_disable_lora(enabled=True):\n",
    "    for layer in [net.linear1, net.linear2, net.linear3]:\n",
    "        layer.parametrizations[\"weight\"][0].enabled = enabled\n",
    "```\n",
    "\n",
    "- **Purpose**: Toggles LoRA updates for the layers (`linear1`, `linear2`, `linear3`).\n",
    "- **How?**\n",
    "  - Each parameterized weight has an `enabled` flag (defined in `LoRAParameterization`) that controls whether \\( \\Delta W \\) is applied during the forward pass.\n",
    "  - When `enabled=False`, the forward pass uses only the original weight \\( W \\), ignoring the LoRA updates.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Why Use `parametrize`?**\n",
    "\n",
    "- **Non-Intrusive Modifications**: The original weight matrix remains untouched. LoRA’s updates are modularly added.\n",
    "- **Flexibility**: You can enable or disable LoRA dynamically, making it easier to experiment with fine-tuning strategies.\n",
    "- **Scalability**: The same approach can be applied to multiple layers without modifying their original implementation.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Practical Intuition**\n",
    "\n",
    "- **Think of the layers as a trainable filter**:  \n",
    "  LoRA adds a small, tunable adjustment (\\( \\Delta W \\)) to the pre-trained weights. You can \"switch on\" these adjustments to fine-tune for a specific task or \"switch off\" to revert to the original model.\n",
    "\n",
    "- **Efficient Fine-Tuning**: Instead of retraining all parameters in the network, you only train the low-rank components, saving computation and memory.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Key Advantages**\n",
    "\n",
    "1. **Low Memory Footprint**: By focusing only on \\( B \\) and \\( A \\), you train fewer parameters compared to full fine-tuning.\n",
    "2. **Ease of Integration**: The `parametrize` module simplifies adding and managing LoRA updates.\n",
    "3. **Dynamic Control**: The `enable_disable_lora` function provides a clean way to toggle LoRA for experimentation.\n",
    "\n",
    "Would you like me to explain or expand on specific parts, such as how `LoRAParameterization` might work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `register_parametrization` function in PyTorch is a powerful tool for applying parameter transformations (e.g., custom modifications like **LoRA**) to layers in a model. Let’s break it down with a simple, **intuitive example** that explains its working.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example: Applying a Scaling Parametrization**\n",
    "\n",
    "Suppose you have a linear layer (`nn.Linear`) and you want to scale its weights dynamically by a learnable factor. You can use `register_parametrization` to apply this scaling without directly modifying the layer's original weights.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step-by-Step Code Explanation**\n",
    "\n",
    "#### 1. **Define a Parametrization Class**\n",
    "The parametrization defines how the original parameter (weights) is transformed.\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import parametrize\n",
    "\n",
    "# Parametrization class: scales weights by a learnable factor\n",
    "class ScaleParametrization(nn.Module):\n",
    "    def __init__(self, scale_factor=1.0):\n",
    "        super().__init__()\n",
    "        # Learnable scaling factor\n",
    "        self.scale = nn.Parameter(torch.tensor(scale_factor, dtype=torch.float32))\n",
    "\n",
    "    def forward(self, weights):\n",
    "        # Scale the weights dynamically\n",
    "        return weights * self.scale\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Create a Simple Model**\n",
    "Define a model with a single `nn.Linear` layer.\n",
    "\n",
    "```python\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.linear = nn.Linear(3, 2)  # A linear layer with input size 3 and output size 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Register the Parametrization**\n",
    "Apply the scaling parametrization to the weights of the `linear` layer.\n",
    "\n",
    "```python\n",
    "# Create the model\n",
    "model = SimpleModel()\n",
    "\n",
    "# Print original weights\n",
    "print(\"Original weights:\", model.linear.weight)\n",
    "\n",
    "# Register the scaling parametrization\n",
    "parametrize.register_parametrization(model.linear, \"weight\", ScaleParametrization(scale_factor=2.0))\n",
    "\n",
    "# Print parametrized weights (scaled)\n",
    "print(\"Parametrized weights:\", model.linear.weight)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Observe the Transformation**\n",
    "The `ScaleParametrization` scales the weights dynamically during forward passes, while the original weights remain unchanged.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. **Train the Model**\n",
    "You can now train the model, and the scaling factor will be updated during optimization.\n",
    "\n",
    "```python\n",
    "# Define an optimizer and loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Dummy input and target\n",
    "x = torch.tensor([[1.0, 2.0, 3.0]])\n",
    "target = torch.tensor([[0.5, 1.5]])\n",
    "\n",
    "# Training step\n",
    "for _ in range(5):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Observe changes\n",
    "    print(\"Scaled weights:\", model.linear.weight)\n",
    "    print(\"Scaling factor:\", model.linear.parametrizations.weight[0].scale)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Explanation of Key Concepts**\n",
    "\n",
    "1. **Original vs. Parametrized Weights**:\n",
    "   - The `parametrize.register_parametrization` applies a transformation (`ScaleParametrization`) to the `weight` tensor of the `linear` layer.\n",
    "   - The original weights are preserved and can be accessed using:\n",
    "     ```python\n",
    "     model.linear.parametrizations.weight.original\n",
    "     ```\n",
    "\n",
    "2. **Dynamic Updates**:\n",
    "   - During training, the scaling factor (`scale`) is updated, which changes the parametrized weights without modifying the original weights.\n",
    "\n",
    "3. **Accessing Components**:\n",
    "   - **Original weights**: `model.linear.parametrizations.weight.original`\n",
    "   - **Parametrized weights**: `model.linear.weight`\n",
    "   - **Scaling factor**: `model.linear.parametrizations.weight[0].scale`\n",
    "\n",
    "---\n",
    "\n",
    "### **Output Example**\n",
    "\n",
    "After registering the parametrization:\n",
    "\n",
    "- **Original weights**:  \n",
    "  ```\n",
    "  tensor([[0.5, -0.2, 0.1], [0.3, 0.4, -0.5]])\n",
    "  ```\n",
    "- **Parametrized weights (scaled)**:  \n",
    "  ```\n",
    "  tensor([[1.0, -0.4, 0.2], [0.6, 0.8, -1.0]])  # Original weights * scale_factor (2.0)\n",
    "  ```\n",
    "\n",
    "As training progresses, the scaling factor will adjust, influencing the scaled weights.\n",
    "\n",
    "---\n",
    "\n",
    "This demonstrates how `register_parametrization` allows you to dynamically transform parameters while keeping the original values intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchedOpen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "most models in deep neural networks are made up of billions of parameters. If every paramter is 32 bits has model is 7 billion paramter,  then we need 23gb just to stor the parameters on  disk.\n",
    "\n",
    "when we inference a mdoel, we need to load all the parameters in the memory(RAM/memory of GPU), this means big models ca not be loaded easily on a standard PC.\n",
    "\n",
    "Just like humans computers are slow at computing flaoting point operations compared to integer operations. Try to do 3 * 6  and compoare it to 1.27 * 2.897, which one do you compute fast?\n",
    "\n",
    "\n",
    "\n",
    "The solution is Quanitzation.\n",
    "\n",
    "Quantiations aims to reduce the total amount of bits required to represent each parameter, usually by converting floating -point numbers into integers. This way, a model that normally occupies 10GB can be \"compressed\" to less than 1 GB(depending on the type of quantization used)\n",
    "\n",
    "Qunatization doesn't mean truncating/rounding.\n",
    "\n",
    "Quantiation can also speed up the computation, as working with smaller data types is faster(for example multiplying two integers is faster than mulitplying two floating points numbers)\n",
    "\n",
    "\n",
    "### advantages \n",
    "\n",
    "1. less memory consumption when loading models\n",
    "2. less inference time due to simpler data types\n",
    "3. less energy consumption, because inference takes less compute overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization: A Comprehensive Overview\n",
    "\n",
    "#### **1. The Problem of Large Models**\n",
    "Deep neural networks (DNNs) are often made up of billions of parameters. Each of these parameters is typically stored as a **32-bit floating-point number** (FP32). This means that if a model has **7 billion parameters**, it will require about **28 GB** of memory just to store these parameters on disk.\n",
    "\n",
    "When you run inference (i.e., use the trained model for predictions), all of these parameters need to be loaded into memory, typically **RAM** or **GPU memory**. This poses a challenge for large models because standard consumer-grade PCs or GPUs may not have the memory capacity to store such massive models, making it difficult to run inference on them efficiently.\n",
    "\n",
    "#### **2. Floating-Point vs. Integer Operations**\n",
    "Computers perform **floating-point operations** (like multiplication or addition with numbers that have decimals) more slowly compared to **integer operations** (like operations on whole numbers). This difference in speed arises from the **complexity** of floating-point numbers, which have to handle both the **mantissa** (the value) and the **exponent** (how much to scale the value). This makes floating-point calculations computationally expensive.\n",
    "\n",
    "For example:\n",
    "- **Integer operation**: \\( 3 \\times 6 = 18 \\) (simple and fast)\n",
    "- **Floating-point operation**: \\( 1.27 \\times 2.897 = 3.681 \\) (more complex, requires more precision)\n",
    "\n",
    "Thus, working with **floating-point numbers** takes more time than working with **integers** because the computer has to handle more complexity during the computation.\n",
    "\n",
    "#### **3. What is Quantization?**\n",
    "Quantization is a technique used to address the issues of large model sizes and slow computation by reducing the precision of the model's parameters. In simpler terms, quantization reduces the **bit width** used to represent each parameter. Instead of using **32-bit floating-point numbers**, quantization converts the model's parameters into **lower precision data types**, typically **integers**.\n",
    "\n",
    "For example, instead of using 32-bit floating-point numbers (FP32), you can represent the parameters using:\n",
    "- **16-bit floating-point numbers (FP16)** or even\n",
    "- **8-bit integers (INT8)**.\n",
    "\n",
    "This reduces the **memory footprint** of the model, allowing it to fit into the memory of devices with limited resources.\n",
    "\n",
    "#### **4. The Impact of Quantization on Model Size**\n",
    "Let's take an example to understand the size reduction:\n",
    "- A model with **7 billion parameters** stored as **32-bit floats** would require **28 GB** of memory (since 1 parameter = 4 bytes).\n",
    "- By using **16-bit floats (FP16)**, the model size would reduce to **14 GB**.\n",
    "- By using **8-bit integers (INT8)**, the model size would shrink further to **7 GB** or less.\n",
    "\n",
    "In some cases, with aggressive quantization, models that originally required **10 GB** of memory can be compressed to **under 1 GB**, making them feasible to run on smaller devices.\n",
    "\n",
    "#### **5. Quantization is Not Just Rounding or Truncating**\n",
    "It’s important to understand that **quantization is not simply truncating or rounding** the values of the parameters. While rounding or truncating would reduce precision and possibly introduce large errors, quantization involves carefully selecting a lower precision format that preserves as much of the model’s performance as possible. Quantization techniques include:\n",
    "- **Uniform quantization**: The entire range of values is divided into equal intervals.\n",
    "- **Non-uniform quantization**: The intervals are adjusted based on the distribution of the values, preserving important features of the data.\n",
    "\n",
    "#### **6. Speeding Up Computation with Quantization**\n",
    "Quantization can also speed up computations. Since integer operations are faster than floating-point operations, using **8-bit integers** instead of **32-bit floats** leads to faster **multiplications**, **additions**, and other operations. This can result in:\n",
    "- **Faster inference**: Since smaller data types require less computation and memory access.\n",
    "- **Lower latency**: Especially important for real-time applications where response time is crucial.\n",
    "- **Reduced energy consumption**: Smaller models and faster computations can reduce the energy usage of devices, which is important for mobile or embedded systems.\n",
    "\n",
    "#### **7. Practical Benefits of Quantization**\n",
    "- **Memory efficiency**: By reducing the size of the model, you can run large models on devices with limited memory, such as mobile phones or embedded devices.\n",
    "- **Computational efficiency**: Quantized models can execute faster due to reduced computational complexity.\n",
    "- **Deployment on resource-constrained devices**: Models that would be too large or slow to run on typical hardware can now be deployed on edge devices or low-power systems.\n",
    "\n",
    "#### **8. Trade-offs of Quantization**\n",
    "While quantization offers several advantages, it does come with some trade-offs:\n",
    "- **Loss of precision**: Reducing the precision of parameters can slightly degrade the accuracy of the model. However, in many cases, the drop in accuracy is minimal and can be mitigated by **fine-tuning** the quantized model.\n",
    "- **Need for specialized hardware**: Some hardware accelerators (like certain GPUs or TPUs) are optimized for lower precision operations (like INT8 or FP16), but not all hardware supports these operations efficiently.\n",
    "\n",
    "#### **Conclusion**\n",
    "Quantization is a powerful technique in deep learning that addresses the challenges of **large model sizes** and **slow computations**. By converting floating-point parameters to lower precision integers, quantization reduces the memory footprint of models and speeds up computations. This makes it possible to deploy large models on **resource-constrained devices** while maintaining performance. It is a key tool for deploying AI models in practical, real-world applications, especially for edge devices, mobile phones, and other embedded systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Quantization: A Deeper Dive**\n",
    "\n",
    "#### **1. Problem of Large Models**\n",
    "Deep neural networks (DNNs) are made up of **billions of parameters**. These parameters are often stored as **32-bit floating-point numbers** (FP32). Let's say a model has **7 billion parameters**; storing these parameters requires about **28 GB** of disk space (since 1 parameter = 4 bytes).\n",
    "\n",
    "When you run inference (i.e., use the model to make predictions), all these parameters must be loaded into **memory (RAM or GPU memory)**. For large models, this becomes a significant issue, as standard PCs or GPUs may not have enough memory to load such massive models, making it difficult to perform inference.\n",
    "\n",
    "#### **2. Floating-Point vs. Integer Operations**\n",
    "Computers process **floating-point operations** (such as 1.27 * 2.897) more slowly compared to **integer operations** (such as 3 * 6). The reason is that floating-point numbers are more complex, involving both the **mantissa** (the value) and the **exponent** (how much to scale the value), which makes floating-point calculations more computationally expensive.\n",
    "\n",
    "- **Integer operation**: \\( 3 \\times 6 = 18 \\) (fast and simple)\n",
    "- **Floating-point operation**: \\( 1.27 \\times 2.897 = 3.681 \\) (slower and more complex)\n",
    "\n",
    "#### **3. Solution: Quantization**\n",
    "**Quantization** is a technique that aims to reduce the **bit width** of each parameter. Instead of using **32-bit floating-point numbers (FP32)**, the model parameters are converted to **lower precision data types**, such as **16-bit floating-point (FP16)** or even **8-bit integers (INT8)**.\n",
    "\n",
    "By doing this, you can reduce the **memory footprint** of the model, making it possible to store and run large models on **devices with limited memory** (like mobile phones or embedded systems).\n",
    "\n",
    "For example:\n",
    "- A model with **7 billion parameters** stored as **32-bit floats** requires **28 GB** of memory.\n",
    "- By using **16-bit floats (FP16)**, the memory requirement reduces to **14 GB**.\n",
    "- By using **8-bit integers (INT8)**, the model can be reduced to **7 GB** or even less.\n",
    "\n",
    "This **compression** makes it possible to deploy large models on devices that would otherwise not have enough memory to load them.\n",
    "\n",
    "#### **4. Quantization is Not Just Rounding or Truncating**\n",
    "**Quantization is not simply truncating or rounding** the values of the parameters. Instead, it carefully reduces the precision of the model's parameters while maintaining as much of the model's performance as possible. \n",
    "\n",
    "There are several types of quantization techniques:\n",
    "- **Uniform Quantization**: The value range is divided into equal intervals.\n",
    "- **Non-uniform Quantization**: The intervals are adjusted based on the distribution of values to preserve important features of the model.\n",
    "\n",
    "#### **5. Speeding Up Computation with Quantization**\n",
    "Quantization can also **speed up computations**. Since **integer operations** are faster than **floating-point operations**, using smaller data types (like **8-bit integers**) leads to faster arithmetic operations. For example:\n",
    "- **Integer multiplication** is faster than **floating-point multiplication** because integers are simpler to process.\n",
    "\n",
    "Thus, quantization reduces the time required for **inference** by making the computations faster.\n",
    "\n",
    "#### **6. Advantages of Quantization**\n",
    "\n",
    "1. **Less Memory Consumption**:  \n",
    "   By reducing the bit-width of the model's parameters, quantization significantly reduces the memory needed to store the model. This makes it feasible to load large models onto devices with limited memory.\n",
    "\n",
    "2. **Reduced Inference Time**:  \n",
    "   Smaller data types (such as **INT8**) require less processing power, leading to faster computations during inference. This means **faster predictions** and **lower latency**.\n",
    "\n",
    "3. **Energy Efficiency**:  \n",
    "   With smaller models and faster computations, **energy consumption** is reduced. This is especially important for mobile and embedded devices, where power is a critical constraint.\n",
    "\n",
    "#### **7. Practical Benefits of Quantization**\n",
    "- **Memory Efficiency**: Large models can be deployed on **edge devices** with limited memory.\n",
    "- **Faster Inference**: Quantized models run **faster**, making them suitable for **real-time applications**.\n",
    "- **Deployment on Resource-Constrained Devices**: Devices with limited **compute power** or **battery life** can still run large models, which is crucial for mobile applications or IoT devices.\n",
    "\n",
    "#### **8. Trade-offs and Considerations**\n",
    "While quantization has numerous advantages, it comes with a few trade-offs:\n",
    "- **Loss of Precision**: Reducing the precision of parameters can slightly degrade the accuracy of the model. However, this loss in accuracy is often minimal and can be mitigated by techniques such as **fine-tuning** after quantization.\n",
    "- **Hardware Requirements**: Some hardware (e.g., specific **GPUs** or **TPUs**) may be better optimized for lower precision operations (like **INT8**), while others may not support them as efficiently.\n",
    "\n",
    "#### **Conclusion**\n",
    "Quantization is a crucial technique in **deep learning** for addressing the challenges of large model sizes and slow computations. By reducing the precision of model parameters, quantization makes it possible to run large models on devices with limited resources while improving computation speed and reducing memory and energy consumption. It is a powerful tool for **deploying AI models** in **real-world applications**, especially in resource-constrained environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical representation of integer and floating point numbers\n",
    "Computers use fixed number of bits to represent any piece of data(a number, a character or pixel's color)\n",
    "A bit string made up of n bits can represent upto 2**n distinct numbers. For example, with 3 bits, we can represent a total of 2^3 distinct numbers.\n",
    "we usually represent nmbers in black of 8bits(byte), 16bits(short), 32 bits(int), 64 bits(long), 128 bits\n",
    "\n",
    "![](quant_01.png)\n",
    "## In most CPUs, integera are represented using 2's complement:, the first bit nidicates sign while the rest  indicate the absolute value of the number(in case it's positive), or it's complement in case of negative. 2's complement also gives a unique representation to the number 0.i.e. +0 and -0 have same binary represtation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integers are represented in the CPU as binary numbers, using sequences of bits (binary digits). This representation allows for efficient processing and manipulation by the arithmetic and logic units (ALUs) of the CPU. Here's an in-depth explanation of how integers are represented and processed in the CPU, covering various aspects:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Binary Representation**\n",
    "   - **Unsigned Integers**: Represented as binary numbers using all available bits for the value. For example, an 8-bit representation of the number 5 is `00000101`.\n",
    "   - **Signed Integers**: Use one bit (most significant bit, or MSB) to represent the sign (0 for positive, 1 for negative), and the remaining bits represent the magnitude of the number. \n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Methods of Signed Integer Representation**\n",
    "The CPU typically uses one of these methods for signed integers:\n",
    "\n",
    "#### **a. Sign-Magnitude Representation**\n",
    "   - MSB is the sign bit.\n",
    "   - Remaining bits represent the magnitude.\n",
    "   - Example (8-bit):\n",
    "     - +5: `00000101`\n",
    "     - -5: `10000101`\n",
    "   - Pros: Simple to understand.\n",
    "   - Cons: Complexity in arithmetic operations due to two representations for zero (`00000000` and `10000000`).\n",
    "\n",
    "#### **b. One's Complement**\n",
    "   - Negative numbers are represented by inverting all bits of the positive number.\n",
    "   - Example (8-bit):\n",
    "     - +5: `00000101`\n",
    "     - -5: `11111010`\n",
    "   - Pros: Slightly simpler arithmetic than sign-magnitude.\n",
    "   - Cons: Still has two representations for zero (`00000000` and `11111111`).\n",
    "\n",
    "#### **c. Two's Complement** (Most Common)\n",
    "   - Negative numbers are represented by taking the bitwise complement of the positive number and adding 1.\n",
    "   - Example (8-bit):\n",
    "     - +5: `00000101`\n",
    "     - -5: `11111011`\n",
    "   - Pros:\n",
    "     - Single representation for zero (`00000000`).\n",
    "     - Arithmetic operations (addition, subtraction) are straightforward and efficient.\n",
    "   - Cons: None significant; this is why it’s widely used.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Word Size and Bit-width**\n",
    "   - CPUs have a specific word size, typically 8, 16, 32, or 64 bits. This determines:\n",
    "     - **Range of integers**:\n",
    "       - Unsigned: \\(0\\) to \\(2^n - 1\\).\n",
    "       - Signed (Two's Complement): \\(-2^{n-1}\\) to \\(2^{n-1} - 1\\).\n",
    "     - **Storage size** for integers in registers and memory.\n",
    "   - Example for a 32-bit CPU:\n",
    "     - Unsigned range: \\(0\\) to \\(4,294,967,295\\).\n",
    "     - Signed range: \\(-2,147,483,648\\) to \\(2,147,483,647\\).\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Arithmetic Operations**\n",
    "   - Performed in binary, with the ALU handling carry/borrow for addition and subtraction.\n",
    "   - Overflow detection is critical:\n",
    "     - For signed integers, overflow occurs if the result exceeds the representable range.\n",
    "     - The CPU typically has an **overflow flag** in its status register to signal this.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Endianness**\n",
    "   - Determines the byte order for storing multi-byte integers in memory.\n",
    "     - **Big-Endian**: Most significant byte stored first.\n",
    "     - **Little-Endian**: Least significant byte stored first.\n",
    "   - CPUs (like Intel x86) use little-endian, while others (like some ARM architectures) may use big-endian.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Floating-Point and Special Representations**\n",
    "   - Although floating-point numbers are not integers, they can approximate large integers. However, CPUs handle them differently, using standards like IEEE 754.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Instruction Set Architecture (ISA)**\n",
    "   - Determines the specific instructions the CPU uses for integer operations:\n",
    "     - Addition, subtraction, multiplication, division.\n",
    "     - Logical operations (AND, OR, XOR).\n",
    "     - Bitwise shifts and rotations.\n",
    "   - Integer division and modulo are more complex and slower than addition and subtraction.\n",
    "\n",
    "---\n",
    "\n",
    "### 8. **Registers and Memory**\n",
    "   - Integer data is loaded into **registers** for processing.\n",
    "   - Registers are hardware storage locations within the CPU and have a fixed size (e.g., 32 or 64 bits).\n",
    "   - Larger integers may require multiple registers or memory locations.\n",
    "\n",
    "---\n",
    "\n",
    "### 9. **Special Integer Types**\n",
    "   - **BCD (Binary-Coded Decimal)**: Used in applications requiring exact decimal representation (e.g., financial systems).\n",
    "   - **Unsigned Integers**: Used when negative values are unnecessary, doubling the positive range.\n",
    "\n",
    "---\n",
    "\n",
    "### 10. **Hardware Support and Optimization**\n",
    "   - Modern CPUs include:\n",
    "     - **Vector Processing Units** for parallel integer operations (SIMD instructions).\n",
    "     - **Hardware Multipliers** and **Dividers** for efficient operations.\n",
    "     - **Caching and Pipelines** to optimize repeated integer operations.\n",
    "\n",
    "---\n",
    "\n",
    "This comprehensive representation allows CPUs to handle integer operations efficiently while supporting diverse applications and architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll explain how integers are represented in CPU architecture, covering the key aspects from binary representation to memory storage and handling.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Integer Representation in CPUs: A Comprehensive Guide\n",
    "\n",
    "## 1. Basic Binary Representation\n",
    "\n",
    "Integers in CPUs are stored as binary numbers using a sequence of bits (0s and 1s). The number of bits determines the range of values that can be represented:\n",
    "\n",
    "- 8-bit: 1 byte\n",
    "- 16-bit: 2 bytes\n",
    "- 32-bit: 4 bytes\n",
    "- 64-bit: 8 bytes\n",
    "\n",
    "### Example Binary Representations:\n",
    "```\n",
    "Decimal: 13\n",
    "Binary:  00001101\n",
    "```\n",
    "\n",
    "## 2. Signed vs. Unsigned Integers\n",
    "\n",
    "### Unsigned Integers\n",
    "- Only represent positive numbers (including zero)\n",
    "- Range for n bits: 0 to 2^n - 1\n",
    "- Example (8-bit): 0 to 255\n",
    "\n",
    "### Signed Integers\n",
    "Use two's complement representation:\n",
    "1. Most significant bit (MSB) indicates sign (0 for positive, 1 for negative)\n",
    "2. Range for n bits: -2^(n-1) to 2^(n-1) - 1\n",
    "3. Example (8-bit): -128 to 127\n",
    "\n",
    "#### Two's Complement Process:\n",
    "1. Invert all bits\n",
    "2. Add 1 to the result\n",
    "\n",
    "Example converting -5 to two's complement (8-bit):\n",
    "```\n",
    "+5:              00000101\n",
    "Invert:          11111010\n",
    "Add 1:           11111011 (-5 in two's complement)\n",
    "```\n",
    "\n",
    "## 3. Memory Layout\n",
    "\n",
    "### Little-Endian\n",
    "- Least significant byte stored at lowest memory address\n",
    "- Example (32-bit integer 0x12345678):\n",
    "```\n",
    "Address:    0x1000  0x1001  0x1002  0x1003\n",
    "Value:      78      56      34      12\n",
    "```\n",
    "\n",
    "### Big-Endian\n",
    "- Most significant byte stored at lowest memory address\n",
    "- Example (same 32-bit integer):\n",
    "```\n",
    "Address:    0x1000  0x1001  0x1002  0x1003\n",
    "Value:      12      34      56      78\n",
    "```\n",
    "\n",
    "## 4. Integer Overflow and Underflow\n",
    "\n",
    "### Overflow Example (8-bit unsigned):\n",
    "```\n",
    "   11111111  (255)\n",
    "+  00000001  (1)\n",
    "-----------\n",
    "   00000000  (wraps to 0)\n",
    "```\n",
    "\n",
    "### Underflow Example (8-bit signed):\n",
    "```\n",
    "   10000000  (-128)\n",
    "-  00000001  (1)\n",
    "-----------\n",
    "   01111111  (wraps to 127)\n",
    "```\n",
    "\n",
    "## 5. CPU Register Storage\n",
    "\n",
    "- General-purpose registers store integers during operations\n",
    "- Register size matches CPU architecture (32-bit or 64-bit)\n",
    "- Modern x86-64 registers:\n",
    "  - RAX, RBX, RCX, RDX (64-bit)\n",
    "  - EAX, EBX, ECX, EDX (32-bit portions)\n",
    "  - AX, BX, CX, DX (16-bit portions)\n",
    "  - AL, BL, CL, DL (8-bit portions)\n",
    "\n",
    "## 6. Arithmetic Operations\n",
    "\n",
    "### Addition\n",
    "```\n",
    "   00000101  (5)\n",
    "+  00000011  (3)\n",
    "-----------\n",
    "   00001000  (8)\n",
    "```\n",
    "\n",
    "### Multiplication\n",
    "```\n",
    "   00000101  (5)\n",
    "×  00000011  (3)\n",
    "-----------\n",
    "   00001111  (15)\n",
    "```\n",
    "\n",
    "## 7. Special Values\n",
    "\n",
    "### Zero\n",
    "- Represented as all bits set to 0\n",
    "- Same representation in both signed and unsigned\n",
    "\n",
    "### Maximum Values\n",
    "- Unsigned: All bits set to 1\n",
    "- Signed: All bits set to 1 except MSB\n",
    "\n",
    "### Minimum Values\n",
    "- Unsigned: All bits set to 0\n",
    "- Signed: MSB set to 1, all others 0\n",
    "\n",
    "## 8. Performance Considerations\n",
    "\n",
    "- Alignment: Integers should be aligned to their natural boundaries\n",
    "- Cache line sizing: Proper alignment helps optimize cache usage\n",
    "- SIMD operations: Modern CPUs can perform multiple integer operations simultaneously\n",
    "\n",
    "\n",
    "\n",
    "Let me explain some of the key aspects that are particularly important to understand:\n",
    "\n",
    "1. Fundamental Storage: At its core, integers are stored as binary numbers - sequences of 1s and 0s. The CPU uses different bit lengths (8, 16, 32, or 64) depending on the architecture and data type.\n",
    "\n",
    "2. Sign Handling: The way negative numbers are handled is particularly interesting. Modern CPUs use two's complement representation, which has several advantages:\n",
    "   - It allows for simpler hardware implementation of arithmetic operations\n",
    "   - There's only one representation of zero\n",
    "   - Addition and subtraction work the same way for both positive and negative numbers\n",
    "\n",
    "3. Memory Considerations: The way integers are stored in memory can vary between architectures. This is known as \"endianness\":\n",
    "   - Little-endian systems (like x86) store the least significant byte first\n",
    "   - Big-endian systems store the most significant byte first\n",
    "   This becomes important when working with data across different systems or reading binary files.\n",
    "\n",
    "4. Hardware Operations: CPUs have specialized circuits for integer arithmetic that can:\n",
    "   - Perform basic operations (add, subtract, multiply, divide)\n",
    "   - Detect overflow/underflow conditions\n",
    "   - Handle carry and borrow in arithmetic operations\n",
    "\n",
    "Would you like me to elaborate on any of these aspects or explain more about a specific area of integer representation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integer Representation in CPUs: A Comprehensive Guide\n",
    "\n",
    "## 1. Basic Binary Representation\n",
    "\n",
    "Integers in CPUs are stored as binary numbers using a sequence of bits (0s and 1s). The number of bits determines the range of values that can be represented:\n",
    "\n",
    "- 8-bit: 1 byte\n",
    "- 16-bit: 2 bytes\n",
    "- 32-bit: 4 bytes\n",
    "- 64-bit: 8 bytes\n",
    "\n",
    "### Example Binary Representations:\n",
    "```\n",
    "Decimal: 13\n",
    "Binary:  00001101\n",
    "```\n",
    "\n",
    "## 2. Signed vs. Unsigned Integers\n",
    "\n",
    "### Unsigned Integers\n",
    "- Only represent positive numbers (including zero)\n",
    "- Range for n bits: 0 to 2^n - 1\n",
    "- Example (8-bit): 0 to 255\n",
    "\n",
    "### Signed Integers\n",
    "Use two's complement representation:\n",
    "1. Most significant bit (MSB) indicates sign (0 for positive, 1 for negative)\n",
    "2. Range for n bits: -2^(n-1) to 2^(n-1) - 1\n",
    "3. Example (8-bit): -128 to 127\n",
    "\n",
    "#### Two's Complement Process:\n",
    "1. Invert all bits\n",
    "2. Add 1 to the result\n",
    "\n",
    "Example converting -5 to two's complement (8-bit):\n",
    "```\n",
    "+5:              00000101\n",
    "Invert:          11111010\n",
    "Add 1:           11111011 (-5 in two's complement)\n",
    "```\n",
    "\n",
    "## 3. Memory Layout\n",
    "\n",
    "### Little-Endian\n",
    "- Least significant byte stored at lowest memory address\n",
    "- Example (32-bit integer 0x12345678):\n",
    "```\n",
    "Address:    0x1000  0x1001  0x1002  0x1003\n",
    "Value:      78      56      34      12\n",
    "```\n",
    "\n",
    "### Big-Endian\n",
    "- Most significant byte stored at lowest memory address\n",
    "- Example (same 32-bit integer):\n",
    "```\n",
    "Address:    0x1000  0x1001  0x1002  0x1003\n",
    "Value:      12      34      56      78\n",
    "```\n",
    "\n",
    "## 4. Integer Overflow and Underflow\n",
    "\n",
    "### Overflow Example (8-bit unsigned):\n",
    "```\n",
    "   11111111  (255)\n",
    "+  00000001  (1)\n",
    "-----------\n",
    "   00000000  (wraps to 0)\n",
    "```\n",
    "\n",
    "### Underflow Example (8-bit signed):\n",
    "```\n",
    "   10000000  (-128)\n",
    "-  00000001  (1)\n",
    "-----------\n",
    "   01111111  (wraps to 127)\n",
    "```\n",
    "\n",
    "## 5. CPU Register Storage\n",
    "\n",
    "- General-purpose registers store integers during operations\n",
    "- Register size matches CPU architecture (32-bit or 64-bit)\n",
    "- Modern x86-64 registers:\n",
    "  - RAX, RBX, RCX, RDX (64-bit)\n",
    "  - EAX, EBX, ECX, EDX (32-bit portions)\n",
    "  - AX, BX, CX, DX (16-bit portions)\n",
    "  - AL, BL, CL, DL (8-bit portions)\n",
    "\n",
    "## 6. Arithmetic Operations\n",
    "\n",
    "### Addition\n",
    "```\n",
    "   00000101  (5)\n",
    "+  00000011  (3)\n",
    "-----------\n",
    "   00001000  (8)\n",
    "```\n",
    "\n",
    "### Multiplication\n",
    "```\n",
    "   00000101  (5)\n",
    "×  00000011  (3)\n",
    "-----------\n",
    "   00001111  (15)\n",
    "```\n",
    "\n",
    "## 7. Special Values\n",
    "\n",
    "### Zero\n",
    "- Represented as all bits set to 0\n",
    "- Same representation in both signed and unsigned\n",
    "\n",
    "### Maximum Values\n",
    "- Unsigned: All bits set to 1\n",
    "- Signed: All bits set to 1 except MSB\n",
    "\n",
    "### Minimum Values\n",
    "- Unsigned: All bits set to 0\n",
    "- Signed: MSB set to 1, all others 0\n",
    "\n",
    "## 8. Performance Considerations\n",
    "\n",
    "- Alignment: Integers should be aligned to their natural boundaries\n",
    "- Cache line sizing: Proper alignment helps optimize cache usage\n",
    "- SIMD operations: Modern CPUs can perform multiple integer operations simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Word Size and Bit Width in a CPU**\n",
    "\n",
    "---\n",
    "\n",
    "### **1. What is Word Size?**\n",
    "\n",
    "- **Definition**: \n",
    "  - Word size refers to the number of bits a CPU can process, transfer, or store in a single operation.\n",
    "  - It is a fundamental characteristic of a CPU’s architecture.\n",
    "\n",
    "- **Typical Word Sizes**: \n",
    "  - Common word sizes are 8, 16, 32, or 64 bits, depending on the processor's architecture.\n",
    "  - Example:\n",
    "    - An 8-bit CPU processes data in chunks of 8 bits.\n",
    "    - A 64-bit CPU processes data in chunks of 64 bits.\n",
    "\n",
    "- **Significance**:\n",
    "  - Determines how much data the CPU can handle at once.\n",
    "  - Influences the range of integers that can be represented.\n",
    "  - Affects the size of CPU registers, data buses, and addressable memory.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. What is Bit Width?**\n",
    "\n",
    "- **Definition**: \n",
    "  - Bit width describes the number of bits used in a specific context within the CPU, such as:\n",
    "    - **Data bus width**: The width of the bus that carries data between the CPU and memory.\n",
    "    - **Address bus width**: Determines the maximum addressable memory.\n",
    "    - **Registers width**: The number of bits in CPU registers.\n",
    "  - While bit width and word size often align, they can differ for specialized components.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Relation Between Word Size and Bit Width**\n",
    "\n",
    "- **Word Size**: \n",
    "  - Represents the size of the CPU’s general-purpose registers and ALU.\n",
    "  - Example:\n",
    "    - A 32-bit word size means registers and operations typically handle 32-bit chunks of data.\n",
    "\n",
    "- **Bit Width in Buses**:\n",
    "  - **Data Bus**:\n",
    "    - Determines how many bits of data can be transferred to/from memory in one cycle.\n",
    "    - A CPU with a 32-bit word size might have a 64-bit data bus for higher memory throughput.\n",
    "  - **Address Bus**:\n",
    "    - Determines the maximum addressable memory:\n",
    "      \\[\n",
    "      \\text{Addressable Memory} = 2^{\\text{Address Bus Width}}\n",
    "      \\]\n",
    "    - Example:\n",
    "      - A 32-bit address bus can address \\(2^{32} = 4 \\, \\text{GB}\\) of memory.\n",
    "      - A 64-bit address bus can address \\(2^{64} = 16 \\, \\text{Exabytes}\\).\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Impact on Integer Representation**\n",
    "\n",
    "- **Word Size and Integer Range**:\n",
    "  - Determines the maximum range of integers the CPU can process in a single operation.\n",
    "  - For unsigned integers:\n",
    "    \\[\n",
    "    \\text{Range} = 0 \\text{ to } 2^{n} - 1\n",
    "    \\]\n",
    "  - For signed integers (Two's Complement):\n",
    "    \\[\n",
    "    \\text{Range} = -2^{n-1} \\text{ to } 2^{n-1} - 1\n",
    "    \\]\n",
    "    - Example for 32-bit:\n",
    "      - Unsigned: \\(0 \\text{ to } 4,294,967,295\\).\n",
    "      - Signed: \\(-2,147,483,648 \\text{ to } 2,147,483,647\\).\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Historical Context**\n",
    "- Early CPUs (e.g., 8-bit or 16-bit) had smaller word sizes and bit widths, limiting processing power.\n",
    "- Modern CPUs, like 64-bit processors, handle larger data chunks, enabling:\n",
    "  - Larger addressable memory spaces.\n",
    "  - Faster and more efficient computation of large datasets.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Practical Examples**\n",
    "\n",
    "#### **Word Size in Arithmetic Operations**:\n",
    "- A 32-bit CPU performs arithmetic on 32-bit integers in a single operation.\n",
    "- A 64-bit CPU can process 64-bit integers directly, improving precision and range.\n",
    "\n",
    "#### **Bit Width in Memory Access**:\n",
    "- A 64-bit data bus transfers 64 bits of data per cycle, enabling faster memory operations compared to a 32-bit data bus.\n",
    "\n",
    "#### **Address Space**:\n",
    "- A 32-bit address bus limits memory to \\(4 \\, \\text{GB}\\), which can be restrictive for modern applications.\n",
    "- A 64-bit address bus supports addressing vast memory spaces, crucial for high-performance computing.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Modern Trends**\n",
    "- Most modern processors are **64-bit**.\n",
    "  - **Benefits**:\n",
    "    - Larger memory support.\n",
    "    - Improved computational performance for large integers.\n",
    "    - Compatibility with modern software and operating systems.\n",
    "  - **Challenges**:\n",
    "    - Increased memory usage for storing larger pointers and data structures.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "Word size and bit width are critical attributes of a CPU that define its capabilities in data processing, memory addressing, and overall performance. They have evolved significantly over time, enabling more powerful and efficient computing systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### computers use fixed nuimber of bits to represent numbers but how can python handle such big numbers like 2**999 without any problems. which is much bigger than any 64 bit number and how can pytohn handle this huge number without any problems. Python uses son called BigNum arithmetics to represent\n",
    "\n",
    "for example 6 in decimal needs one bit but in base  2 it needs 110 so this is actually a rule. the smaller the base the bigger the number of the degits we need to represent  those numbers.. so python does inverse. it saves 2**9999 as an array of  digits in base 2 ** 30, so overall we need less digits to store very big numbers.\n",
    "\n",
    "so in decimal system, for 2*9999 we would need 3010 digits to store it in memory while python stores it in memory in base 2**30 so it only needs 334 elements. in which all elemtns are 0s except the most significant one which is equal to 512\n",
    "\n",
    "\n",
    "2**9999 == 512 * ((2**30) ** 333)  ## 2^30 is base , 333 is position of digit\n",
    "![](quant_02.png)\n",
    "\n",
    "\n",
    "\n",
    "### it is implemented by cpython which is pytohn interpretor and not CPU, so its not CPU doing this but python interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**9999 == 512 * ((2**30) ** 333)  ## 2^30 is base , 333 is position of digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python can handle arbitrarily large numbers like \\(2^{9999}\\) without issues because it uses **BigNum arithmetic**, a technique implemented in the Python interpreter (specifically CPython, the default implementation of Python). This capability allows Python to work with integers much larger than the fixed bit-width integers handled by the CPU.\n",
    "\n",
    "Here’s an explanation of how Python achieves this, breaking it down step by step:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. The Problem with Fixed Bit Width**\n",
    "- Most CPUs have a fixed word size (e.g., 32-bit or 64-bit), which limits the range of integers they can natively represent.\n",
    "  - For a 64-bit signed integer: \\(-2^{63}\\) to \\(2^{63} - 1\\).\n",
    "  - Beyond this range, computations would cause an **overflow** in most low-level languages like C.\n",
    "- Python, however, avoids this limitation by using **dynamic typing** and **arbitrary-precision integers**.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Arbitrary-Precision Integers in Python**\n",
    "- Python's integers (of type `int`) can grow in size as needed, limited only by the available memory.\n",
    "- Internally, Python does not represent large numbers as a single binary number. Instead, it uses an **array of digits** in a large base (e.g., \\(2^{30}\\)).\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Base Representation for Efficiency**\n",
    "- To store very large numbers, Python optimizes by:\n",
    "  - Representing the number in a base higher than the typical binary base \\(2\\).\n",
    "  - Using a base of \\(2^{30}\\) (or \\(2^{15}\\) on some systems for compatibility).\n",
    "- **Why \\(2^{30}\\)?**\n",
    "  - A larger base reduces the number of \"digits\" required to represent the number.\n",
    "  - Example:\n",
    "    - \\(2^{9999}\\) in decimal requires **3010 digits**.\n",
    "    - \\(2^{9999}\\) in base \\(2^{30}\\) requires only **334 digits**.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. How Python Represents \\(2^{9999}\\)**\n",
    "- Python represents \\(2^{9999}\\) as:\n",
    "  \\[\n",
    "  2^{9999} = \\text{Digit}_0 \\times (2^{30})^0 + \\text{Digit}_1 \\times (2^{30})^1 + \\cdots\n",
    "  \\]\n",
    "- For \\(2^{9999}\\):\n",
    "  - Most of the \"digits\" are \\(0\\), except the **most significant digit** (MSD).\n",
    "  - In base \\(2^{30}\\), \\(2^{9999}\\) is represented as:\n",
    "    \\[\n",
    "    512 \\times (2^{30})^{333}\n",
    "    \\]\n",
    "    - \\(512\\) is the MSD.\n",
    "    - \\(333\\) is the position (exponent of \\(2^{30}\\)).\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Why Base \\(2^{30}\\) is Efficient**\n",
    "- **Compact Representation**:\n",
    "  - Storing numbers in base \\(2^{30}\\) requires fewer \"digits\" compared to smaller bases.\n",
    "- **Efficient Arithmetic**:\n",
    "  - CPUs can process \\(2^{30}\\)-based digits efficiently because they align well with the CPU's word size.\n",
    "  - Python splits the number into chunks that fit into standard CPU registers, allowing the CPU to perform arithmetic operations on smaller parts of the number.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Implementation in CPython**\n",
    "- The CPython interpreter (written in C) implements BigNum arithmetic using:\n",
    "  - **Arrays**: To store digits of the number.\n",
    "  - **Algorithms**: For arithmetic operations like addition, subtraction, multiplication, and division on large numbers.\n",
    "  - Example: Multiplication of two large numbers involves breaking them into smaller parts, performing multiplication on chunks, and combining results.\n",
    "- Libraries like **`gmpy2`** or Python’s built-in **`decimal`** module further optimize large number computations.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Python vs. CPU**\n",
    "- **CPU Limitations**:\n",
    "  - The CPU itself cannot directly handle numbers larger than its word size (e.g., 64 bits).\n",
    "  - For operations beyond the CPU's capability, the Python interpreter splits the work into smaller operations.\n",
    "- **Python’s Role**:\n",
    "  - Python acts as an intermediary, handling the complexities of breaking large numbers into manageable chunks and combining results.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Practical Example**\n",
    "Here’s how Python would compute \\(2^{9999}\\):\n",
    "```python\n",
    "n = 2 ** 9999\n",
    "print(n)\n",
    "```\n",
    "- Internally:\n",
    "  - Python calculates the result using \\(2^{30}\\)-based arithmetic.\n",
    "  - The result is stored as an array of 334 elements.\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Visualization**\n",
    "Using the formula:\n",
    "\\[\n",
    "2^{9999} = 512 \\times (2^{30})^{333}\n",
    "\\]\n",
    "- Python stores this number efficiently:\n",
    "  - **334 elements** in memory, with only the most significant digit (\\(512\\)) being non-zero.\n",
    "  - This reduces the memory footprint compared to storing all \\(3010\\) decimal digits.\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Summary**\n",
    "- Python can handle massive integers using **BigNum arithmetic**.\n",
    "- It represents large numbers in base \\(2^{30}\\), reducing the number of digits required.\n",
    "- The Python interpreter (not the CPU) manages this representation and performs efficient arithmetic operations on large numbers.\n",
    "\n",
    "This approach allows Python to handle numbers as large as memory permits, without being constrained by the CPU's fixed bit-width limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BigNum arithmetic** refers to computational techniques and data structures designed to handle arbitrarily large numbers that exceed the size limits of standard fixed-width data types like 32-bit or 64-bit integers. It is used in many programming languages, including Python, to enable seamless operations on extremely large integers.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Concepts of BigNum Arithmetic**\n",
    "1. **Arbitrary Precision**:\n",
    "   - Unlike fixed-width integers, BigNum allows numbers to grow in size as needed, limited only by the system's memory.\n",
    "   - This is achieved by representing numbers as arrays of smaller chunks (or \"digits\").\n",
    "\n",
    "2. **Base Representation**:\n",
    "   - BigNum implementations often use a large base (e.g., \\(2^{30}\\)) to store numbers.\n",
    "   - Larger bases reduce the number of chunks (or \"digits\") required, making arithmetic operations more efficient.\n",
    "\n",
    "3. **Array-Based Storage**:\n",
    "   - Numbers are stored as arrays of \"digits,\" where each digit represents a chunk of the number in the chosen base.\n",
    "   - For example, \\(123456789\\) in base \\(10^4\\) might be stored as:\n",
    "     \\[\n",
    "     [6789, 2345, 1]\n",
    "     \\]\n",
    "     (each element is a \"digit\" in base \\(10^4\\)).\n",
    "\n",
    "4. **Arithmetic Operations**:\n",
    "   - BigNum arithmetic involves algorithms for addition, subtraction, multiplication, and division that operate on these arrays.\n",
    "   - Operations are performed digit by digit, often using carry or borrow techniques, similar to how we do manual arithmetic.\n",
    "\n",
    "---\n",
    "\n",
    "### **How BigNum Works in Python**\n",
    "Python's `int` type uses BigNum arithmetic internally. Here’s a breakdown:\n",
    "\n",
    "#### **Representation**:\n",
    "- Python uses **base \\(2^{30}\\)** (or \\(2^{15}\\) on some systems) for its BigNum representation.\n",
    "- A large number like \\(2^{9999}\\) is stored as an array of integers, where each element is a \"digit\" in base \\(2^{30}\\).\n",
    "\n",
    "#### **Arithmetic Example**:\n",
    "For a number like \\(2^{9999}\\):\n",
    "- In base \\(2^{30}\\), it might be represented as:\n",
    "  \\[\n",
    "  [512, 0, 0, \\ldots, 0]\n",
    "  \\]\n",
    "  (Most elements are zero except for the most significant digit.)\n",
    "\n",
    "#### **Efficient Storage**:\n",
    "- In decimal, \\(2^{9999}\\) would require **3010 digits**.\n",
    "- In base \\(2^{30}\\), it requires only **334 digits**, drastically reducing memory usage.\n",
    "\n",
    "---\n",
    "\n",
    "### **BigNum Operations**\n",
    "#### 1. **Addition**:\n",
    "   - Performed digit by digit, with carry propagation.\n",
    "   - Example:\n",
    "     - Adding \\(123456789\\) and \\(987654321\\) in base \\(10^4\\):\n",
    "       - Represent as arrays: \\([6789, 2345, 1]\\) and \\([4321, 8765, 9]\\).\n",
    "       - Add digits with carry:\n",
    "         \\[\n",
    "         [1110, 1111, 10]\n",
    "         \\]\n",
    "       - Final result: \\([1110, 1111, 10]\\).\n",
    "\n",
    "#### 2. **Multiplication**:\n",
    "   - Uses chunk-based multiplication with carry propagation.\n",
    "   - Optimized using algorithms like **Karatsuba** or **FFT-based multiplication** for very large numbers.\n",
    "\n",
    "#### 3. **Division**:\n",
    "   - Uses long division or modular arithmetic on the array of digits.\n",
    "   - Python supports efficient division, even for extremely large numbers.\n",
    "\n",
    "#### 4. **Exponentiation**:\n",
    "   - Python uses **exponentiation by squaring** for efficient computation.\n",
    "   - For \\(2^{9999}\\), it calculates:\n",
    "     \\[\n",
    "     2^{9999} = ((2^2)^2)^2 \\ldots\n",
    "     \\]\n",
    "     reducing the number of multiplications required.\n",
    "\n",
    "---\n",
    "\n",
    "### **Advantages of BigNum Arithmetic**\n",
    "1. **Arbitrary Size**:\n",
    "   - Numbers can grow as large as available memory allows.\n",
    "2. **Precision**:\n",
    "   - No loss of precision, unlike floating-point arithmetic.\n",
    "3. **Versatility**:\n",
    "   - Supports operations on integers, rationals, and modular arithmetic.\n",
    "\n",
    "---\n",
    "\n",
    "### **Applications of BigNum Arithmetic**\n",
    "1. **Cryptography**:\n",
    "   - Used in RSA encryption and other algorithms that require operations on very large prime numbers.\n",
    "2. **Scientific Computation**:\n",
    "   - Solving problems involving extremely large or small numbers.\n",
    "3. **Financial Systems**:\n",
    "   - Precise calculations involving very large sums or tiny fractional amounts.\n",
    "4. **Number Theory**:\n",
    "   - Calculations involving primes, factorials, or other large integers.\n",
    "\n",
    "---\n",
    "\n",
    "### **BigNum Arithmetic in CPython**\n",
    "Python's BigNum arithmetic is implemented in the CPython interpreter using the C library for arbitrary-precision integers:\n",
    "- It uses **arrays of integers** for storage.\n",
    "- Arithmetic operations are optimized for speed and efficiency.\n",
    "\n",
    "For even faster BigNum operations, Python libraries like **`gmpy2`** leverage the **GNU Multiple Precision Arithmetic Library (GMP)**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "BigNum arithmetic allows Python to handle numbers like \\(2^{9999}\\) effortlessly by representing them as arrays of digits in a large base (e.g., \\(2^{30}\\)). This efficient representation, combined with optimized algorithms for arithmetic operations, ensures that Python can perform calculations on arbitrarily large integers with precision and efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll explain in detail how Python handles large numbers through its BigNum arithmetic implementation.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "# Implementation of a simplified BigNum system to demonstrate the concept\n",
    "\n",
    "class BigNum:\n",
    "    \"\"\"\n",
    "    A simplified implementation of big number arithmetic similar to Python's approach\n",
    "    Using base 2^30 for storage\n",
    "    \"\"\"\n",
    "    BASE = 1 << 30  # 2^30\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        self.digits = []\n",
    "        # Convert the number to base 2^30 representation\n",
    "        while value:\n",
    "            self.digits.append(value % self.BASE)\n",
    "            value //= self.BASE\n",
    "    \n",
    "    def to_decimal(self):\n",
    "        \"\"\"Convert back to decimal representation\"\"\"\n",
    "        result = 0\n",
    "        for i, digit in enumerate(self.digits):\n",
    "            result += digit * (self.BASE ** i)\n",
    "        return result\n",
    "\n",
    "    @classmethod\n",
    "    def demonstrate_storage(cls, number):\n",
    "        \"\"\"Show how a number is stored in base 2^30\"\"\"\n",
    "        bn = BigNum(number)\n",
    "        print(f\"Number: {number}\")\n",
    "        print(f\"Base-2^30 digits: {bn.digits}\")\n",
    "        print(f\"Number of digits needed: {len(bn.digits)}\")\n",
    "        \n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Demonstrate with a smaller number for clarity\n",
    "    number = 2**35  # A number that needs multiple base-2^30 digits\n",
    "    BigNum.demonstrate_storage(number)\n",
    "    \n",
    "    # Calculate space savings\n",
    "    def calculate_storage_comparison(n):\n",
    "        \"\"\"Compare decimal vs base-2^30 storage requirements\"\"\"\n",
    "        decimal_digits = len(str(n))\n",
    "        base_2_30_digits = (n.bit_length() + 29) // 30\n",
    "        return decimal_digits, base_2_30_digits\n",
    "\n",
    "# Example of memory layout for a big number in base 2^30:\n",
    "\"\"\"\n",
    "For number: 2^999\n",
    "Memory layout:\n",
    "[d0, d1, d2, ..., d333]  # 334 elements where:\n",
    "- d0 to d332 are zeros\n",
    "- d333 = 512\n",
    "This represents: 512 * (2^30)^333\n",
    "\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "Let me break down the key concepts of how Python handles large numbers:\n",
    "\n",
    "1. The Fundamental Problem:\n",
    "- Standard computers use fixed-width integers (typically 32 or 64 bits)\n",
    "- This limits the maximum value that can be stored\n",
    "- 64-bit integers can only go up to 2⁶⁴-1\n",
    "- But Python needs to handle much larger numbers like 2⁹⁹⁹⁹\n",
    "\n",
    "2. Python's Solution: Base-2³⁰ Storage\n",
    "- Instead of using base-10 or base-2, Python uses base-2³⁰\n",
    "- Why base-2³⁰?\n",
    "  * It's close to the maximum 32-bit signed integer (2³¹-1)\n",
    "  * Allows for efficient arithmetic operations\n",
    "  * Prevents overflow during intermediate calculations\n",
    "\n",
    "3. Storage Efficiency:\n",
    "- Example with 2⁹⁹⁹:\n",
    "  * In decimal: Needs 3010 digits\n",
    "  * In base-2: Needs 9999 bits\n",
    "  * In base-2³⁰: Needs only 334 elements\n",
    "- Formula for required elements: ⌈n/30⌉ where n is the bit length\n",
    "\n",
    "4. Internal Representation:\n",
    "- Numbers are stored as an array of 30-bit \"digits\"\n",
    "- Each element in the array represents a power of 2³⁰\n",
    "- Example for 2⁹⁹⁹:\n",
    "  * Most elements are 0\n",
    "  * Only the most significant digit is 512\n",
    "  * Can be written as: 512 * (2³⁰)³³³\n",
    "\n",
    "5. Implementation Details:\n",
    "- Handled by CPython interpreter, not CPU\n",
    "- Uses dynamic memory allocation\n",
    "- Automatic conversion between regular and big integers\n",
    "- Operations are implemented in C for efficiency\n",
    "\n",
    "6. Performance Considerations:\n",
    "- Operations are slower than CPU native integers\n",
    "- Memory usage grows with number size\n",
    "- Trade-off between range and performance\n",
    "- Still very efficient compared to naive implementations\n",
    "\n",
    "7. Benefits:\n",
    "- No integer overflow errors\n",
    "- Transparent to the programmer\n",
    "- Automatic handling of conversion\n",
    "- Maintains precision for arbitrary-size integers\n",
    "\n",
    "8. Practical Applications:\n",
    "- Cryptography\n",
    "- Scientific computing\n",
    "- Financial calculations\n",
    "- Any application requiring exact integer arithmetic\n",
    "\n",
    "Would you like me to elaborate on any of these aspects or provide more specific examples of how certain operations work with these big numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me explain BigNum arithmetic in detail, starting with the fundamentals and building up to more complex operations.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "class BigNum:\n",
    "    \"\"\"\n",
    "    A comprehensive implementation of BigNum arithmetic using base 2^30\n",
    "    to demonstrate how Python and other languages handle arbitrary-precision integers\n",
    "    \"\"\"\n",
    "    BASE = 1 << 30  # Using 2^30 as our base for efficient storage\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        self.digits = []\n",
    "        # Handle negative numbers\n",
    "        self.negative = value < 0\n",
    "        value = abs(value)\n",
    "        \n",
    "        # Convert to our base-2^30 representation\n",
    "        while value:\n",
    "            self.digits.append(value % self.BASE)\n",
    "            value //= self.BASE\n",
    "        \n",
    "        if not self.digits:\n",
    "            self.digits = [0]\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        \"\"\"\n",
    "        Addition implementation for BigNum\n",
    "        Simulates how Python performs big integer addition\n",
    "        \"\"\"\n",
    "        if self.negative != other.negative:\n",
    "            # If signs differ, perform subtraction instead\n",
    "            if self.negative:\n",
    "                return -((-self) + other)\n",
    "            else:\n",
    "                return self + (-other)\n",
    "                \n",
    "        result = BigNum(0)\n",
    "        result.digits = []\n",
    "        carry = 0\n",
    "        max_len = max(len(self.digits), len(other.digits))\n",
    "        \n",
    "        # Pad shorter number with zeros\n",
    "        self_digits = self.digits + [0] * (max_len - len(self.digits))\n",
    "        other_digits = other.digits + [0] * (max_len - len(other.digits))\n",
    "        \n",
    "        # Add corresponding digits and handle carry\n",
    "        for i in range(max_len):\n",
    "            current_sum = self_digits[i] + other_digits[i] + carry\n",
    "            result.digits.append(current_sum % self.BASE)\n",
    "            carry = current_sum // self.BASE\n",
    "            \n",
    "        if carry:\n",
    "            result.digits.append(carry)\n",
    "            \n",
    "        result.negative = self.negative\n",
    "        return result\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        \"\"\"\n",
    "        Multiplication implementation for BigNum\n",
    "        Demonstrates the schoolbook multiplication algorithm for large numbers\n",
    "        \"\"\"\n",
    "        if not self.digits or not other.digits:\n",
    "            return BigNum(0)\n",
    "            \n",
    "        # Initialize result with enough space\n",
    "        result = [0] * (len(self.digits) + len(other.digits))\n",
    "        \n",
    "        # Perform digit-by-digit multiplication\n",
    "        for i, digit1 in enumerate(self.digits):\n",
    "            carry = 0\n",
    "            for j, digit2 in enumerate(other.digits):\n",
    "                # Multiply digits and add to existing value\n",
    "                product = digit1 * digit2 + result[i + j] + carry\n",
    "                result[i + j] = product % self.BASE\n",
    "                carry = product // self.BASE\n",
    "            \n",
    "            if carry:\n",
    "                result[i + len(other.digits)] += carry\n",
    "                \n",
    "        # Create new BigNum from result\n",
    "        output = BigNum(0)\n",
    "        output.digits = result\n",
    "        while output.digits and output.digits[-1] == 0:\n",
    "            output.digits.pop()\n",
    "            \n",
    "        output.negative = self.negative != other.negative\n",
    "        return output\n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"Convert BigNum back to decimal string representation\"\"\"\n",
    "        if not self.digits:\n",
    "            return \"0\"\n",
    "            \n",
    "        result = 0\n",
    "        for i, digit in enumerate(self.digits):\n",
    "            result += digit * (self.BASE ** i)\n",
    "            \n",
    "        return f\"{'-' if self.negative else ''}{result}\"\n",
    "\n",
    "# Example usage demonstrating big number operations\n",
    "def demonstrate_bignum_operations():\n",
    "    # Create some big numbers\n",
    "    a = BigNum(2**100)  # A very large number\n",
    "    b = BigNum(2**50)   # Another large number\n",
    "    \n",
    "    # Perform operations\n",
    "    sum_result = a + b\n",
    "    product_result = a * b\n",
    "    \n",
    "    print(f\"a = {a}\")\n",
    "    print(f\"b = {b}\")\n",
    "    print(f\"a + b = {sum_result}\")\n",
    "    print(f\"a * b = {product_result}\")\n",
    "\n",
    "```\n",
    "\n",
    "Let me explain how BigNum arithmetic works, building from basic principles to complex operations:\n",
    "\n",
    "First, let's understand why we need BigNum arithmetic. Regular computer integers are limited by their bit size - a 64-bit integer can only represent numbers up to 2⁶⁴-1. For many applications in cryptography, scientific computing, and mathematical calculations, we need much larger numbers.\n",
    "\n",
    "The fundamental idea behind BigNum arithmetic is to break large numbers into smaller chunks that computers can handle efficiently. Think of it like how we work with large numbers by hand - we process them digit by digit. However, instead of using base-10 digits like we do, BigNum implementations typically use much larger bases to improve efficiency.\n",
    "\n",
    "Here's how the basic operations work:\n",
    "\n",
    "Addition in BigNum systems works similarly to how we add numbers by hand:\n",
    "1. We align the numbers by their least significant digits\n",
    "2. Add corresponding digits along with any carry from the previous addition\n",
    "3. If there's a carry after the last digit, we create a new digit\n",
    "For example, when adding large numbers like 2¹⁰⁰ + 2⁵⁰, we process each 30-bit chunk separately, carrying over any overflow to the next chunk.\n",
    "\n",
    "Multiplication is more complex but follows a similar principle to long multiplication:\n",
    "1. Each digit of the first number is multiplied by each digit of the second number\n",
    "2. The results are shifted based on position and summed\n",
    "3. Carries are propagated through the entire result\n",
    "The process is similar to how we multiply large numbers on paper, but using base-2³⁰ instead of base-10.\n",
    "\n",
    "Some key optimizations that make BigNum arithmetic efficient:\n",
    "1. Choice of base: Using base-2³⁰ allows for efficient operations while avoiding overflow in 32-bit arithmetic\n",
    "2. Memory management: Dynamic allocation of exactly the space needed for each number\n",
    "3. Carry handling: Efficient propagation of carries during operations\n",
    "4. Optimization for special cases: Separate handling of small numbers that fit in machine words\n",
    "\n",
    "The implementation also handles special cases:\n",
    "- Negative numbers require special handling during operations\n",
    "- Leading zeros need to be trimmed to maintain canonical representation\n",
    "- Operations between numbers of different sizes need proper alignment\n",
    "\n",
    "Would you like me to explain any particular aspect in more detail? For example, we could dive deeper into multiplication algorithms, or explore how different bases affect performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number: 34359738368\n",
      "Base-2^30 digits: [0, 32]\n",
      "Number of digits needed: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nFor number: 2^999\\nMemory layout:\\n[d0, d1, d2, ..., d333]  # 334 elements where:\\n- d0 to d332 are zeros\\n- d333 = 512\\nThis represents: 512 * (2^30)^333\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementation of a simplified BigNum system to demonstrate the concept\n",
    "\n",
    "\n",
    "class BigNum:\n",
    "    \"\"\"\n",
    "    A simplified implementation of big number arithmetic similar to Python's approach\n",
    "    Using base 2^30 for storage\n",
    "    \"\"\"\n",
    "\n",
    "    BASE = 1 << 30  # 2^30\n",
    "\n",
    "    def __init__(self, value):\n",
    "        self.digits = []\n",
    "        # Convert the number to base 2^30 representation\n",
    "        while value:\n",
    "            self.digits.append(value % self.BASE)\n",
    "            value //= self.BASE\n",
    "\n",
    "    def to_decimal(self):\n",
    "        \"\"\"Convert back to decimal representation\"\"\"\n",
    "        result = 0\n",
    "        for i, digit in enumerate(self.digits):\n",
    "            result += digit * (self.BASE**i)\n",
    "        return result\n",
    "\n",
    "    @classmethod\n",
    "    def demonstrate_storage(cls, number):\n",
    "        \"\"\"Show how a number is stored in base 2^30\"\"\"\n",
    "        bn = BigNum(number)\n",
    "        print(f\"Number: {number}\")\n",
    "        print(f\"Base-2^30 digits: {bn.digits}\")\n",
    "        print(f\"Number of digits needed: {len(bn.digits)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Demonstrate with a smaller number for clarity\n",
    "    number = 2**35  # A number that needs multiple base-2^30 digits\n",
    "    BigNum.demonstrate_storage(number)\n",
    "\n",
    "    # Calculate space savings\n",
    "    def calculate_storage_comparison(n):\n",
    "        \"\"\"Compare decimal vs base-2^30 storage requirements\"\"\"\n",
    "        decimal_digits = len(str(n))\n",
    "        base_2_30_digits = (n.bit_length() + 29) // 30\n",
    "        return decimal_digits, base_2_30_digits\n",
    "\n",
    "\n",
    "# Example of memory layout for a big number in base 2^30:\n",
    "\"\"\"\n",
    "For number: 2^999\n",
    "Memory layout:\n",
    "[d0, d1, d2, ..., d333]  # 334 elements where:\n",
    "- d0 to d332 are zeros\n",
    "- d333 = 512\n",
    "This represents: 512 * (2^30)^333\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How are floatig point numbers are represented in CPU?\n",
    "\n",
    "deciaml numbers are just numbers  that also invlude negative powers of te base\n",
    "\n",
    "85.612 = 8*10^1 +5 *10^0 + 6*10^-1 + 1 *10^-2 +2 *10^-3\n",
    "\n",
    "The IEEE-754 standard define representation format for floatin gpoint numbers in 32-bit\n",
    "\n",
    "Bascially we divide the 32-bit string into three paers\n",
    "1. first bit(msp) indicates sign : 0 mean positive , 1 means negative\n",
    "\n",
    "2. next 8-bits are exponent which also indicatses magnitude of the number \n",
    "3. the last 23 bits are mantissa/fraction meaning all the digits corrsponding to negative powers of 2.. i.e. decimal part\n",
    "fraction = 1 +1 *2**-2 = 1.25\n",
    "\n",
    "\n",
    "To convert this string into a value, we need to this\n",
    "Value =(-1)^sign * 2^(E-127) * (1+ sum_i=1to23 (b_(23-i)) * 2^(-i) )\n",
    "\n",
    "(+1) X 2^-3 * 1.25 = +0.15625\n",
    "\n",
    "![](quant_03.png)\n",
    "\n",
    "Above representation  is  for 32-bit\n",
    "modern GPUs also support 16-bit floating point nuimber with less precision becauwe we have less bit dedicated to factional part and less  bit dedicated to exponent so we can not have too many digits after decimal point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Floating-point representation is a way to express real numbers (numbers with fractions or decimals) in a computer, using a method that's efficient for storage and computation. Here's an intuitive breakdown with relatable examples:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. The Problem: Why Do We Need Floating Point?**\n",
    "Imagine you're working with very large or very small numbers, like:\n",
    "- The distance to the nearest star: **40,208,000,000,000 km**\n",
    "- The size of a bacteria: **0.0000001 meters**\n",
    "\n",
    "Storing such numbers as regular integers or fixed-point numbers (just the number and its decimal part) would:\n",
    "- Require a lot of memory for large numbers.\n",
    "- Lose precision for very small numbers.\n",
    "\n",
    "Floating-point representation solves this by using **scientific notation**, just like in math.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. The Solution: Scientific Notation**\n",
    "In scientific notation, a number is split into two parts:\n",
    "- **A significant (or mantissa)**: The main digits of the number.\n",
    "- **An exponent**: A power of 10 that tells you where the decimal point goes.\n",
    "\n",
    "For example:\n",
    "- \\( 40208 = 4.0208 \\times 10^4 \\)\n",
    "- \\( 0.0000001 = 1.0 \\times 10^{-7} \\)\n",
    "\n",
    "Computers use a similar idea but with base \\( 2 \\) (binary) instead of base \\( 10 \\).\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Floating-Point Representation in Computers**\n",
    "A floating-point number is typically stored in three parts:\n",
    "1. **Sign bit (S)**: 1 bit to indicate if the number is positive (0) or negative (1).\n",
    "2. **Exponent (E)**: A few bits to store the power of 2 (not 10).\n",
    "3. **Mantissa (M)**: The main digits of the number, normalized to fall between 1 and 2.\n",
    "\n",
    "For example, the number \\( 6.5 \\):\n",
    "- In binary, \\( 6.5 = 110.1 \\).\n",
    "- Normalize it to \\( 1.101 \\times 2^2 \\).\n",
    "- Store:\n",
    "  - Sign: \\( 0 \\) (positive)\n",
    "  - Exponent: \\( 2 + 127 = 129 \\) (using a bias of 127)\n",
    "  - Mantissa: \\( 101 \\) (remaining bits after the leading 1).\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Real-Life Example**\n",
    "Suppose we want to store the number **5.75**:\n",
    "- Convert \\( 5.75 \\) to binary: \\( 101.11 \\).\n",
    "- Normalize: \\( 1.0111 \\times 2^2 \\).\n",
    "- Store:\n",
    "  - Sign: \\( 0 \\) (positive).\n",
    "  - Exponent: \\( 2 + 127 = 129 \\).\n",
    "  - Mantissa: \\( 0111 \\) (remaining bits after the leading 1).\n",
    "\n",
    "In 32-bit floating-point (IEEE 754 format):\n",
    "- \\( S \\): 1 bit (0 for positive).\n",
    "- \\( E \\): 8 bits (129 in binary: \\( 10000001 \\)).\n",
    "- \\( M \\): 23 bits (fill remaining bits with zeros).\n",
    "\n",
    "So, \\( 5.75 \\) in 32-bit floating point looks like:\n",
    "\\[ 0\\ 10000001\\ 01110000000000000000000 \\]\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Key Intuitions**\n",
    "1. **Dynamic Range**: By adjusting the exponent, floating-point numbers can represent both very large and very small values efficiently.\n",
    "   - \\( 1.0 \\times 10^{38} \\): Huge!\n",
    "   - \\( 1.0 \\times 10^{-38} \\): Tiny!\n",
    "\n",
    "2. **Precision vs. Range**: \n",
    "   - Precision is determined by the mantissa.\n",
    "   - Range is determined by the exponent.\n",
    "\n",
    "3. **Why Not Integers?**\n",
    "   - Integers can only represent whole numbers.\n",
    "   - Floating point handles decimals and fractions naturally.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Everyday Example**\n",
    "Imagine a bank needs to store:\n",
    "- \\( \\$123,456.78 \\): Large value.\n",
    "- \\( \\$0.000034 \\): Small value.\n",
    "\n",
    "Using integers:\n",
    "- Would need massive memory for large numbers.\n",
    "- Would lose tiny values (rounded to 0).\n",
    "\n",
    "Floating point efficiently handles both:\n",
    "- \\( 123456.78 = 1.2345678 \\times 10^5 \\)\n",
    "- \\( 0.000034 = 3.4 \\times 10^{-5} \\)\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Limitations**\n",
    "- **Rounding Errors**: Floating-point cannot represent all decimals precisely (e.g., \\( 0.1 \\) in binary is repeating).\n",
    "- **Overflow/Underflow**: Numbers too large/small for the range cannot be represented.\n",
    "\n",
    "Despite these, floating-point representation is a brilliant trade-off between range, precision, and efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me explain how floating-point numbers are represented in computers, building from fundamental concepts to the specific details of the IEEE-754 standard.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "def visualize_float32(binary_string):\n",
    "    \"\"\"\n",
    "    Creates a visual representation of a 32-bit floating point number\n",
    "    Demonstrates how the bits are interpreted according to IEEE-754\n",
    "    \"\"\"\n",
    "    # Parse the binary string into its components\n",
    "    sign_bit = int(binary_string[0])\n",
    "    exponent_bits = int(binary_string[1:9], 2)\n",
    "    mantissa_bits = binary_string[9:]\n",
    "    \n",
    "    # Calculate the actual value\n",
    "    sign = (-1) ** sign_bit\n",
    "    exponent = exponent_bits - 127  # Apply bias\n",
    "    mantissa = 1.0  # Hidden 1\n",
    "    \n",
    "    # Calculate mantissa value\n",
    "    for i, bit in enumerate(mantissa_bits):\n",
    "        if bit == '1':\n",
    "            mantissa += 2 ** -(i + 1)\n",
    "    \n",
    "    value = sign * (2 ** exponent) * mantissa\n",
    "    \n",
    "    # Create formatted output\n",
    "    print(\"IEEE-754 32-bit Floating Point Analysis\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Binary:\", \" \".join([\n",
    "        binary_string[0],           # Sign\n",
    "        binary_string[1:9],         # Exponent\n",
    "        binary_string[9:]           # Mantissa\n",
    "    ]))\n",
    "    print(\"\\nComponents:\")\n",
    "    print(f\"Sign bit:     {sign_bit} ({'negative' if sign_bit else 'positive'})\")\n",
    "    print(f\"Exponent:     {binary_string[1:9]} (decimal: {exponent_bits}, unbiased: {exponent})\")\n",
    "    print(f\"Mantissa:     {mantissa_bits}\")\n",
    "    print(f\"Hidden bit:   1\")\n",
    "    print(f\"\\nCalculated value: {value}\")\n",
    "\n",
    "# Example usage for the number from the image (0.15625)\n",
    "example = \"00111100001000000000000000000000\"\n",
    "visualize_float32(example)\n",
    "\n",
    "```\n",
    "\n",
    "Let me break down how floating-point numbers work in computers, starting from the basics:\n",
    "\n",
    "1. Understanding Decimal Numbers\n",
    "First, let's understand how decimal numbers work in base-10. The number 85.612 can be broken down as:\n",
    "- 8 × 10¹ (80)\n",
    "- 5 × 10⁰ (5)\n",
    "- 6 × 10⁻¹ (0.6)\n",
    "- 1 × 10⁻² (0.01)\n",
    "- 2 × 10⁻³ (0.002)\n",
    "\n",
    "2. IEEE-754 Standard Structure\n",
    "The IEEE-754 standard defines how to represent these numbers in binary using three components:\n",
    "\n",
    "a) Sign Bit (1 bit):\n",
    "   - 0 for positive numbers\n",
    "   - 1 for negative numbers\n",
    "   This allows representation of both positive and negative numbers.\n",
    "\n",
    "b) Exponent (8 bits):\n",
    "   - Stores the power of 2 plus a bias of 127\n",
    "   - Range: -126 to +127 after removing bias\n",
    "   - The bias prevents the need for a sign bit on the exponent\n",
    "   - In the example, 124 - 127 = -3 is the actual exponent\n",
    "\n",
    "c) Mantissa/Fraction (23 bits):\n",
    "   - Represents the fractional part after 1\n",
    "   - Uses an implicit leading 1 (called the \"hidden bit\")\n",
    "   - Each position represents a negative power of 2\n",
    "   - In the example: 1 + 2⁻² = 1.25\n",
    "\n",
    "3. Value Calculation\n",
    "The final value is calculated using the formula:\n",
    "(-1)ˢⁱᵍⁿ × 2⁽ᵉˣᵖᵒⁿᵉⁿᵗ⁻¹²⁷⁾ × (1 + mantissa)\n",
    "\n",
    "In our example:\n",
    "- Sign = 0, so (-1)⁰ = +1\n",
    "- Exponent = 124, so 2¹²⁴⁻¹²⁷ = 2⁻³\n",
    "- Mantissa = 1.25\n",
    "Final value: +1 × 2⁻³ × 1.25 = 0.15625\n",
    "\n",
    "4. Special Cases\n",
    "The IEEE-754 standard also includes special representations for:\n",
    "- Zero (all bits zero except sign)\n",
    "- Infinity (all exponent bits 1, mantissa 0)\n",
    "- NaN (Not a Number: all exponent bits 1, non-zero mantissa)\n",
    "\n",
    "5. Precision Considerations\n",
    "The 32-bit format (called \"single precision\") provides:\n",
    "- ~7 decimal digits of precision\n",
    "- Range from ~1.18×10⁻³⁸ to ~3.4×10³⁸\n",
    "\n",
    "6. Modern Variations (16-bit)\n",
    "Modern GPUs support 16-bit floating point (half precision):\n",
    "- 1 sign bit\n",
    "- 5 exponent bits\n",
    "- 10 mantissa bits\n",
    "This trades precision for memory efficiency and processing speed.\n",
    "\n",
    "Understanding this representation helps explain why floating-point arithmetic sometimes produces unexpected results - not all decimal numbers can be exactly represented in binary floating-point format, leading to small rounding errors in calculations.\n",
    "\n",
    "Would you like me to explain more about any particular aspect, such as how rounding works, or how the 64-bit (double precision) format differs from this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IEEE-754 32-bit Floating Point Analysis\n",
      "--------------------------------------------------\n",
      "Binary: 0 01111000 01000000000000000000000\n",
      "\n",
      "Components:\n",
      "Sign bit:     0 (positive)\n",
      "Exponent:     01111000 (decimal: 120, unbiased: -7)\n",
      "Mantissa:     01000000000000000000000\n",
      "Hidden bit:   1\n",
      "\n",
      "Calculated value: 0.009765625\n"
     ]
    }
   ],
   "source": [
    "def visualize_float32(binary_string):\n",
    "    \"\"\"\n",
    "    Creates a visual representation of a 32-bit floating point number\n",
    "    Demonstrates how the bits are interpreted according to IEEE-754\n",
    "    \"\"\"\n",
    "    # Parse the binary string into its components\n",
    "    sign_bit = int(binary_string[0])\n",
    "    exponent_bits = int(binary_string[1:9], 2)\n",
    "    mantissa_bits = binary_string[9:]\n",
    "\n",
    "    # Calculate the actual value\n",
    "    sign = (-1) ** sign_bit\n",
    "    exponent = exponent_bits - 127  # Apply bias\n",
    "    mantissa = 1.0  # Hidden 1\n",
    "\n",
    "    # Calculate mantissa value\n",
    "    for i, bit in enumerate(mantissa_bits):\n",
    "        if bit == \"1\":\n",
    "            mantissa += 2 ** -(i + 1)\n",
    "\n",
    "    value = sign * (2**exponent) * mantissa\n",
    "\n",
    "    # Create formatted output\n",
    "    print(\"IEEE-754 32-bit Floating Point Analysis\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\n",
    "        \"Binary:\",\n",
    "        \" \".join(\n",
    "            [\n",
    "                binary_string[0],  # Sign\n",
    "                binary_string[1:9],  # Exponent\n",
    "                binary_string[9:],  # Mantissa\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    print(\"\\nComponents:\")\n",
    "    print(f\"Sign bit:     {sign_bit} ({'negative' if sign_bit else 'positive'})\")\n",
    "    print(\n",
    "        f\"Exponent:     {binary_string[1:9]} (decimal: {exponent_bits}, unbiased: {exponent})\"\n",
    "    )\n",
    "    print(f\"Mantissa:     {mantissa_bits}\")\n",
    "    print(f\"Hidden bit:   1\")\n",
    "    print(f\"\\nCalculated value: {value}\")\n",
    "\n",
    "\n",
    "# Example usage for the number from the image (0.15625)\n",
    "example = \"00111100001000000000000000000000\"\n",
    "visualize_float32(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Floating Point Number Representation in the CPU (IEEE 754 Standard)**\n",
    "\n",
    "Floating point numbers are a way of representing real numbers that can accommodate both very large and very small values. These numbers include integers, fractions, and irrational numbers, and can also represent values with both positive and negative exponents.\n",
    "\n",
    "The **IEEE 754 standard** defines the representation of floating point numbers in computers, specifically in binary. The most commonly used formats are:\n",
    "1. **Single precision (32-bit)**\n",
    "2. **Double precision (64-bit)**\n",
    "3. **Half precision (16-bit)**, which is used in modern GPUs for high-performance computing.\n",
    "\n",
    "---\n",
    "\n",
    "### **Understanding the Structure of Floating Point Numbers**\n",
    "\n",
    "Floating point numbers are generally represented as a string of bits, divided into three parts:\n",
    "1. **Sign bit (1 bit)**: Indicates whether the number is positive or negative.\n",
    "2. **Exponent (8 bits in 32-bit, 11 bits in 64-bit)**: Determines the magnitude of the number.\n",
    "3. **Mantissa/Fraction (23 bits in 32-bit, 52 bits in 64-bit)**: Contains the precision of the number.\n",
    "\n",
    "In the **32-bit floating point format (single precision)**:\n",
    "- **1 bit** for the sign\n",
    "- **8 bits** for the exponent\n",
    "- **23 bits** for the mantissa (fraction)\n",
    "\n",
    "This structure allows for the representation of both very large and very small numbers, but with a trade-off in precision. Let’s break this down further.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Sign Bit**\n",
    "- **Sign bit (1 bit)**: The first bit of the 32-bit string is used to represent the sign of the number:\n",
    "  - `0` means the number is **positive**.\n",
    "  - `1` means the number is **negative**.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Exponent (8 bits)**\n",
    "- The **exponent** represents the magnitude of the number and is stored in **biased** form. The bias for a single precision number is **127**, meaning the exponent value is offset by 127.\n",
    "  - The exponent field is an 8-bit number, which means it can represent values from **0 to 255**.\n",
    "  - The actual exponent is calculated as: \n",
    "    \\[\n",
    "    E - 127\n",
    "    \\]\n",
    "    where \\(E\\) is the value stored in the exponent field.\n",
    "\n",
    "- **Exponent Range**: \n",
    "  - The range of exponents in single precision is from \\(-126\\) to \\(+127\\) (since the exponent is biased by 127).\n",
    "  - Special cases: \n",
    "    - If the exponent is all zeros (00000000), the number is considered a **denormalized** number (used for very small numbers).\n",
    "    - If the exponent is all ones (11111111), it is reserved for **infinity** and **NaN** (Not a Number).\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Mantissa (23 bits)**\n",
    "- The **mantissa (or fraction)** represents the significant digits of the number.\n",
    "- In the IEEE 754 standard, floating point numbers are stored in **normalized form**, which means the leading 1 is assumed and not stored. This is called the **hidden bit** or **implicit leading bit**.\n",
    "  - So, for a number like **1.25**, the mantissa in binary would be stored as **0.01** (with the leading 1 assumed).\n",
    "  - The mantissa is represented in base 2 (binary), and the value is computed by summing up the bits (from left to right), each multiplied by a negative power of 2.\n",
    "\n",
    "The value of the mantissa is:\n",
    "\\[\n",
    "1 + \\sum_{i=1}^{23} b_i \\cdot 2^{-i}\n",
    "\\]\n",
    "where \\(b_i\\) is the \\(i^{th}\\) bit in the mantissa.\n",
    "\n",
    "---\n",
    "\n",
    "### **IEEE 754 Representation of a Floating Point Number**\n",
    "The general formula for converting a 32-bit floating point number into its value is:\n",
    "\n",
    "\\[\n",
    "\\text{Value} = (-1)^{\\text{sign}} \\times 2^{(E - 127)} \\times \\left(1 + \\sum_{i=1}^{23} b_i \\cdot 2^{-i}\\right)\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- **sign**: The sign bit (0 or 1)\n",
    "- **E**: The exponent (8 bits)\n",
    "- **b_i**: The bits of the mantissa (23 bits)\n",
    "\n",
    "---\n",
    "\n",
    "### **Example: Converting a Floating Point Number**\n",
    "Let's convert the decimal number **0.15625** to IEEE 754 single precision format.\n",
    "\n",
    "1. **Write 0.15625 in binary**:\n",
    "   - \\(0.15625\\) in binary is **0.00101**.\n",
    "   \n",
    "2. **Normalize the binary number**:\n",
    "   - To normalize it, shift the binary point to the right of the first 1:\n",
    "   \\[\n",
    "   0.00101 = 1.01 \\times 2^{-3}\n",
    "   \\]\n",
    "   \n",
    "3. **Determine the exponent**:\n",
    "   - The exponent is \\(-3\\), so we add the bias (127):\n",
    "   \\[\n",
    "   -3 + 127 = 124\n",
    "   \\]\n",
    "   The exponent in binary is **01111100**.\n",
    "\n",
    "4. **Determine the mantissa**:\n",
    "   - The mantissa is the fractional part after the leading 1:\n",
    "   \\[\n",
    "   1.01 = 1 + 0 \\times 2^{-1} + 1 \\times 2^{-2} + 0 \\times 2^{-3} + 1 \\times 2^{-4} = 1.25\n",
    "   \\]\n",
    "   The mantissa (fractional part) is **01000000000000000000000** (the remaining bits are filled with zeros).\n",
    "\n",
    "5. **Assemble the IEEE 754 representation**:\n",
    "   - **Sign bit**: 0 (positive)\n",
    "   - **Exponent**: 01111100\n",
    "   - **Mantissa**: 01000000000000000000000\n",
    "   \n",
    "   So, the 32-bit IEEE 754 representation of **0.15625** is:\n",
    "   \\[\n",
    "   0 | 01111100 | 01000000000000000000000\n",
    "   \\]\n",
    "\n",
    "---\n",
    "\n",
    "### **Floating Point Precision and Trade-offs**\n",
    "\n",
    "#### **Precision**\n",
    "- **Single precision (32-bit)** can represent about **7 decimal digits** accurately.\n",
    "- **Double precision (64-bit)** can represent about **15 decimal digits** accurately.\n",
    "- **Half precision (16-bit)** is much less precise, typically representing only **3-4 decimal digits**.\n",
    "\n",
    "#### **Range**\n",
    "- Single precision can represent numbers from about \\(10^{-38}\\) to \\(10^{38}\\).\n",
    "- Double precision can represent numbers from about \\(10^{-308}\\) to \\(10^{308}\\).\n",
    "- Half precision has a smaller range but is useful for high-performance applications where precision is less critical.\n",
    "\n",
    "#### **Denormalized Numbers**\n",
    "- Numbers that are too small to be represented normally are stored as **denormalized numbers**, where the exponent is all zeros and the leading 1 is not assumed.\n",
    "\n",
    "---\n",
    "\n",
    "### **Modern GPUs and Half Precision (16-bit)**\n",
    "- Modern GPUs often use **16-bit floating point** numbers for efficiency, particularly in machine learning and graphics applications.\n",
    "- **16-bit floating point** format (half precision) is similar to the 32-bit format but with fewer bits for the exponent and mantissa, resulting in lower precision but faster computations.\n",
    "\n",
    "### **Summary of IEEE 754 Floating Point Representation**\n",
    "- Floating point numbers in the IEEE 754 format are represented using three parts: **sign**, **exponent**, and **mantissa**.\n",
    "- The **sign bit** determines the number's positivity or negativity.\n",
    "- The **exponent** determines the magnitude of the number, with a bias applied to it.\n",
    "- The **mantissa** contains the fractional part of the number, with an implicit leading 1 in normalized numbers.\n",
    "- This format allows for the representation of both very large and very small numbers, with a trade-off between **range** and **precision**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Quantization\n",
    "\n",
    "\n",
    "### how neural networks work:\n",
    "\n",
    "input -> hidden_layer -> hidden_layer -> output     \n",
    "calculate loss by compaaring ground truth and output\n",
    "\n",
    "then we calculate gradient w.r.t each parameter\n",
    "and then we run back propagation to update these parameters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**The nn can be madeup of diffeent layers, for example a linear layer is made up of two matrices called the weright and the bias, whcih are comonly represented using floating-point numbers. Quantization aims to use integer numbers to represent these two matrices, while mantining accuracy of the model.**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Applying Quantization\n",
    "Y = WX + Bias  #for hidden_layer1   \n",
    "\n",
    "\n",
    "we want to make sure all the operations perfoermed here are intger operations becase they are much faster compared to floating point based operations.\n",
    "\n",
    "# then we take the output Y  and we dequantized it and feed it into next layer. and we dequantize it in such a way that next layer won't even know that quantizatiojn happened in pervious layer.. SO we want to it in such a way that model output doesn't changes\n",
    "### SO we want to keep model accuracy but we want to perform all these operation using integers.\n",
    "so we need to find a mapping between floating point numbers and integers and vice versa.\n",
    "we need too find this mapping of floatin gpoint to int that goes both ways and at same way we want to optimize the space occupation of the model inside the RAM/disk and we want to make it faster to do these operations (like using int becaseu computing ints is much faster than computing flaoting points)\n",
    "\n",
    "![](quant_04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIAS is INT32 because product of two 8-bit ints is greater than two 8-bit range so, bias is int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Quantization in Neural Networks\n",
    "\n",
    "Quantization is a technique used in machine learning to optimize neural networks by converting floating-point numbers (used to represent model parameters) into integers. This reduces memory usage, speeds up computation, and lowers energy consumption while aiming to maintain the model's accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "## **How Neural Networks Work**\n",
    "\n",
    "Neural networks process data through layers:\n",
    "\n",
    "1. **Input Layer**: Accepts raw data (e.g., images, text).\n",
    "2. **Hidden Layers**: Extract features and perform computations.\n",
    "3. **Output Layer**: Produces predictions or results.\n",
    "\n",
    "### Workflow:\n",
    "1. Data flows through the layers using the formula:  \n",
    "   `Y = W * X + Bias`  \n",
    "   Here:\n",
    "   - `W` is the weight matrix.\n",
    "   - `X` is the input.\n",
    "   - `Bias` is an additional parameter.\n",
    "2. Compare the output with the ground truth to calculate the error (loss).\n",
    "3. Update the parameters (`W` and `Bias`) using backpropagation to minimize the loss.\n",
    "\n",
    "Neural network parameters (weights and biases) are typically stored as floating-point numbers, which are computationally expensive to process.\n",
    "\n",
    "---\n",
    "\n",
    "## **What is Quantization?**\n",
    "\n",
    "Quantization replaces floating-point numbers with integers to:\n",
    "- **Reduce memory usage**: Integers use fewer bits than floats.\n",
    "- **Speed up computations**: Integer arithmetic is faster than floating-point arithmetic.\n",
    "- **Lower energy consumption**: Integer operations require less computational power.\n",
    "\n",
    "---\n",
    "\n",
    "## **Applying Quantization**\n",
    "\n",
    "### **Forward Pass with Quantized Operations**\n",
    "1. Perform matrix multiplication using integers:  \n",
    "   `Y = W * X + Bias`  \n",
    "   where `W`, `X`, and `Bias` are integers.\n",
    "2. Convert (dequantize) the output `Y` back to floating-point before feeding it into the next layer. This ensures the next layer operates as if no quantization occurred.\n",
    "\n",
    "### **Goal of Quantization**\n",
    "- Perform all computations using integers while preserving model accuracy.\n",
    "- Ensure the final output is indistinguishable from the original floating-point model.\n",
    "\n",
    "---\n",
    "\n",
    "## **Mapping Floating-Point Numbers to Integers**\n",
    "\n",
    "### **Quantization Scale**\n",
    "To quantize a model, map floating-point values to integers:\n",
    "1. Define a **scale** (`S`) to map the range of floating-point numbers to integers.\n",
    "   For example, if the floating-point range is -1.0 to 1.0 and the integer range is -128 to 127 (8-bit integers), calculate the scale as:  \n",
    "   `S = (Max Float - Min Float) / (Max Int - Min Int)`  \n",
    "   In this case:  \n",
    "   `S = (1.0 - (-1.0)) / (127 - (-128)) = 2.0 / 255 ≈ 0.00784`.\n",
    "\n",
    "2. Use the scale to quantize and dequantize:\n",
    "   - Quantize: `Q = round(F / S)`  \n",
    "     (Convert floating-point value `F` to integer `Q`.)\n",
    "   - Dequantize: `F = Q * S`  \n",
    "     (Convert integer `Q` back to floating-point value `F`.)\n",
    "\n",
    "### **Example**\n",
    "- Floating-point value: `0.5`\n",
    "- Scale: `0.00784`\n",
    "- Quantized value: `Q = round(0.5 / 0.00784) = 64`\n",
    "- Dequantized value: `F = 64 * 0.00784 ≈ 0.5`\n",
    "\n",
    "---\n",
    "\n",
    "## **Types of Quantization**\n",
    "\n",
    "1. **Post-Training Quantization**:\n",
    "   - Apply quantization to a pre-trained model.\n",
    "   - Simple and fast, but may slightly reduce accuracy.\n",
    "\n",
    "2. **Quantization-Aware Training (QAT)**:\n",
    "   - Simulate quantization during training.\n",
    "   - Helps the model adapt to quantization, improving accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "## **Advantages of Quantization**\n",
    "\n",
    "1. **Reduced Memory Usage**:  \n",
    "   A 32-bit model can be converted to an 8-bit model, reducing memory usage by 75%.\n",
    "\n",
    "2. **Faster Inference**:  \n",
    "   Integer operations are faster than floating-point operations, especially on hardware optimized for quantization (e.g., GPUs, TPUs).\n",
    "\n",
    "3. **Lower Energy Consumption**:  \n",
    "   Less computation reduces power usage, ideal for edge devices like mobile phones and IoT devices.\n",
    "\n",
    "---\n",
    "\n",
    "## **Challenges in Quantization**\n",
    "\n",
    "1. **Accuracy Loss**:  \n",
    "   Quantization may introduce small errors, especially for models sensitive to precision.\n",
    "\n",
    "2. **Range Handling**:  \n",
    "   Models with large or small weights need careful scaling to prevent loss of information.\n",
    "\n",
    "3. **Hardware Dependency**:  \n",
    "   Efficient quantized operations depend on hardware support.\n",
    "\n",
    "---\n",
    "\n",
    "## **Conclusion**\n",
    "\n",
    "Quantization is a powerful technique to optimize neural networks for deployment, especially in resource-constrained environments. By converting floating-point operations to integer operations, quantization reduces memory usage, speeds up computations, and lowers energy consumption. With methods like Quantization-Aware Training, it is possible to achieve nearly the same accuracy as the original model while reaping the benefits of quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Quantization in Neural Networks\n",
    "\n",
    "Quantization is a technique used in machine learning to optimize the storage and computational efficiency of neural networks by converting floating-point numbers (commonly used to represent model parameters) into integers. This process significantly reduces memory usage and speeds up computations while aiming to maintain the accuracy of the model.\n",
    "\n",
    "---\n",
    "\n",
    "## **How Neural Networks Work**\n",
    "\n",
    "A neural network processes data through a series of layers:\n",
    "1. **Input Layer**: Accepts raw data, such as an image or text.\n",
    "2. **Hidden Layers**: Perform computations to extract features.\n",
    "3. **Output Layer**: Produces predictions or results.\n",
    "\n",
    "The workflow:\n",
    "- **Forward Pass**: Data flows through the layers:\n",
    "  \\[\n",
    "  Y = W \\cdot X + \\text{Bias}\n",
    "  \\]\n",
    "  where \\( W \\) is the weight matrix, \\( X \\) is the input, and Bias is an additional parameter.\n",
    "- **Loss Calculation**: The output is compared with the ground truth to calculate the error.\n",
    "- **Backward Pass (Backpropagation)**: Gradients are calculated for each parameter (weights and biases), and parameters are updated to minimize the loss.\n",
    "\n",
    "---\n",
    "\n",
    "## **Floating-Point Numbers in Neural Networks**\n",
    "\n",
    "Neural network parameters (weights and biases) are typically stored as floating-point numbers:\n",
    "- **Floating-point representation** allows for high precision and a wide range of values, making it ideal for complex calculations.\n",
    "- However, **floating-point operations** are computationally expensive and memory-intensive.\n",
    "\n",
    "For example:\n",
    "- A single weight or bias in 32-bit floating-point format requires **4 bytes** of memory.\n",
    "- A neural network with billions of parameters may require **tens of gigabytes** of memory just for storage.\n",
    "\n",
    "---\n",
    "\n",
    "## **What is Quantization?**\n",
    "\n",
    "Quantization involves converting these floating-point numbers into **integer representations** to:\n",
    "1. **Reduce Memory Usage**: Integers require fewer bits (e.g., 8 bits for an int compared to 32 bits for a float).\n",
    "2. **Speed Up Computations**: Integer arithmetic is faster than floating-point arithmetic.\n",
    "3. **Lower Energy Consumption**: Performing integer operations consumes less power, which is critical for edge devices like mobile phones and IoT devices.\n",
    "\n",
    "---\n",
    "\n",
    "## **Applying Quantization**\n",
    "\n",
    "### **Forward Pass with Quantized Operations**\n",
    "\n",
    "1. **Matrix Multiplication in Quantized Form**:\n",
    "   \\[\n",
    "   Y = W \\cdot X + \\text{Bias}\n",
    "   \\]\n",
    "   In a quantized model:\n",
    "   - \\( W \\), \\( X \\), and \\( \\text{Bias} \\) are stored as integers.\n",
    "   - All operations (multiplication, addition) are performed using integers.\n",
    "\n",
    "2. **Dequantization for the Next Layer**:\n",
    "   - After the computation, the output \\( Y \\) is **dequantized** (converted back to a floating-point representation).\n",
    "   - This ensures the next layer processes data as if no quantization occurred, preserving the model's accuracy.\n",
    "\n",
    "### **Goal of Quantization**\n",
    "- Perform all operations using integers while maintaining the model's accuracy.\n",
    "- The output of the quantized layer should closely match the output of the original floating-point model.\n",
    "\n",
    "---\n",
    "\n",
    "## **Mapping Floating-Point Numbers to Integers**\n",
    "\n",
    "### **Finding the Mapping**\n",
    "To quantize a model, we need to map floating-point values to integers and back:\n",
    "1. **Quantization Scale (\\( S \\))**:\n",
    "   - Defines the range of values for the integers.\n",
    "   - Example: If floating-point values range from -1.0 to 1.0, integers might range from -128 to 127 (for 8-bit signed integers).\n",
    "\n",
    "   The scale \\( S \\) is calculated as:\n",
    "   \\[\n",
    "   S = \\frac{\\text{Max Float} - \\text{Min Float}}{\\text{Max Int} - \\text{Min Int}}\n",
    "   \\]\n",
    "\n",
    "2. **Quantization Formula**:\n",
    "   \\[\n",
    "   Q = \\text{round}\\left(\\frac{F}{S}\\right)\n",
    "   \\]\n",
    "   where \\( Q \\) is the quantized integer, \\( F \\) is the floating-point value, and \\( S \\) is the scale.\n",
    "\n",
    "3. **Dequantization Formula**:\n",
    "   \\[\n",
    "   F = Q \\cdot S\n",
    "   \\]\n",
    "   This converts the integer back to its floating-point approximation.\n",
    "\n",
    "### **Example**\n",
    "- Suppose the floating-point range is \\( -1.0 \\) to \\( 1.0 \\).\n",
    "- Integer range: \\( -128 \\) to \\( 127 \\) (8-bit integers).\n",
    "- Scale: \\( S = \\frac{1.0 - (-1.0)}{127 - (-128)} = \\frac{2.0}{255} \\approx 0.00784 \\).\n",
    "\n",
    "For a floating-point value \\( F = 0.5 \\):\n",
    "- Quantized value: \\( Q = \\text{round}\\left(\\frac{0.5}{0.00784}\\right) = 64 \\).\n",
    "- Dequantized value: \\( F = 64 \\cdot 0.00784 \\approx 0.5 \\).\n",
    "\n",
    "---\n",
    "\n",
    "## **Types of Quantization**\n",
    "\n",
    "1. **Post-Training Quantization**:\n",
    "   - Quantization is applied to a pre-trained floating-point model.\n",
    "   - Simple and fast, but may slightly reduce accuracy.\n",
    "\n",
    "2. **Quantization-Aware Training (QAT)**:\n",
    "   - Quantization is simulated during training.\n",
    "   - The model learns to adapt to quantization, improving accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "## **Advantages of Quantization**\n",
    "\n",
    "1. **Reduced Memory Consumption**:\n",
    "   - A model with 32-bit parameters can be converted to 8-bit, reducing memory usage by \\( 75\\% \\).\n",
    "\n",
    "2. **Faster Inference**:\n",
    "   - Integer operations are significantly faster than floating-point operations, especially on specialized hardware (e.g., GPUs, TPUs).\n",
    "\n",
    "3. **Energy Efficiency**:\n",
    "   - Less computation and smaller memory footprint reduce energy consumption, making quantization ideal for edge devices.\n",
    "\n",
    "---\n",
    "\n",
    "## **Challenges in Quantization**\n",
    "\n",
    "1. **Accuracy Drop**:\n",
    "   - Quantization may introduce errors due to reduced precision, especially in sensitive models like language models.\n",
    "\n",
    "2. **Range Handling**:\n",
    "   - Models with very large or very small weights may require special handling to prevent loss of information.\n",
    "\n",
    "3. **Hardware Support**:\n",
    "   - Quantized operations are hardware-dependent. Not all hardware supports efficient integer arithmetic.\n",
    "\n",
    "---\n",
    "\n",
    "## **Conclusion**\n",
    "Quantization is a powerful technique to optimize neural networks for deployment, especially in resource-constrained environments. By converting floating-point operations to integer operations, quantization reduces memory usage, speeds up computations, and lowers energy consumption while striving to maintain model accuracy. With techniques like Quantization-Aware Training, it is possible to achieve near-floating-point performance even in quantized models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me break down quantization in neural networks and explain how it helps optimize model performance while maintaining accuracy. I'll walk through this step by step to build a complete understanding.\n",
    "\n",
    "First, let's understand the fundamental motivation: Neural networks typically use floating-point numbers (decimals like 0.123, -1.456, etc.) for their calculations. While this gives high precision, it comes with two significant costs:\n",
    "1. Memory usage: Floating-point numbers take up more storage space\n",
    "2. Computation speed: Floating-point arithmetic is slower than integer arithmetic, especially on simpler hardware like mobile devices or IoT sensors\n",
    "\n",
    "This is where quantization comes in - it's a technique to convert these floating-point numbers into integers while preserving the network's ability to make accurate predictions.\n",
    "\n",
    "Let's examine how a neural network operates and where quantization fits in:\n",
    "\n",
    "In a typical neural network layer, we perform this operation:\n",
    "Y = WX + B\n",
    "Where:\n",
    "- X is the input (or \"activation\" from previous layer)\n",
    "- W is the weight matrix\n",
    "- B is the bias\n",
    "- Y is the output\n",
    "\n",
    "The quantization process involves three key steps:\n",
    "\n",
    "1. Quantization of Weights and Biases:\n",
    "- Before inference, we convert the floating-point weights (W) and biases (B) to integers\n",
    "- We need to determine a scale factor that maps the range of floating-point values to integers\n",
    "- For example, if we're using int32, we might map the floating-point range [-1, 1] to integers [-2³¹, 2³¹-1]\n",
    "\n",
    "2. Integer Computation:\n",
    "- During inference, all mathematical operations (multiplication and addition) are performed using integer arithmetic\n",
    "- This is where we get the performance benefit since integer operations are much faster\n",
    "- The formula becomes: Y_int = X_int × W_int + B_int\n",
    "\n",
    "3. Dequantization:\n",
    "- After computing the result, we convert the integer output back to floating-point\n",
    "- This step is crucial because the next layer expects floating-point inputs\n",
    "- The dequantization process uses the same scale factors to recover the approximate floating-point values\n",
    "\n",
    "The clever part is that we design the quantization/dequantization process so that:\n",
    "- The next layer can't \"tell\" that the previous layer was quantized\n",
    "- The overall accuracy of the network remains nearly the same\n",
    "- We get the speed benefits of integer arithmetic\n",
    "- We reduce memory usage since integers typically require less storage\n",
    "\n",
    "Let's look at a concrete example:\n",
    "If we have a weight value of 0.5 and we're using a scale factor of 1000:\n",
    "1. Quantization: 0.5 × 1000 = 500 (stored as integer)\n",
    "2. During computation: multiply and add using this integer value\n",
    "3. Dequantization: 500 ÷ 1000 = 0.5 (back to floating-point)\n",
    "\n",
    "This is a simplified example - in practice, there are more sophisticated techniques for choosing scale factors and handling the full range of values efficiently.\n",
    "\n",
    "A key point about quantization is that it introduces some approximation error (since we're rounding to integers), but neural networks are remarkably robust to these small errors. Through careful choice of quantization parameters, we can often reduce precision to 8-bit integers while maintaining most of the model's accuracy.\n",
    "\n",
    "Would you like me to elaborate on any particular aspect of quantization, such as how to choose optimal scale factors or how to handle edge cases?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a breakdown of memory usage for **data types** and their sizes:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Floating-Point Numbers (4 Bytes)**  \n",
    "- **Size**: 4 bytes (32 bits) for a single-precision floating-point.  \n",
    "- **Why larger than integers or characters?**  \n",
    "  - Floating-point numbers store:\n",
    "    - **Sign bit**: 1 bit to indicate positive or negative.\n",
    "    - **Exponent**: 8 bits to scale the value.\n",
    "    - **Mantissa (fraction)**: 23 bits for precision.\n",
    "  - Example:  \n",
    "    - `3.14159` is represented as a floating-point number in memory using these components.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Integers (1 Byte)**  \n",
    "- **Size**: 1 byte (8 bits) for small integers (e.g., `int8_t` in C).  \n",
    "- Can represent:\n",
    "  - Unsigned: 0 to 255.\n",
    "  - Signed: -128 to 127.\n",
    "- Larger integers (e.g., `int16_t`, `int32_t`) occupy more bytes:\n",
    "  - 16-bit integer: 2 bytes.\n",
    "  - 32-bit integer: 4 bytes.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Characters (1 Byte)**  \n",
    "- **Size**: 1 byte (8 bits).  \n",
    "- Represents a single ASCII character.\n",
    "  - Example: `'A'` = 65 in ASCII.\n",
    "- In extended encoding systems like **UTF-8**, some characters may occupy more than 1 byte (e.g., non-English characters like `é`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Why These Sizes Matter?**\n",
    "1. **Memory Usage**:\n",
    "   - Floating-point numbers (4 bytes) consume more memory than integers (1 byte) or characters (1 byte).\n",
    "   - Example: A list of 1,000,000 floating-point numbers will use 4 MB, while integers of the same size will use only 1 MB.\n",
    "\n",
    "2. **Performance**:\n",
    "   - Smaller data types (e.g., integers, characters) are faster to process because they use fewer CPU cycles.\n",
    "   - Floating-point operations involve complex calculations (e.g., exponent and mantissa), making them slower.\n",
    "\n",
    "3. **Application**:\n",
    "   - Use floating-point numbers for **precision** (e.g., scientific calculations).\n",
    "   - Use integers for **efficiency** (e.g., counting or indexing).\n",
    "   - Use characters for **text representation** (e.g., storing words or symbols).\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary Table**\n",
    "| Data Type        | Size (Bytes) | Example Values           |\n",
    "|-------------------|--------------|--------------------------|\n",
    "| Floating Point    | 4            | 3.14, -0.001, 1.0e10     |\n",
    "| Integer (int8_t)  | 1            | 0, 127, -128             |\n",
    "| Character (char)  | 1            | 'A', 'z', '#'            |\n",
    "\n",
    "Understanding these differences is critical for optimizing memory usage and performance in applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STRING: one byte per character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of bytes a **string** occupies depends on the following factors:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Encoding Used**\n",
    "Strings in programming are stored as sequences of characters, and the encoding determines how many bytes each character takes:\n",
    "- **ASCII Encoding**: Each character takes **1 byte**.\n",
    "  - Example: `\"Hello\"` (5 characters) = **5 bytes**.\n",
    "- **UTF-8 Encoding**: \n",
    "  - **Basic Latin characters** (e.g., English letters): 1 byte per character.\n",
    "  - **Non-Latin characters** (e.g., `é`, `你`): 2–4 bytes per character.\n",
    "  - Example: `\"Hello 😊\"` (5 Latin + 1 emoji) = **5 bytes + 4 bytes** = **9 bytes**.\n",
    "- **UTF-16 Encoding**: Each character takes **2 bytes**, but some characters (e.g., emojis) can take **4 bytes**.\n",
    "- **UTF-32 Encoding**: Each character takes **4 bytes**, regardless of complexity.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Length of the String**\n",
    "The total size of the string is the number of characters multiplied by the number of bytes per character, plus potential extra storage for metadata.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Metadata and Null Terminator**\n",
    "In many programming languages:\n",
    "- A string often includes **metadata** (e.g., length information or memory address).\n",
    "- Strings may end with a **null terminator** (`\\0`), which takes an additional byte in some cases.\n",
    "  - Example in C: `\"Hello\"` (5 characters) = **6 bytes** (5 for characters + 1 for `\\0`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples of String Sizes**\n",
    "| String           | Encoding   | Size (Bytes)      |\n",
    "|-------------------|------------|-------------------|\n",
    "| `\"Hello\"`         | ASCII      | 5                 |\n",
    "| `\"Hello 😊\"`       | UTF-8      | 9 (5 Latin + 4)   |\n",
    "| `\"你好\"`           | UTF-8      | 6 (3 bytes/char)  |\n",
    "| `\"Hello\"`         | UTF-16     | 10 (2 bytes/char) |\n",
    "| `\"😊\"`            | UTF-32     | 4                 |\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Points**\n",
    "- The size of a string depends on its **length**, **content**, and **encoding**.\n",
    "- ASCII strings are lightweight (1 byte/character), while strings with non-Latin characters or emojis can require significantly more memory, especially with encodings like UTF-8 or UTF-16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me help clarify the memory usage of different data types, as this is crucial for understanding the benefits of quantization.\n",
    "\n",
    "Let's break down the standard memory requirements:\n",
    "\n",
    "A single-precision floating-point number (float) actually occupies 4 bytes (32 bits), not 1 byte. It uses these bits to store three components: the sign, exponent, and mantissa, which allow it to represent decimal numbers with high precision.\n",
    "\n",
    "An integer's size can vary depending on its type:\n",
    "- A standard int typically uses 4 bytes (32 bits)\n",
    "- A short int uses 2 bytes (16 bits)\n",
    "- A signed char or uint8 (8-bit integer) uses 1 byte (8 bits)\n",
    "\n",
    "A character (char) indeed uses 1 byte (8 bits), which is enough to represent 256 different values.\n",
    "\n",
    "This is why quantization often converts 32-bit floating-point numbers to 8-bit integers - it reduces memory usage by a factor of 4! For example, if we have a neural network layer with 1 million parameters:\n",
    "- Using floating-point: 1,000,000 × 4 bytes = 4,000,000 bytes (about 4 MB)\n",
    "- Using 8-bit integers: 1,000,000 × 1 byte = 1,000,000 bytes (about 1 MB)\n",
    "\n",
    "This reduction in memory usage is especially important for deploying neural networks on devices with limited memory, like smartphones or embedded systems. The smaller memory footprint also means faster data transfer between memory and processor, which contributes to the overall speed improvement.\n",
    "\n",
    "Would you like me to explain more about how we maintain accuracy while making this dramatic reduction in precision from 32 bits to 8 bits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "symmetric : [-127, 127]\n",
    "Asymmetric: [0, 255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How this works??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "suppose hidden linear layer has a 5*5 matrix, the goal of quantization is to reduce the precision of numbers that we see in this W matrix by mapping it into a range that occupies less bits.\n",
    "\n",
    "***a floating point number occupies 4 bytes(32-bits)***\n",
    "***an integer occupies***\n",
    "\n",
    "So, we will be mapping floating point numbers(that occupy 32-bit each ) in W matrix to a range that occupies less bits like 8-bits.\n",
    "\n",
    "with eight bits we can represent ***[-127, 127]*** range( we can actually represent [-128, 127] but we sacrifiec -128 to obtain a symmetric range)\n",
    "\n",
    "so we map each number in W matrix to its 8-bit representation(QUANTIZATION) in such a way that we can then map back to the original number(DEQUANTIZATION)\n",
    "\n",
    "During Dequantization we shoobtain the original W but we usually loose some precision. so model won't be as accurate as its non-quantized version.\n",
    "So we want to make sure that we loose least accuracy possible.so minimize this loss of precision.\n",
    "\n",
    "![](quant_05.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s break this down and explain quantization in the context of your provided example and diagram.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Goal of Quantization**\n",
    "The purpose of quantization in neural networks is to reduce the memory and computation requirements of the model. This is achieved by:\n",
    "- Mapping **floating-point numbers** (32 bits) to **integers** (8 bits) in a range such as `[-127, 127]`.\n",
    "- Performing computations with integers, which are faster and require less memory.\n",
    "- Minimizing the loss of precision to ensure the model’s accuracy remains close to the original.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Quantization Process**\n",
    "Quantization involves two main steps:\n",
    "1. **Quantizing the weights (or activations)**:\n",
    "   - The original floating-point weights in the matrix `W` are mapped to an 8-bit integer range (`[-127, 127]`).\n",
    "   - This is done by scaling the floating-point numbers to fit within the range.\n",
    "\n",
    "   Formula for Quantization:\n",
    "   \\[\n",
    "   Q = \\text{round}\\left(\\frac{W}{S}\\right)\n",
    "   \\]\n",
    "   Where:\n",
    "   - \\( Q \\) is the quantized integer.\n",
    "   - \\( W \\) is the original floating-point number.\n",
    "   - \\( S \\) is the scale factor that determines how floating-point values are mapped to integers.\n",
    "\n",
    "2. **Dequantizing back to floating-point**:\n",
    "   - After performing computations with the quantized integers, we map them back to floating-point numbers.\n",
    "   - This is done by multiplying the quantized value by the same scale factor \\( S \\).\n",
    "\n",
    "   Formula for Dequantization:\n",
    "   \\[\n",
    "   W' = Q \\times S\n",
    "   \\]\n",
    "   Where:\n",
    "   - \\( W' \\) is the dequantized floating-point number (approximation of \\( W \\)).\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Symmetric Range and Precision**\n",
    "- With 8 bits, integers can represent a range of `[-128, 127]`. However, the range is often restricted to `[-127, 127]` for symmetry.\n",
    "- The sacrifice of one value (`-128`) ensures that the mapping is balanced around zero.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Example Breakdown (5x5 Weight Matrix)**\n",
    "In the diagram:\n",
    "- The original 5x5 weight matrix (`W`) contains floating-point values (e.g., `2484.8`, `-323.89`, etc.).\n",
    "- During quantization:\n",
    "  - These values are scaled and mapped to integers within the range `[-127, 127]`.\n",
    "  - For example:\n",
    "    - `2484.8` might map to `127` (the maximum representable integer).\n",
    "    - `-323.89` might map to `-17`.\n",
    "    - `0` maps directly to `0`.\n",
    "- After computation, the matrix is dequantized back to approximate floating-point values.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Loss of Precision**\n",
    "- During dequantization, the floating-point values are reconstructed, but some precision is lost.\n",
    "  - For instance, `-323.89` was quantized to `-17` and dequantized to `-332.61`.\n",
    "  - The slight difference (`-323.89` vs. `-332.61`) is the quantization error.\n",
    "- This loss in precision can affect the model’s accuracy, but with careful scaling, the impact is minimized.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Benefits of Quantization**\n",
    "1. **Memory Savings**:\n",
    "   - A 5x5 matrix with floating-point weights (32 bits per number) requires \\( 5 \\times 5 \\times 4 = 100 \\) bytes.\n",
    "   - The same matrix with quantized weights (8 bits per number) requires \\( 5 \\times 5 \\times 1 = 25 \\) bytes.\n",
    "   - This is a 75% reduction in memory usage.\n",
    "\n",
    "2. **Faster Computations**:\n",
    "   - Integer operations are significantly faster than floating-point operations, especially on specialized hardware like GPUs or TPUs.\n",
    "\n",
    "3. **Smaller Model Size**:\n",
    "   - Quantized models take up less space on disk, making them ideal for deployment on edge devices.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Key Challenges**\n",
    "- **Balancing Accuracy and Efficiency**:\n",
    "  - The main challenge is to minimize the accuracy loss caused by quantization.\n",
    "- **Choosing the Scale Factor**:\n",
    "  - The scale factor \\( S \\) must be carefully selected to balance the range and precision of the mapping.\n",
    "- **Handling Activation Functions**:\n",
    "  - Nonlinear activations (e.g., ReLU, Sigmoid) need special handling during quantization to ensure correct behavior.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "Quantization is a powerful technique for optimizing neural networks by converting floating-point computations to integer computations. The goal is to achieve significant savings in memory and computation time while keeping the accuracy loss as low as possible. By carefully scaling and mapping the weights, the quantized model can approximate the behavior of the original floating-point model with minimal degradation in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me help explain the quantization process for neural network weights, using the 5x5 matrix example to illustrate the concepts in detail.\n",
    "\n",
    "Let's start with what we see in the original matrix (on the left in the image). These are floating-point numbers like 2484.8, -323.89, etc. Each of these numbers takes up 32 bits (4 bytes) of memory. In a floating-point representation, these bits are divided into:\n",
    "- 1 bit for the sign (positive/negative)\n",
    "- 8 bits for the exponent\n",
    "- 23 bits for the fraction (mantissa)\n",
    "\n",
    "This gives us great precision but uses a lot of memory. For this 5x5 matrix alone, we're using:\n",
    "5 × 5 × 32 bits = 800 bits of memory\n",
    "\n",
    "Now, the goal of quantization is to represent these numbers using just 8 bits each, while maintaining as much of their relative relationships as possible. With 8 bits, we can represent integers from -127 to 127 (we exclude -128 to keep the range symmetric, which makes calculations simpler and more efficient).\n",
    "\n",
    "Let's look at how this mapping works:\n",
    "\n",
    "1. First, we analyze the range of values in our original matrix. In the example, we have values from around -323.89 to 2484.8.\n",
    "\n",
    "2. We then need to find a scale factor that will map these values into our target range of [-127, 127]. This scale factor needs to be carefully chosen because:\n",
    "   - If it's too large, we'll lose smaller differences between numbers\n",
    "   - If it's too small, we'll lose the ability to represent larger values\n",
    "\n",
    "3. Looking at the quantized matrix (middle matrix in the image), we can see how the mapping worked:\n",
    "   - 2484.8 → 127 (maximum value)\n",
    "   - -323.89 → -17\n",
    "   - 0 → 0 (zero stays zero, which is important for preserving network behavior)\n",
    "\n",
    "4. For dequantization (right matrix), we apply the inverse of our scaling to recover values close to the originals:\n",
    "   - 127 → 2484.8\n",
    "   - -17 → -332.61\n",
    "   - 0 → 0\n",
    "\n",
    "Notice how the dequantized values are slightly different from the originals:\n",
    "- Original: -323.89\n",
    "- After quantization and dequantization: -332.61\n",
    "\n",
    "This difference represents the precision loss from quantization. However, neural networks are often robust to these small changes because:\n",
    "- The relative relationships between weights are largely preserved\n",
    "- The network's ability to generalize often isn't dependent on exact decimal precision\n",
    "- The loss in precision is systematic and consistent across the network\n",
    "\n",
    "The memory savings are substantial:\n",
    "- Original: 5 × 5 × 32 bits = 800 bits\n",
    "- Quantized: 5 × 5 × 8 bits = 200 bits\n",
    "\n",
    "That's a 75% reduction in memory usage for this layer! When applied across an entire neural network with millions of parameters, the savings become even more significant.\n",
    "\n",
    "Would you like me to explain more about how we choose the optimal scale factors for quantization, or would you prefer to explore how this process affects the actual computations during forward propagation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asymmetric vs Symmetric Quantization\n",
    "\n",
    "\n",
    "## 1. ***Assymmetric Quantization maps floating point numbers to the range of [0,255]***\n",
    "## 2. ***Symmetric Quantization maps floating point numbers to the range of [-127, 127],, this give advantage that zero  is mapped at 0 in quantized number***\n",
    "![](quant_06.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Asymmetric vs Symmetric Quantization**\n",
    "\n",
    "Quantization is a technique to map floating-point numbers into a reduced range of integers, improving computational efficiency and reducing memory usage in neural networks. Asymmetric and symmetric quantization are two common approaches with distinct characteristics.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Overview of the Two Approaches**\n",
    "\n",
    "#### **Asymmetric Quantization**\n",
    "- **Mapping Range**: Maps floating-point values to an integer range of **[0, 255]** (8-bit unsigned integers).\n",
    "- **Key Characteristic**: Zero in the floating-point range is not necessarily mapped to 0 in the quantized range. Instead, it is mapped to a value dependent on the range of the data and the chosen scale factor.\n",
    "- **Representation**:\n",
    "  - Floating-point range: `[min_value, max_value]`.\n",
    "  - Integer range: `[0, 2^n - 1]` (e.g., `[0, 255]` for 8 bits).\n",
    "  - Quantization involves scaling and shifting.\n",
    "\n",
    "#### **Symmetric Quantization**\n",
    "- **Mapping Range**: Maps floating-point values to an integer range of **[-127, 127]** (8-bit signed integers).\n",
    "- **Key Characteristic**: Zero in the floating-point range is always mapped to 0 in the quantized range, making it symmetric around zero.\n",
    "- **Representation**:\n",
    "  - Floating-point range: `[-max_abs_value, max_abs_value]` (symmetric around zero).\n",
    "  - Integer range: `[-(2^(n-1) - 1), (2^(n-1) - 1)]` (e.g., `[-127, 127]` for 8 bits).\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Differences Between Asymmetric and Symmetric Quantization**\n",
    "\n",
    "| **Aspect**                 | **Asymmetric Quantization**                   | **Symmetric Quantization**                     |\n",
    "|----------------------------|-----------------------------------------------|-----------------------------------------------|\n",
    "| **Integer Range**           | [0, 255]                                     | [-127, 127]                                   |\n",
    "| **Floating-Point Mapping**  | `[min_value, max_value]`                     | `[-max_abs_value, max_abs_value]`             |\n",
    "| **Zero Mapping**            | Zero maps to a non-zero integer (depends on offset). | Zero maps directly to 0 in the quantized range. |\n",
    "| **Complexity**              | Requires scale and offset for mapping.       | Requires only a scale factor for mapping.     |\n",
    "| **Use Case**                | Useful for data with non-zero minimum values (e.g., images with pixel values in [0, 255]). | Preferred when data is symmetric around zero. |\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Visual Explanation (Based on the Diagram)**\n",
    "\n",
    "#### **Asymmetric Quantization**\n",
    "- The floating-point range in the diagram is `[-44.93, 43.31]`.\n",
    "- This range is scaled and shifted to fit into the integer range `[0, 255]`.\n",
    "- Example:\n",
    "  - `-44.93` (minimum) is mapped to `0`.\n",
    "  - `43.31` (maximum) is mapped to `255`.\n",
    "  - The zero point (floating-point 0) is mapped to an integer offset value (e.g., `z` in the diagram).\n",
    "\n",
    "#### **Symmetric Quantization**\n",
    "- The floating-point range in the diagram is also `[-44.93, 43.31]`.\n",
    "- However, it is scaled symmetrically around zero to fit into the integer range `[-127, 127]`.\n",
    "- Example:\n",
    "  - `-44.93` is mapped to `-127`.\n",
    "  - `43.31` is mapped to `127`.\n",
    "  - The zero point (floating-point 0) is directly mapped to integer 0.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Key Benefits and Drawbacks**\n",
    "\n",
    "#### **Asymmetric Quantization**\n",
    "**Benefits**:\n",
    "- Allows for data that is not centered around zero.\n",
    "- Ideal for scenarios where data has a natural non-zero minimum, such as image pixel values (e.g., `[0, 255]`).\n",
    "\n",
    "**Drawbacks**:\n",
    "- Slightly more complex due to the need for both scale and offset.\n",
    "- Zero-point handling introduces additional overhead.\n",
    "\n",
    "#### **Symmetric Quantization**\n",
    "**Benefits**:\n",
    "- Simpler implementation (only requires scaling, no offset).\n",
    "- Zero in floating-point maps directly to zero in integers, simplifying computations in neural networks (e.g., convolution operations).\n",
    "\n",
    "**Drawbacks**:\n",
    "- Inefficient for data that is not symmetric around zero, as part of the integer range may be unused (wasting representation capacity).\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Real-World Applications**\n",
    "\n",
    "#### **Asymmetric Quantization**\n",
    "- Commonly used for **input data preprocessing** in neural networks (e.g., images with pixel values in `[0, 255]`).\n",
    "- Useful when the data has a fixed positive range.\n",
    "\n",
    "#### **Symmetric Quantization**\n",
    "- Preferred for **model weights** and **activations**, which are often symmetric around zero.\n",
    "- Simplifies hardware implementation for neural network inference.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Key Takeaway**\n",
    "The choice between asymmetric and symmetric quantization depends on the characteristics of the data and the application:\n",
    "- Use **asymmetric quantization** for data with non-zero minimums or positive ranges (e.g., image preprocessing).\n",
    "- Use **symmetric quantization** for weights and activations in neural networks, where symmetry around zero simplifies computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me explain the key differences between asymmetric and symmetric quantization, using the example numbers shown in the image to illustrate the concepts.\n",
    "\n",
    "In asymmetric quantization, we map floating-point numbers to the range [0, 255], which uses all positive numbers that can be represented with 8 bits (2⁸ - 1 = 255). Looking at the example in the image:\n",
    "- The original range [-44.93, 43.31] gets mapped to [0, 255]\n",
    "- Negative numbers like -44.93 map to small positive numbers\n",
    "- Zero maps to some middle value (shown as 'z' in the diagram)\n",
    "- Positive numbers map to larger positive numbers\n",
    "\n",
    "### The challenge with asymmetric quantization is that zero in the original numbers maps to some non-zero value in the quantized range. This can cause complications because zero is a special value in neural networks, often used in operations like ReLU activation functions or padding. So we need off set for that\n",
    "\n",
    "In symmetric quantization, we map to the range [-127, 127], sacrificing one value (-128) to maintain symmetry. Looking at the example:\n",
    "- The original range [-44.93, 44.93] maps to [-127, 127]\n",
    "- Zero maps to zero\n",
    "- Negative numbers map to negative numbers\n",
    "- Positive numbers map to positive numbers\n",
    "\n",
    "The key advantage of symmetric quantization is that it preserves the sign of numbers and maps zero to zero. This makes computations more intuitive and helps preserve the network's behavior, especially around zero. For example:\n",
    "- Original: -44.93 → Quantized: -127\n",
    "- Original: 0 → Quantized: 0\n",
    "- Original: 43.31 → Quantized: 122\n",
    "\n",
    "We can see this in action in the bottom rows of the image:\n",
    "- Asymmetric (orange): All numbers are positive (0-255)\n",
    "- Symmetric (green): Numbers maintain their signs (-127 to 127)\n",
    "\n",
    "Let's look at a concrete example from the image:\n",
    "Original number: 38.48\n",
    "- Asymmetric quantization maps it to 241 (positive)\n",
    "- Symmetric quantization maps it to 109 (positive, but using a different scale)\n",
    "\n",
    "This difference becomes important when performing computations. In symmetric quantization, multiplying two numbers preserves the expected sign, making it more natural to work with. The zero-mapping property also means that important neural network operations like zero-padding and activation functions behave more predictably.\n",
    "\n",
    "Would you like me to explain more about how these different mapping schemes affect the actual computations in the neural network, or would you prefer to explore how we choose between symmetric and asymmetric quantization for different types of layers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The challenge with **asymmetric quantization** lies in the mapping of zero from the floating-point range to a non-zero value in the quantized range. Let's dive deeper into why this occurs, why it's problematic, and how the **offset** resolves the issue.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. The Problem with Zero Mapping in Asymmetric Quantization**\n",
    "In **asymmetric quantization**, the floating-point range `[min_value, max_value]` is mapped to the integer range `[0, 255]`. Since the range doesn't necessarily include zero symmetrically, the mapping is not centered around zero. As a result:\n",
    "- **Zero in floating-point space maps to a non-zero value** (e.g., `z` in the diagram) in the quantized range.\n",
    "- This misalignment creates issues because **zero** is a significant value in many neural network operations:\n",
    "  - **ReLU Activation**: Outputs zeros for all negative inputs.\n",
    "  - **Padding**: Zero-padding is commonly used in convolutional layers.\n",
    "  - **Sparse Representations**: Many deep learning optimizations rely on zero values being preserved.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Why Does This Happen?**\n",
    "The quantization process in asymmetric quantization includes both a **scale** and an **offset**:\n",
    "1. **Scale Factor**: Determines how the floating-point range is scaled to fit the integer range.\n",
    "2. **Offset (Zero Point)**: Ensures the integer representation can handle non-zero zero-mappings.\n",
    "\n",
    "For a floating-point value `x`, the quantized value `q` is calculated as:\n",
    "\\[ q = \\text{round}\\left(\\frac{x}{\\text{scale}} + \\text{offset}\\right) \\]\n",
    "\n",
    "- The **offset** is computed so that a specific floating-point value (usually `0`) maps to an integer in the range `[0, 255]`.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Complications Without Proper Offset Handling**\n",
    "If the **offset** is not correctly computed:\n",
    "- Operations that rely on zero (like ReLU or padding) will no longer behave as expected.\n",
    "- During dequantization, converting quantized values back to floating-point may lead to inaccuracies.\n",
    "- Misaligned zero-mapping can propagate errors through the neural network, especially in layers like batch normalization or ReLU.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. How the Offset Resolves This Issue**\n",
    "The **offset** ensures that zero in the floating-point range is correctly mapped to an integer in the quantized range:\n",
    "- By explicitly including the offset, we can adjust the quantized range to preserve the semantics of zero.\n",
    "- # For example, in the diagram, the offset ensures that `0` in floating-point maps to the integer `z` in `[0, 255]`.\n",
    "\n",
    "#### **Example**\n",
    "- Floating-point range: `[-44.93, 43.31]`.\n",
    "- Scale factor: `(max_value - min_value) / (2^n - 1)` = `(43.31 - (-44.93)) / 255`.\n",
    "- Offset: `round(-min_value / scale)` = `round(44.93 / scale)`.\n",
    "\n",
    "This offset aligns the zero in floating-point space to a specific quantized integer value.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Trade-Offs of Using Offset**\n",
    "While the offset solves the zero-mapping problem, it introduces a slight computational overhead:\n",
    "- **Extra Computation**: The need to add or subtract the offset during quantization and dequantization increases complexity.\n",
    "- **Storage Cost**: The offset must be stored alongside the scale factor, slightly increasing the memory footprint.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Why Symmetric Quantization Avoids This Problem**\n",
    "In **symmetric quantization**, the floating-point range is always centered around zero, and zero maps directly to `0` in the integer range:\n",
    "- No offset is required.\n",
    "- Simpler implementation for operations relying on zero values.\n",
    "- However, symmetric quantization is less efficient for data that isn't centered around zero, leading to unused integer values.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "The offset in **asymmetric quantization** is crucial to handle the mismatch between the floating-point zero and the quantized range. While it introduces some overhead, it ensures that critical neural network operations like ReLU, padding, and sparse optimizations behave as expected. However, symmetric quantization offers a simpler alternative when data is centered around zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Asymmetric Quantization\n",
    "It allows to map a series of floating-point numbers in the range [beta, alpha] into another in the range [0, 2^n -1].\n",
    "for example by using 8-bits,  we can represent the floating-point numbers in the range [0, 255]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "suppose we have tensor\n",
    "x_f = [43.31, -44.93 , 0, 22.99, -43.93]\n",
    "\n",
    "to get quantized version, divide each number with `scale s`, then we round up/down to nearest integer and add another number z.\n",
    "x_i  = round(x_f/s) + z\n",
    "\n",
    "\n",
    "x_i = clamp(x_i; 0; 2^n -1) make sures int doesn't exceed range [0, 255] for n =8\n",
    "\n",
    "\n",
    "clamp make sure value is between assigned min max. If values exceeds extreme upper or lower, it is assigned that extreme value.\n",
    "\n",
    "\n",
    "here s = (alpha - beta)/((2**n)-1)    where fp range is [beta, alpha]  and 2 **n-1 is 256 for 8-bits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asymmetric vs Symmetric Quantization\n",
    "\n",
    "\n",
    "1. Assymmetric Quantization maps floating point numbers to the range of [0,255]\n",
    "2. Symmetric Quantization maps floating point numbers to the range of [-127, 127],, this give advantage that zero  is mapped at 0 in quantized number\n",
    "![](quant_06.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=tensor([ 0.7356, -1.0237, -0.1583, -2.5490])\n",
      "torch.clamp(a, min=0.0, max=2)= tensor([0.7356, 0.0000, 0.0000, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn(4)\n",
    "print(f\"{a=}\")\n",
    "print(f\"{torch.clamp(a, min=0.0, max=2)= }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](quant_07.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Asymmetric Quantization: An Overview**\n",
    "\n",
    "Asymmetric quantization maps floating-point numbers within a range `[β, α]` to an integer range `[0, 2^n - 1]`. This is particularly useful for efficient storage and computation on hardware with limited precision, such as 8-bit integer operations. Here's a detailed breakdown of the process using the example you provided:\n",
    "\n",
    "---\n",
    "\n",
    "### **Steps in Asymmetric Quantization**\n",
    "\n",
    "#### **Step 1: Define the Floating-Point Range**\n",
    "- **Input range:** `[β, α]` (e.g., `[−44.93, 43.31]` in this case).\n",
    "- **Quantized range:** `[0, 255]` for 8-bit integers (`n = 8`).\n",
    "\n",
    "#### **Step 2: Compute the Scale Factor (s)**\n",
    "The **scale** factor determines how floating-point values are mapped to the integer range:\n",
    "\\[\n",
    "s = \\frac{\\alpha - \\beta}{(2^n - 1)}\n",
    "\\]\n",
    "For the range `[−44.93, 43.31]` and 8-bit quantization (`n = 8`):\n",
    "\\[\n",
    "s = \\frac{43.31 - (-44.93)}{255} = \\frac{88.24}{255} \\approx 0.346\n",
    "\\]\n",
    "\n",
    "#### **Step 3: Add the Offset (z)**\n",
    "The offset ensures that zero in the floating-point range maps to a corresponding integer value:\n",
    "\\[\n",
    "z = \\text{round}\\left(-\\frac{\\beta}{s}\\right)\n",
    "\\]\n",
    "For this example:\n",
    "\\[\n",
    "z = \\text{round}\\left(-\\frac{-44.93}{0.346}\\right) = \\text{round}(129.86) = 130\n",
    "\\]\n",
    "\n",
    "#### **Step 4: Quantize the Values**\n",
    "For each floating-point value \\( x_f \\), the quantized value \\( x_i \\) is calculated as:\n",
    "\\[\n",
    "x_i = \\text{round}\\left(\\frac{x_f}{s}\\right) + z\n",
    "\\]\n",
    "This maps the floating-point values to integers.\n",
    "\n",
    "#### **Step 5: Apply Clamping**\n",
    "To ensure that the quantized values remain within the target range `[0, 255]`, clamping is applied:\n",
    "\\[\n",
    "x_i = \\text{clamp}(x_i, 0, 255)\n",
    "\\]\n",
    "If \\( x_i \\) exceeds 255, it is set to 255. If it is less than 0, it is set to 0.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example Calculation**\n",
    "Using the tensor \\( x_f = [43.31, -44.93, 0, 22.99, -43.93] \\), the steps are as follows:\n",
    "\n",
    "1. **For \\( x_f = 43.31 \\):**\n",
    "   \\[\n",
    "   x_i = \\text{round}\\left(\\frac{43.31}{0.346}\\right) + 130 = \\text{round}(125.16) + 130 = 255\n",
    "   \\]\n",
    "\n",
    "2. **For \\( x_f = -44.93 \\):**\n",
    "   \\[\n",
    "   x_i = \\text{round}\\left(\\frac{-44.93}{0.346}\\right) + 130 = \\text{round}(-129.86) + 130 = 0\n",
    "   \\]\n",
    "\n",
    "3. **For \\( x_f = 0 \\):**\n",
    "   \\[\n",
    "   x_i = \\text{round}\\left(\\frac{0}{0.346}\\right) + 130 = \\text{round}(0) + 130 = 130\n",
    "   \\]\n",
    "\n",
    "4. **For \\( x_f = 22.99 \\):**\n",
    "   \\[\n",
    "   x_i = \\text{round}\\left(\\frac{22.99}{0.346}\\right) + 130 = \\text{round}(66.43) + 130 = 196\n",
    "   \\]\n",
    "\n",
    "5. **For \\( x_f = -43.93 \\):**\n",
    "   \\[\n",
    "   x_i = \\text{round}\\left(\\frac{-43.93}{0.346}\\right) + 130 = \\text{round}(-126.98) + 130 = 3\n",
    "   \\]\n",
    "\n",
    "---\n",
    "\n",
    "### **Resulting Quantized Values**\n",
    "After applying clamping to ensure values are in the range `[0, 255]`:\n",
    "\\[\n",
    "x_i = [255, 0, 130, 196, 3]\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "### **Clamping**\n",
    "The clamping function ensures that the quantized values do not exceed the boundaries of the integer range. For example:\n",
    "- If \\( x_i = 300 \\), it is clamped to \\( 255 \\).\n",
    "- If \\( x_i = -10 \\), it is clamped to \\( 0 \\).\n",
    "\n",
    "This is crucial for preventing overflow or underflow during hardware computations.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "Asymmetric quantization:\n",
    "1. Maps a floating-point range `[β, α]` to an integer range `[0, 2^n - 1]`.\n",
    "2. Requires a **scale factor (s)** and an **offset (z)**.\n",
    "3. Includes clamping to keep quantized values within bounds.\n",
    "4. Is widely used for efficient computation on low-precision hardware, despite challenges with zero alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Asymmetric Quantization: An Overview**\n",
    "\n",
    "Asymmetric quantization maps floating-point numbers in a range `[β, α]` to an integer range `[0, 2^n - 1]`. This approach is commonly used to compress data for hardware with limited precision, like 8-bit integers.\n",
    "\n",
    "---\n",
    "\n",
    "### **Steps in Asymmetric Quantization**\n",
    "\n",
    "#### **Step 1: Define the Floating-Point Range**\n",
    "- Input range: `[β, α]` (e.g., `[-44.93, 43.31]` in this case).\n",
    "- Quantized range: `[0, 255]` for 8-bit integers (`n = 8`).\n",
    "\n",
    "#### **Step 2: Compute the Scale Factor (s)**\n",
    "The scale factor determines how floating-point values are mapped to the integer range:\n",
    "```\n",
    "s = (α - β) / (2^n - 1) # here we are just calculating fp range and normalizing it by range of  integers 8-bit\n",
    "\n",
    "```\n",
    "For the range `[-44.93, 43.31]` and 8-bit quantization:\n",
    "```\n",
    "s = (43.31 - (-44.93)) / 255\n",
    "s = 88.24 / 255 ≈ 0.346\n",
    "```\n",
    "\n",
    "#### **Step 3: Add the Offset (z)**\n",
    "The offset ensures that zero in the floating-point range maps to an integer value:\n",
    "```\n",
    "z = round(-β / s)\n",
    "```\n",
    "For this example:\n",
    "```\n",
    "z = round(-(-44.93) / 0.346)\n",
    "z = round(129.86) = 130\n",
    "```\n",
    "\n",
    "#### **Step 4: Quantize the Values**\n",
    "For each floating-point value `x_f`, the quantized value `x_i` is calculated as:\n",
    "```\n",
    "x_i = round(x_f / s) + z\n",
    "```\n",
    "This maps the floating-point values to integers.\n",
    "\n",
    "#### **Step 5: Apply Clamping**\n",
    "To ensure the quantized values remain in the target range `[0, 255]`, clamping is applied:\n",
    "```\n",
    "x_i = clamp(x_i, 0, 255)\n",
    "```\n",
    "If `x_i` exceeds 255, it is set to 255. If it is less than 0, it is set to 0.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example Calculation**\n",
    "Using the tensor `x_f = [43.31, -44.93, 0, 22.99, -43.93]`, the steps are as follows:\n",
    "\n",
    "1. **For `x_f = 43.31`:**\n",
    "   ```\n",
    "   x_i = round(43.31 / 0.346) + 130\n",
    "   x_i = round(125.16) + 130 = 255\n",
    "   ```\n",
    "\n",
    "2. **For `x_f = -44.93`:**\n",
    "   ```\n",
    "   x_i = round(-44.93 / 0.346) + 130\n",
    "   x_i = round(-129.86) + 130 = 0\n",
    "   ```\n",
    "\n",
    "3. **For `x_f = 0`:**\n",
    "   ```\n",
    "   x_i = round(0 / 0.346) + 130\n",
    "   x_i = round(0) + 130 = 130\n",
    "   ```\n",
    "\n",
    "4. **For `x_f = 22.99`:**\n",
    "   ```\n",
    "   x_i = round(22.99 / 0.346) + 130\n",
    "   x_i = round(66.43) + 130 = 196\n",
    "   ```\n",
    "\n",
    "5. **For `x_f = -43.93`:**\n",
    "   ```\n",
    "   x_i = round(-43.93 / 0.346) + 130\n",
    "   x_i = round(-126.98) + 130 = 3\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Resulting Quantized Values**\n",
    "After applying clamping to ensure values are in the range `[0, 255]`:\n",
    "```\n",
    "x_i = [255, 0, 130, 196, 3]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Clamping**\n",
    "The clamping function ensures that the quantized values stay within the allowed range. For example:\n",
    "- If `x_i = 300`, it is clamped to `255`.\n",
    "- If `x_i = -10`, it is clamped to `0`.\n",
    "\n",
    "This step is critical to avoid overflows or underflows during hardware computations.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "Asymmetric quantization:\n",
    "1. Maps floating-point numbers in a range `[β, α]` to integers in `[0, 2^n - 1]`.\n",
    "2. Requires a scale factor (`s`) and an offset (`z`).\n",
    "3. Applies clamping to ensure values remain in the valid range.\n",
    "4. Enables efficient computation on low-precision hardware.### **1. Asymmetric Quantization: An Overview**\n",
    "\n",
    "Asymmetric quantization maps floating-point numbers in a range `[β, α]` to an integer range `[0, 2^n - 1]`. This approach is commonly used to compress data for hardware with limited precision, like 8-bit integers.\n",
    "\n",
    "---\n",
    "\n",
    "### **Steps in Asymmetric Quantization**\n",
    "\n",
    "#### **Step 1: Define the Floating-Point Range**\n",
    "- Input range: `[β, α]` (e.g., `[-44.93, 43.31]` in this case).\n",
    "- Quantized range: `[0, 255]` for 8-bit integers (`n = 8`).\n",
    "\n",
    "#### **Step 2: Compute the Scale Factor (s)**\n",
    "The scale factor determines how floating-point values are mapped to the integer range:\n",
    "```\n",
    "s = (α - β) / (2^n - 1)  \n",
    "```\n",
    "For the range `[-44.93, 43.31]` and 8-bit quantization:\n",
    "```\n",
    "s = (43.31 - (-44.93)) / 255\n",
    "s = 88.24 / 255 ≈ 0.346\n",
    "```\n",
    "\n",
    "#### **Step 3: Add the Offset (z)**\n",
    "The offset ensures that zero in the floating-point range maps to an integer value:\n",
    "```\n",
    "z = round(-β / s)\n",
    "```\n",
    "For this example:\n",
    "```\n",
    "z = round(-(-44.93) / 0.346)\n",
    "z = round(129.86) = 130\n",
    "```\n",
    "\n",
    "#### **Step 4: Quantize the Values**\n",
    "For each floating-point value `x_f`, the quantized value `x_i` is calculated as:\n",
    "```\n",
    "x_i = round(x_f / s) + z\n",
    "```\n",
    "This maps the floating-point values to integers.\n",
    "\n",
    "#### **Step 5: Apply Clamping**\n",
    "To ensure the quantized values remain in the target range `[0, 255]`, clamping is applied:\n",
    "```\n",
    "x_i = clamp(x_i, 0, 255)\n",
    "```\n",
    "If `x_i` exceeds 255, it is set to 255. If it is less than 0, it is set to 0.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example Calculation**\n",
    "Using the tensor `x_f = [43.31, -44.93, 0, 22.99, -43.93]`, the steps are as follows:\n",
    "\n",
    "1. **For `x_f = 43.31`:**\n",
    "   ```\n",
    "   x_i = round(43.31 / 0.346) + 130\n",
    "   x_i = round(125.16) + 130 = 255\n",
    "   ```\n",
    "\n",
    "2. **For `x_f = -44.93`:**\n",
    "   ```\n",
    "   x_i = round(-44.93 / 0.346) + 130\n",
    "   x_i = round(-129.86) + 130 = 0\n",
    "   ```\n",
    "\n",
    "3. **For `x_f = 0`:**\n",
    "   ```\n",
    "   x_i = round(0 / 0.346) + 130\n",
    "   x_i = round(0) + 130 = 130\n",
    "   ```\n",
    "\n",
    "4. **For `x_f = 22.99`:**\n",
    "   ```\n",
    "   x_i = round(22.99 / 0.346) + 130\n",
    "   x_i = round(66.43) + 130 = 196\n",
    "   ```\n",
    "\n",
    "5. **For `x_f = -43.93`:**\n",
    "   ```\n",
    "   x_i = round(-43.93 / 0.346) + 130\n",
    "   x_i = round(-126.98) + 130 = 3\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Resulting Quantized Values**\n",
    "After applying clamping to ensure values are in the range `[0, 255]`:\n",
    "```\n",
    "x_i = [255, 0, 130, 196, 3]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Clamping**\n",
    "The clamping function ensures that the quantized values stay within the allowed range. For example:\n",
    "- If `x_i = 300`, it is clamped to `255`.\n",
    "- If `x_i = -10`, it is clamped to `0`.\n",
    "\n",
    "This step is critical to avoid overflows or underflows during hardware computations.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "Asymmetric quantization:\n",
    "1. Maps floating-point numbers in a range `[β, α]` to integers in `[0, 2^n - 1]`.\n",
    "2. Requires a scale factor (`s`) and an offset (`z`).\n",
    "3. Applies clamping to ensure values remain in the valid range.\n",
    "4. Enables efficient computation on low-precision hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![](quant_07.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# here we are just calculating fp range and normalizing it by range of  integers 8-bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exactly! In **asymmetric quantization**, the key idea is to normalize the floating-point range `[β, α]` into the integer range `[0, 2^n - 1]` (for 8-bit, `[0, 255]`). The process involves calculating a **scale factor** to handle the floating-point range and an **offset** to map the values correctly.\n",
    "\n",
    "Here’s a simplified breakdown:\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 1: Calculate Floating-Point Range**\n",
    "- **Input range**: `[β, α]`\n",
    "  - Example: For `x_f = [43.31, -44.93, 0, 22.99, -43.93]`, the range is `[-44.93, 43.31]`.\n",
    "\n",
    "- **Quantized range**: `[0, 255]` (for 8-bit integers).\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2: Normalize the Floating-Point Range**\n",
    "To map the floating-point values to integers, normalize by the range of integers.  \n",
    "The **scale factor** `s` determines how much the floating-point range is \"stretched\" or \"compressed\":\n",
    "```\n",
    "s = (α - β) / (2^n - 1)\n",
    "```\n",
    "For this example:\n",
    "```\n",
    "s = (43.31 - (-44.93)) / 255\n",
    "s = 88.24 / 255 ≈ 0.346\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3: Add an Offset**\n",
    "To handle negative values and ensure that `0` in the floating-point range is mapped correctly, an offset `z` is calculated:\n",
    "```\n",
    "z = round(-β / s)\n",
    "```\n",
    "For `β = -44.93`:\n",
    "```\n",
    "z = round(-(-44.93) / 0.346)\n",
    "z = round(129.86) = 130\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 4: Quantize the Values**\n",
    "Each floating-point value is quantized by dividing by the scale `s` and adding the offset `z`:\n",
    "```\n",
    "x_i = round(x_f / s) + z\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 5: Clamp the Values**\n",
    "To ensure the quantized values fit within the integer range `[0, 255]`, apply clamping:\n",
    "```\n",
    "x_i = clamp(x_i, 0, 255)\n",
    "```\n",
    "This ensures:\n",
    "- If `x_i > 255`, it becomes `255`.\n",
    "- If `x_i < 0`, it becomes `0`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Normalized Example**\n",
    "Given `x_f = [43.31, -44.93, 0, 22.99, -43.93]`:\n",
    "1. Calculate the **scale**: `s ≈ 0.346`.\n",
    "2. Calculate the **offset**: `z = 130`.\n",
    "\n",
    "Quantized values:\n",
    "- For `43.31`:  \n",
    "  ```\n",
    "  x_i = round(43.31 / 0.346) + 130 = round(125.16) + 130 = 255\n",
    "  ```\n",
    "- For `-44.93`:  \n",
    "  ```\n",
    "  x_i = round(-44.93 / 0.346) + 130 = round(-129.86) + 130 = 0\n",
    "  ```\n",
    "- For `0`:  \n",
    "  ```\n",
    "  x_i = round(0 / 0.346) + 130 = 130\n",
    "  ```\n",
    "- For `22.99`:  \n",
    "  ```\n",
    "  x_i = round(22.99 / 0.346) + 130 = round(66.43) + 130 = 196\n",
    "  ```\n",
    "- For `-43.93`:  \n",
    "  ```\n",
    "  x_i = round(-43.93 / 0.346) + 130 = round(-126.98) + 130 = 3\n",
    "  ```\n",
    "\n",
    "Final quantized tensor:\n",
    "```\n",
    "x_i = [255, 0, 130, 196, 3]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "By normalizing the floating-point range `[β, α]` using the scale `s` and offset `z`, asymmetric quantization ensures the floating-point numbers are efficiently mapped to integers in `[0, 255]`. Clamping ensures that no value exceeds the target integer range. This method simplifies computations on hardware with limited precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find zero, we are just scaling min and then subtracting(as an offset) that to get zero ie.  subtracting number from minimum number would result in 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for finding offset , we are just scaling starting of fp range but why to multiply it by -1??\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me explain why we multiply by -1 when finding the offset (zero-point) in asymmetric quantization, as it's a subtle but important detail.\n",
    "\n",
    "The formula for finding the zero-point is:\n",
    "z = round(-β/s)\n",
    "where β is the minimum value in our floating-point range and s is our scale factor.\n",
    "\n",
    "Let's think about why this makes sense:\n",
    "\n",
    "1. First, remember that β is our minimum floating-point value (-44.93 in our example). We want to map this minimum value to 0 in our quantized range.\n",
    "\n",
    "2. When we quantize a number, we use: x_i = round(x_f/s) + z\n",
    "\n",
    "3. So for our minimum value β, we want:\n",
    "   0 = round(β/s) + z\n",
    "\n",
    "4. Solving for z:\n",
    "   z = -round(β/s)\n",
    "   \n",
    "The negative sign appears because we're trying to \"cancel out\" or \"offset\" the minimum value. Think of it like this: if you have a number line starting at -44.93, and you want to shift it so it starts at 0, you need to add +44.93 to everything. That's why we need the negative sign - to convert our \"starting point\" into an \"offset.\"\n",
    "\n",
    "Here's a concrete example:\n",
    "- β = -44.93\n",
    "- s = 0.346\n",
    "- z = round(-(-44.93)/0.346)\n",
    "- z = round(44.93/0.346)\n",
    "- z = round(129.86)\n",
    "- z = 130\n",
    "\n",
    "This zero-point of 130 means that when we quantize our original zero, it will map to 130 in our quantized range, placing it appropriately between our minimum and maximum values.\n",
    "\n",
    "Would you like me to demonstrate how this offset affects the actual quantization of some numbers from our example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great question! Let’s clarify why we multiply by `-1` when calculating the offset `z`.\n",
    "\n",
    "### **Why Multiply by -1?**\n",
    "The offset `z` is calculated as:\n",
    "\n",
    "```text\n",
    "z = round(-β / s)\n",
    "```\n",
    "\n",
    "This multiplication by `-1` (the negative sign) ensures that the **starting point of the floating-point range** (`β`) is correctly aligned with `0` in the quantized range. Let’s break this down step by step:\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Idea**\n",
    "- In asymmetric quantization, the floating-point range `[β, α]` needs to be mapped to `[0, 2^n - 1]`.\n",
    "- The starting point of the quantized range is `0`, while the starting point of the floating-point range is `β` (which could be negative).\n",
    "- To map `β` to `0` in the quantized range, we calculate how far `β` is from `0` in terms of the quantization scale `s`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Mathematical Intuition**\n",
    "1. The quantized value is calculated as:\n",
    "   ```text\n",
    "   x_i = round(x_f / s) + z\n",
    "   ```\n",
    "   For the starting point `x_f = β`:\n",
    "   ```text\n",
    "   x_i = round(β / s) + z\n",
    "   ```\n",
    "\n",
    "2. Since `x_i` for `β` should be `0` in the quantized range:\n",
    "   ```text\n",
    "   0 = round(β / s) + z\n",
    "   ```\n",
    "\n",
    "3. Rearranging to find `z`:\n",
    "   ```text\n",
    "   z = -round(β / s)\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Use `-β`?**\n",
    "The negative sign in `z = -β / s` essentially \"shifts\" the floating-point range so that `β` aligns with `0`. Without this, the mapping would not work correctly, and `β` would not map to the start of the quantized range.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example**\n",
    "Suppose:\n",
    "- Floating-point range: `[β, α] = [-44.93, 43.31]`\n",
    "- Scale: `s = (α - β) / (2^n - 1) = 0.346`\n",
    "\n",
    "To calculate the offset:\n",
    "```text\n",
    "z = round(-β / s)\n",
    "z = round(-(-44.93) / 0.346)\n",
    "z = round(44.93 / 0.346)\n",
    "z = round(129.86)\n",
    "z = 130\n",
    "```\n",
    "\n",
    "This means the floating-point value `β = -44.93` is now aligned with `0` in the quantized range.\n",
    "\n",
    "---\n",
    "\n",
    "### **What If We Didn’t Multiply by -1?**\n",
    "If we didn’t use `-β` and instead just used `β` directly, the offset would shift the values in the wrong direction. For example:\n",
    "```text\n",
    "z = round(β / s) = round(-44.93 / 0.346) = -130\n",
    "```\n",
    "This would incorrectly map `β` to `-130` in the quantized range, which is invalid because quantized values must lie in `[0, 255]`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "The `-1` is necessary because we are **shifting the floating-point range so that its start (`β`) aligns with `0` in the quantized range**. Without this, the mapping would break, and the quantization process would produce incorrect results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the uniform quantization, an important factor is the choice of the scaling factor S: S= (𝛽−𝛼)/(2^b-1), where [𝛼, 𝛽] denotes the clipping range and b is the quantization bit length. The process of choosing the clipping range is often referred to as calibration. There are two options when we choose the clipping range: symmetric and asymmetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dequantized\n",
    "back to floating point number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### s_f = s(x_i -z )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](quant_08.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Symmetric Quantization\n",
    "\n",
    "it allows to map a series of floating point numbers in the range [-alpha, alpha] into the range of \n",
    "[-(2**(n-1) -1), 2**(n-1) -1]\n",
    "\n",
    "for exapme by using 8-bits, we can represent the floating point numbes in the range [-127, 127]\n",
    "\n",
    "\n",
    "x_q = clamp(round(x_f/s)) where s = abs(alpha)/2^(n-1)-1\n",
    "where alpha is biggest number here\n",
    "\n",
    "for symmetric quantization if we use same scaling way as in asymmetric it will still give this formula\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me explain why the scale factor formula works similarly for symmetric quantization, as it's a fascinating consequence of the symmetry around zero.\n",
    "\n",
    "In symmetric quantization, we're mapping to the range [-127, 127] instead of [0, 255], but the scale factor calculation remains remarkably similar. Let's understand why.\n",
    "\n",
    "Consider our floating-point range [-44.93, 44.93]. Notice how it's symmetric around zero - the magnitude of the minimum and maximum are the same. This is what we mean by symmetric quantization.\n",
    "\n",
    "For the scale factor calculation:\n",
    "s = (α - β)/(2ⁿ-1)\n",
    "\n",
    "In our symmetric case:\n",
    "- α = 44.93\n",
    "- β = -44.93\n",
    "- Total range = 44.93 - (-44.93) = 89.86\n",
    "\n",
    "For 8-bit symmetric quantization:\n",
    "- Range = 127 - (-127) = 254\n",
    "\n",
    "So our scale factor becomes:\n",
    "s = 89.86/254 ≈ 0.354\n",
    "\n",
    "This scale factor works because the proportions stay the same - we're still just mapping one range to another. The key difference is that in symmetric quantization:\n",
    "1. Zero maps to zero (no offset needed!)\n",
    "2. Negative numbers map to negative numbers\n",
    "3. Positive numbers map to positive numbers\n",
    "\n",
    "This natural alignment with zero is why symmetric quantization is often preferred - it preserves the sign of numbers and makes computations more intuitive. Think of it like having a number line that we're just stretching or compressing, but keeping it centered at zero.\n",
    "\n",
    "Would you like me to demonstrate how this same scale factor successfully maps our numbers while maintaining symmetry around zero?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're absolutely right! For **symmetric quantization**, the formula for calculating the scaling factor `s` ends up being the same as in asymmetric quantization because the range is symmetric around zero. Let's break this down step by step to understand why.\n",
    "\n",
    "---\n",
    "\n",
    "### **Scaling Factor Formula in Symmetric Quantization**\n",
    "The scaling factor `s` is given by:\n",
    "```text\n",
    "s = (α - β) / (2^n - 1)\n",
    "```\n",
    "Where:\n",
    "- `[β, α]` is the floating-point range.\n",
    "- `(2^n - 1)` is the number of possible quantization levels for an `n`-bit representation.\n",
    "\n",
    "In symmetric quantization:\n",
    "- The range is **centered around zero**.\n",
    "- Thus, the range is symmetric, and we can write:\n",
    "  ```text\n",
    "  β = -α\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Substitute Symmetric Range into the Formula**\n",
    "In symmetric quantization, the floating-point range is `[−α, +α]`. Substituting `β = -α` into the formula for `s`:\n",
    "```text\n",
    "s = (α - (-α)) / (2^n - 1)\n",
    "s = (α + α) / (2^n - 1)\n",
    "s = 2α / (2^n - 1)\n",
    "```\n",
    "\n",
    "This is the scaling factor formula for symmetric quantization. Notice that the calculation of `s` works the same way as in asymmetric quantization because the range `[−α, +α]` is inherently symmetric around zero.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why It Works**\n",
    "In symmetric quantization:\n",
    "1. **Zero maps to zero**: Since the range is symmetric, the quantized value `0` corresponds to the floating-point value `0`. No offset `z` is needed.\n",
    "2. The range `[−α, +α]` directly maps to `[-(2^(n-1) - 1), +(2^(n-1) - 1)]` for `n`-bit integers (e.g., `[-127, 127]` for 8-bit quantization).\n",
    "\n",
    "The formula for `s` ensures that the largest floating-point value `+α` maps to the maximum positive quantized value, and `−α` maps to the maximum negative quantized value.\n",
    "\n",
    "---\n",
    "\n",
    "### **Comparison with Asymmetric Quantization**\n",
    "In asymmetric quantization:\n",
    "- The range `[β, α]` is **not centered around zero**. For example, `[−44.93, 43.31]`.\n",
    "- An offset `z` is required to shift the range so that the starting point `β` maps to `0`.\n",
    "\n",
    "In symmetric quantization:\n",
    "- The range `[−α, +α]` is **centered around zero**, so no offset `z` is needed.\n",
    "- The scaling factor `s` formula works naturally without requiring adjustments for offsets.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example**\n",
    "Suppose:\n",
    "- Floating-point range: `[−43.31, +43.31]`\n",
    "- Quantization levels: 8-bit, so `(2^n - 1) = 255`.\n",
    "\n",
    "For symmetric quantization:\n",
    "```text\n",
    "s = 2α / (2^n - 1)\n",
    "s = 2(43.31) / 255\n",
    "s = 86.62 / 255\n",
    "s ≈ 0.34\n",
    "```\n",
    "\n",
    "Here, `s` ensures that the floating-point range `[−43.31, +43.31]` maps directly to `[-127, +127]` without needing an offset.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "The formula for calculating `s` remains consistent in both asymmetric and symmetric quantization. However, in symmetric quantization, the inherent symmetry of the range eliminates the need for an offset, making the process simpler and more aligned with zero-based mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for dequantization\n",
    "\n",
    "s_f = s * x_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](quant_09.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max = params[0]=145.05476412551317\n",
      "min = params[1]=-40.96722476901697\n",
      "zero = params[2]=0.0\n",
      "params=array([145.05, -40.97,   0.  ,  16.03,  94.48, 109.81, 121.06,  51.63,\n",
      "        41.44,   7.11, -22.32,  80.45, 140.38, 100.28,  79.33,  88.21,\n",
      "         1.88,  25.55, 144.05, -39.97])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# suppress scientific notation\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "\n",
    "# Generate randomly distributed parameters\n",
    "params = np.random.uniform(low=-50, high=150, size=20)\n",
    "\n",
    "\n",
    "# make sure important values are at the begining for better debuggin\n",
    "\n",
    "params[0] = params.max() + 1  # modified it so that first number isbiggest one\n",
    "\n",
    "print(f\"max = {params[0]=}\")\n",
    "params[1] = params.min() - 1  # second number is smallest number\n",
    "print(f\"min = {params[1]=}\")\n",
    "params[2] = (\n",
    "    0  # third number is zero ,  so we can check the effect on biggest, smallest  and zero\n",
    ")\n",
    "print(f\"zero = {params[2]=}\")\n",
    "\n",
    "\n",
    "# round each  number to the second decimal place\n",
    "\n",
    "params = np.round(params, 2)\n",
    "\n",
    "\n",
    "print(f\"{params=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define the quantization methods and quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10,   0, 100,  50])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clamp(params_q: np.array, lower_bound: int, upper_bound: int) -> np.array:\n",
    "    # print(f\"{params_q> upper_bound=}\")\n",
    "    params_q[params_q < lower_bound] = lower_bound\n",
    "    params_q[params_q > upper_bound] = upper_bound\n",
    "    return params_q\n",
    "\n",
    "\n",
    "params_q = np.array([10, -5, 300, 50])\n",
    "clamp(params_q, lower_bound=0, upper_bound=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10., -25.,  30.,  50.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def asymmetric_quantization(params: np.array, bits: int) -> tuple[np.array, float, int]:\n",
    "    # [ 0, 255]\n",
    "    # calculate the scale and zero point\n",
    "\n",
    "    # findin range of floating points\n",
    "    # [ beta, alpha]\n",
    "    alpha = np.max(params)\n",
    "    beta = np.min(params)\n",
    "\n",
    "    scale = (alpha - beta) / (2**bits - 1)\n",
    "    zero = -1 * np.round(beta / scale)\n",
    "    lower_bound, upper_bound = 0, 2**bits - 1\n",
    "\n",
    "    # Quantize the paramets\n",
    "    quantized = clamp(\n",
    "        np.round((params / scale) + zero), lower_bound, upper_bound\n",
    "    ).astype(np.int32)\n",
    "    return quantized, scale, zero\n",
    "\n",
    "\n",
    "def asymmetric_dequantize(params_q: np.array, scale: float, zero: int) -> np.array:\n",
    "    return (params_q - zero) * scale\n",
    "\n",
    "\n",
    "params_in = np.array([10, -25, 30, 50])\n",
    "\n",
    "params_q, scale, zero = asymmetric_quantization(params_in, 8)\n",
    "asymmetric_dequantize(params_q, scale, zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1, -4,  4,  7], dtype=int32), 7.142857142857143)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def symmetric_quantization(params: np.array, bits: int) -> tuple[np.array, float, int]:\n",
    "    alpha = np.max(np.abs(params))\n",
    "\n",
    "    scale = alpha / (2 ** (bits - 1) - 1)\n",
    "    lower_bound, upper_bound = -(2 ** (bits - 1)), 2 ** (bits - 1) - 1\n",
    "\n",
    "    # Quantize the paramets\n",
    "    quantized = clamp(np.round(params / scale), lower_bound, upper_bound).astype(\n",
    "        np.int32\n",
    "    )\n",
    "    return quantized, scale\n",
    "\n",
    "\n",
    "params_q = np.array([10, -25, 30, 50])\n",
    "\n",
    "sqs, s = symmetric_quantization(params_q, 4)\n",
    "sqs, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.14285714, -28.57142857,  28.57142857,  50.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def symmetric_dequantize(params_q: np.array, scale: float) -> np.array:\n",
    "    return params_q * scale\n",
    "\n",
    "\n",
    "symmetric_dequantize(sqs, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantization_error(params: np.array, params_q: np.array):\n",
    "    # calculate the MSE\n",
    "    return np.mean((params - params_q) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[147.92 -49.33   0.   -32.32 146.92 -28.04  74.75 -40.69 122.9  -32.88\n",
      " 141.22  -1.68  78.55 -15.88 -28.64 106.9   42.73 -11.74 115.83  86.3 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Suppress scientific notation\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Generate randomly distributed parameters\n",
    "params = np.random.uniform(low=-50, high=150, size=20)\n",
    "\n",
    "# Make sure important values are at the beginning for better debugging\n",
    "params[0] = params.max() + 1\n",
    "params[1] = params.min() - 1\n",
    "params[2] = 0\n",
    "\n",
    "# Round each number to the second decimal place\n",
    "params = np.round(params, 2)\n",
    "\n",
    "# Print the parameters\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "[147.92 -49.33   0.   -32.32 146.92 -28.04  74.75 -40.69 122.9  -32.88\n",
      " 141.22  -1.68  78.55 -15.88 -28.64 106.9   42.73 -11.74 115.83  86.3 ]\n",
      "\n",
      "Asymmetric scale: 0.7735294117647059, zero: 64.0\n",
      "[255   0  64  22 254  28 161  11 223  21 247  62 166  43  27 202 119  49\n",
      " 214 176]\n",
      "\n",
      "Symmetric scale: 1.1647244094488187\n",
      "[127 -42   0 -28 126 -24  64 -35 106 -28 121  -1  67 -14 -25  92  37 -10\n",
      "  99  74]\n"
     ]
    }
   ],
   "source": [
    "(asymmetric_q, asymmetric_scale, asymmetric_zero) = asymmetric_quantization(params, 8)\n",
    "(symmetric_q, symmetric_scale) = symmetric_quantization(params, 8)\n",
    "\n",
    "print(f\"Original:\")\n",
    "print(np.round(params, 2))\n",
    "print(\"\")\n",
    "print(f\"Asymmetric scale: {asymmetric_scale}, zero: {asymmetric_zero}\")\n",
    "print(asymmetric_q)\n",
    "print(\"\")\n",
    "print(f\"Symmetric scale: {symmetric_scale}\")\n",
    "print(symmetric_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "[147.92 -49.33   0.   -32.32 146.92 -28.04  74.75 -40.69 122.9  -32.88\n",
      " 141.22  -1.68  78.55 -15.88 -28.64 106.9   42.73 -11.74 115.83  86.3 ]\n",
      "\n",
      "Dequantize Asymmetric:\n",
      "[147.74 -49.51   0.   -32.49 146.97 -27.85  75.03 -41.   122.99 -33.26\n",
      " 141.56  -1.55  78.9  -16.24 -28.62 106.75  42.54 -11.6  116.03  86.64]\n",
      "\n",
      "Dequantize Symmetric:\n",
      "[147.92 -48.92   0.   -32.61 146.76 -27.95  74.54 -40.77 123.46 -32.61\n",
      " 140.93  -1.16  78.04 -16.31 -29.12 107.15  43.09 -11.65 115.31  86.19]\n"
     ]
    }
   ],
   "source": [
    "# Dequantize the parameters back to 32 bits\n",
    "params_deq_asymmetric = asymmetric_dequantize(\n",
    "    asymmetric_q, asymmetric_scale, asymmetric_zero\n",
    ")\n",
    "params_deq_symmetric = symmetric_dequantize(symmetric_q, symmetric_scale)\n",
    "\n",
    "print(f\"Original:\")\n",
    "print(np.round(params, 2))\n",
    "print(\"\")\n",
    "print(f\"Dequantize Asymmetric:\")\n",
    "print(np.round(params_deq_asymmetric, 2))\n",
    "print(\"\")\n",
    "print(f\"Dequantize Symmetric:\")\n",
    "print(np.round(params_deq_symmetric, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Asymmetric error: 0.05\n",
      "   Symmetric error: 0.11\n"
     ]
    }
   ],
   "source": [
    "# Calculate the quantization error\n",
    "print(\n",
    "    f'{\"Asymmetric error: \":>20}{np.round(quantization_error(params, params_deq_asymmetric), 2)}'\n",
    ")\n",
    "print(\n",
    "    f'{\"Symmetric error: \":>20}{np.round(quantization_error(params, params_deq_symmetric), 2)}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the error is much bigger for symmetric quantization becasue original mertic is not symetric its between [-50, 150] becaseu orignal vetor is not symmettric\n",
    "\n",
    "\n",
    "# in symmetric quantization we are starting with biggest value in abolsute terms i.e. 127 which will mean that symmetric qunatization will map a arange that is between [-127, 127] but all in vector \"[147.92 -49.33   0.   -32.32 146.92 -28.04  74.75 -40.69 122.9  -32.88 141.22  -1.68  78.55 -15.88 -28.64 106.9   42.73 -11.74 115.83  86.3 ]\" there are no numbers between -127 and -49.3 so we are sacrificing alot of range for the numbers that donn't even exist leaving it unused resulting in all other numbers suffereing from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You make an excellent point. The reason the error is much bigger for symmetric quantization in this case is because the original floating-point values are not symmetrically distributed around zero.\n",
    "\n",
    "Let's break this down step-by-step:\n",
    "\n",
    "1. The original floating-point vector has values ranging from -49.33 to 147.92. This is an asymmetric range, skewed more towards positive values.\n",
    "\n",
    "2. In symmetric quantization, we map this range to [-127, 127]. The key issue is that the original minimum value of -49.33 is much closer to 0 than the original maximum of 147.92.\n",
    "\n",
    "3. This means that a large portion of the symmetric quantization range (-127 to -49.33) is essentially going unused, as there are no original values in that negative range.\n",
    "\n",
    "4. Meanwhile, the positive values from 0 to 147.92 have to be squeezed into the remaining positive range of 0 to 127. This results in a much coarser quantization of these positive values, leading to higher error.\n",
    "\n",
    "You're absolutely right that the asymmetric nature of the original vector is the root cause here. If the original range was more symmetric, like [-100, 100], then the symmetric quantization approach would be able to better utilize the available quantization levels and likely have lower overall error.\n",
    "\n",
    "But since the original data is skewed positive, the symmetric quantization approach is at a disadvantage - it has to reserve a large negative range that goes unused, while the positive values suffer from the coarse quantization.\n",
    "\n",
    "In contrast, asymmetric quantization can fully utilize the [0, 255] range to more precisely represent the positive-skewed original values, even if it loses some precision on the negative side.\n",
    "\n",
    "Thank you for highlighting this important nuance! Understanding the characteristics of the original data is crucial when choosing between symmetric and asymmetric quantization approaches. Your explanation really gets to the heart of why the error can be significantly higher in this specific case with symmetric quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great question! The reason why the error tends to be larger with symmetric quantization compared to asymmetric quantization has to do with how the quantization ranges are defined in each case.\n",
    "\n",
    "Let's explore this step-by-step:\n",
    "\n",
    "In asymmetric quantization, the range is [0, 2^n - 1], where n is the number of bits used (e.g. 8 bits gives a range of [0, 255]). This means the entire quantized range is dedicated to representing positive values.\n",
    "\n",
    "The key advantage here is that all the available quantization levels are focused on capturing the positive values in the original floating-point range. This allows for more precision when quantizing positive numbers.\n",
    "\n",
    "However, the downside is that negative values have to be mapped into this positive-only range. This inevitably leads to some loss of precision, as the negative values get \"squished\" into the lower end of the quantized range.\n",
    "\n",
    "In contrast, symmetric quantization uses a range of [-2^(n-1), 2^(n-1) - 1], where n is again the number of bits. For 8-bit quantization, this becomes [-127, 127].\n",
    "\n",
    "The benefit of the symmetric range is that it can more evenly represent both positive and negative values. Zero maps directly to zero, and the quantization levels are distributed symmetrically around zero.\n",
    "\n",
    "The tradeoff is that the available quantization levels have to be shared between the positive and negative sides of the range. This means there are fewer levels dedicated to representing any given positive or negative value, leading to higher quantization error compared to the asymmetric case.\n",
    "\n",
    "To illustrate with a simple example:\n",
    "\n",
    "Asymmetric 8-bit range: [0, 255]\n",
    "Symmetric 8-bit range: [-127, 127]\n",
    "\n",
    "Let's say we have a floating-point value of 200.0. In the asymmetric case, it can be quantized to 200 exactly. But in the symmetric case, it would have to be quantized to 127, resulting in a larger error.\n",
    "\n",
    "Similarly, a value of -50.0 can be quantized exactly in the symmetric case to -50, but would have to be mapped to a higher positive value in the asymmetric case, again leading to more error.\n",
    "\n",
    "So in summary, the symmetric quantization range has the advantage of better representing the sign of values, but the asymmetric range can be more precise for the positive or negative values individually. The appropriate choice depends on the specific use case and the importance of preserving the sign information versus minimizing overall quantization error.\n",
    "\n",
    "Does this help explain the tradeoffs between the two approaches? Let me know if you have any other questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error is typically larger for **symmetric quantization** compared to **asymmetric quantization** because of how the ranges and offsets are handled. Here's a detailed explanation:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Range Alignment**\n",
    "- **Asymmetric Quantization**:\n",
    "  - The floating-point range `[β, α]` is mapped to `[0, 2^n - 1]`.\n",
    "  - This allows the entire dynamic range of the data to be mapped directly into the quantized range, ensuring a **tighter fit** to the actual distribution of values.\n",
    "  - A zero offset (`z`) is introduced to shift the quantized range so that the zero value in the floating-point range is represented accurately.\n",
    "  \n",
    "- **Symmetric Quantization**:\n",
    "  - The floating-point range `[β, α]` is mapped to `[-2^(n-1), 2^(n-1) - 1]`.\n",
    "  - Since the range is symmetric around zero, **negative and positive values must have equal representation**, even if the actual data distribution is skewed or asymmetric.\n",
    "  - This often leaves part of the quantization range unused, resulting in **less precise mapping** for data that isn't symmetrically distributed.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Zero Point Handling**\n",
    "- **Asymmetric Quantization**:\n",
    "  - The zero point (`z`) ensures that the zero in the floating-point range is mapped exactly to a quantized value.\n",
    "  - This is especially important for operations like ReLU or padding, where zero has a specific role in computations.\n",
    "  - As a result, asymmetric quantization can represent the original values more accurately.\n",
    "\n",
    "- **Symmetric Quantization**:\n",
    "  - Zero is always mapped to the midpoint of the symmetric quantized range (e.g., `0` in `[-128, 127]` for 8-bit).\n",
    "  - If the data distribution has a large offset (e.g., mostly positive or mostly negative), this fixed zero point causes larger errors in representing the values.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Scaling Factor**\n",
    "- The **scaling factor (s)** is derived differently:\n",
    "  - **Asymmetric**: \\( s = \\frac{\\alpha - \\beta}{2^n - 1} \\)\n",
    "  - **Symmetric**: \\( s = \\frac{\\max(|\\beta|, |\\alpha|)}{2^{n-1} - 1} \\)\n",
    "  \n",
    "  - In symmetric quantization, the scaling factor is tied to the largest absolute value in the range, which can overestimate the range if the data is not symmetrically distributed. This results in **larger quantization steps**, increasing the error.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Distribution of Data**\n",
    "- Real-world data is often **asymmetric** (e.g., activations in neural networks tend to have a larger positive range than negative).\n",
    "  - **Asymmetric quantization** adjusts for this by using a zero point (`z`) and scaling the range accordingly.\n",
    "  - **Symmetric quantization**, however, assumes a symmetric distribution, leading to **more unused levels** in the quantized range and higher errors.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Quantization Error**\n",
    "- Quantization error arises when floating-point numbers are mapped to a discrete set of integers.\n",
    "  - **Asymmetric quantization** minimizes this error by aligning the quantized range closely to the actual data distribution.\n",
    "  - **Symmetric quantization** has larger errors because it cannot adapt to asymmetric distributions and often wastes part of the quantization range.\n",
    "\n",
    "---\n",
    "\n",
    "### Why Symmetric Quantization Is Still Used\n",
    "Despite its higher error, symmetric quantization is often used because:\n",
    "- It simplifies hardware implementations (no need to handle offsets).\n",
    "- It is computationally faster since zero always maps to zero.\n",
    "- It is sufficient for some use cases, especially when data is approximately symmetric or the slight increase in error is acceptable.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "The error is larger for symmetric quantization because:\n",
    "- It assumes the range is symmetric, leading to unused quantization levels for asymmetric data.\n",
    "- The scaling factor is less precise for data distributions that aren't symmetric.\n",
    "- Zero handling is less flexible, leading to more mismatches between the floating-point and quantized values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, quantization is typically performed on a trained neural network model, not on the raw training data.\n",
    "\n",
    "The main reasons for quantizing a trained model are:\n",
    "\n",
    "1. Reduced Memory Footprint: Neural networks can have millions or even billions of parameters. Quantizing these parameters from floating-point to lower precision integers (e.g. 8-bit) can significantly reduce the memory required to store the model, making it more efficient for deployment.\n",
    "\n",
    "2. Faster Inference: Integer-based computations are generally much faster than floating-point operations, especially on hardware that is optimized for integer math (like many mobile and embedded processors). Quantizing a model allows it to take advantage of these faster integer-based inference pipelines.\n",
    "\n",
    "3. Reduced Power Consumption: Integer operations require less power than floating-point, which is particularly important for running neural networks on battery-powered devices like smartphones or IoT sensors.\n",
    "\n",
    "The typical workflow is:\n",
    "\n",
    "1. Train the neural network model using full-precision floating-point parameters.\n",
    "2. Once the model is trained and performing well, apply a quantization technique to convert the weights and activations to a lower bit-width (e.g. 8-bit integers).\n",
    "3. Evaluate the quantized model's performance and make any necessary adjustments to the quantization parameters to strike the right balance between accuracy and efficiency.\n",
    "4. Deploy the quantized model for production use cases.\n",
    "\n",
    "Some common quantization techniques used in this process include dynamic quantization, static quantization, and post-training quantization. The specific approach depends on the model architecture, hardware constraints, and the acceptable tradeoffs between model accuracy and inference speed/memory.\n",
    "\n",
    "The key is that quantization happens after the model is fully trained, as a way to optimize the trained model for deployment, rather than impacting the training process itself. Let me know if you have any other questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPly Quantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's review for a linear layer, how quantiation will work?\n",
    "\n",
    "if we never quantized it before, we'll have \n",
    "Y_f = WX+ B\n",
    "\n",
    "\n",
    "we have W as fixed matrix as network is already trained, so we can quantize it using alpha and beta using symmetric or asymmetric quantization\n",
    "Bias can also be quantized as it is a fixed vector and we can calculate the alpha and beta of this vector and we can quantize it using 8-bits.\n",
    "X: X is input which depened on input data. one way is called dynamic quantization which mean for every input we receive, on the fle, we calculate the alpha and beta becaseu we have a vector and then we can quantize it on the fly. \n",
    "\n",
    "\n",
    "but when we quantize it Y_q where q mean quantized\n",
    "\n",
    "Y_q = WX+ B  # perform alll operations using integer arithmetic\n",
    "\n",
    "X: input/activations can be quantized on the fly using a process called dynamic quantization or with obervers\n",
    "W: \n",
    "B: Bias \n",
    "Y_q: After Wx+B becomes integer matrix multiplication than,  Y_q is an integer matrix but this matrix here is not the original floating point matrix of non-qunatized network. It's a quantized value, than how can we map it back to the original floating point number. we does this using Caliveration\n",
    "\n",
    "\n",
    "Now, after quantization, we can perform matrix multiplication which will become integer matrix multiplication \n",
    "\n",
    "\n",
    "\n",
    "after getting output Y_q, we dequantize it.  but how can we deuquantize it since we never learnt calulcated its scale(s) and zero(z) parameters??\n",
    "After Wx+B becomes integer matrix multiplication than,  Y_q is an integer matrix but this matrix here is not the original floating point matrix of non-qunatized network. It's a quantized value, than how can we map it back to the original floating point number. we does this using Caliveration\n",
    "we basically run inference on the model using a few inputs,  and observe typical output to calculate the scale(s) and the zero(z) parameters. This prcocess is called caliberation. It is part of Post training Quantization.\n",
    "\n",
    "\n",
    "![](quant_10.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# as both  and W are in quantizeed(int8)  but product of to 8-bit integer may exceede 8-bit. it can be 16-bit or more. for this reason we use accumulator register (ACC) here is 32-bit and this is also the reason  we quantize B in  vectWX+B as 32-bit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've provided a detailed and insightful explanation of how quantization works for a linear layer in a neural network. Let me summarize the key steps:\n",
    "\n",
    "1. Starting with the original floating-point linear layer computation:\n",
    "   Y_f = WX + B\n",
    "\n",
    "2. Quantizing the weights (W) and bias (B):\n",
    "   - The weights and bias can be quantized using either symmetric or asymmetric quantization.\n",
    "   - This involves determining the appropriate quantization range (α and β) and scaling factor (s) to map the floating-point values to integers.\n",
    "\n",
    "3. Quantizing the input (X):\n",
    "   - The input activations can be quantized on-the-fly using dynamic quantization.\n",
    "   - This computes the quantization parameters (scale and zero-point) for each input batch.\n",
    "\n",
    "4. Performing the quantized computation:\n",
    "   Y_q = (W_q × X_q) + B_q\n",
    "   - All the operations (multiplication and addition) are now performed using integer arithmetic.\n",
    "\n",
    "5. Dequantizing the output:\n",
    "   - After the quantized computation, we need to dequantize the output Y_q to recover the original floating-point values.\n",
    "   - However, since we didn't calculate the scale and zero-point parameters for the output during training, we need to perform a calibration step.\n",
    "   - This calibration involves running inference on a few inputs, observing the typical output, and then calculating the appropriate scale and zero-point.\n",
    "\n",
    "The key point you highlighted is that the Y_q matrix is not the same as the original floating-point output Y_f. It's a quantized version, and we need to use the calibration process to determine the appropriate dequantization parameters.\n",
    "\n",
    "This calibration step is crucial because it allows us to map the quantized integer output back to the original floating-point range, ensuring that the quantized model behaves the same as the original non-quantized model.\n",
    "\n",
    "Your explanation covers all the important aspects of this process, including the use of dynamic quantization for the input, the choice between symmetric and asymmetric quantization, and the need for calibration to handle the dequantization of the output. This level of detail is very helpful for understanding the complete quantization workflow for a linear layer.\n",
    "\n",
    "Please let me know if you have any other questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explain the quantization process for a linear layer in-depth, let’s break it down step by step, incorporating all aspects of the slide and your description.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **The Linear Layer Pre-Quantization**:\n",
    "   - The output of a linear layer is calculated as:\n",
    "     \\[\n",
    "     Y_f = XW + B\n",
    "     \\]\n",
    "     where:\n",
    "     - \\(X\\): Input (activations from the previous layer or input data).\n",
    "     - \\(W\\): Weight matrix (fixed after training).\n",
    "     - \\(B\\): Bias vector (also fixed after training).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Quantization Overview**:\n",
    "Quantization involves converting floating-point values into integers to reduce computation cost and memory usage. In this context, it includes:\n",
    "\n",
    "#### a. **Weight Quantization (\\(W\\))**:\n",
    "   - \\(W\\) is fixed (as the network is already trained).\n",
    "   - It can be quantized using symmetric or asymmetric quantization. \n",
    "     - **Symmetric Quantization**: Values are scaled by a factor (\\(\\alpha\\)), without a zero-point offset.\n",
    "     - **Asymmetric Quantization**: Uses a scale (\\(\\alpha\\)) and a zero-point (\\(\\beta\\)) to handle shifts in the value range.\n",
    "   - Example:\n",
    "     \\[\n",
    "     W_q = \\text{round}\\left(\\frac{W}{\\alpha}\\right)\n",
    "     \\]\n",
    "\n",
    "#### b. **Bias Quantization (\\(B\\))**:\n",
    "   - \\(B\\) is also fixed and can be quantized similarly using its own \\(\\alpha\\) and \\(\\beta\\), but it is often represented in 32-bit integer format for better precision due to its small size.\n",
    "\n",
    "#### c. **Input Quantization (\\(X\\))**:\n",
    "   - Unlike \\(W\\) and \\(B\\), \\(X\\) depends on the runtime input data, so its range may vary.\n",
    "   - To handle this, **dynamic quantization** is applied:\n",
    "     - For each input batch, the scale (\\(\\alpha\\)) and zero-point (\\(\\beta\\)) are computed dynamically \"on-the-fly\".\n",
    "     - Example:\n",
    "       \\[\n",
    "       X_q = \\text{round}\\left(\\frac{X - \\beta}{\\alpha}\\right)\n",
    "       \\]\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Performing Quantized Operations**:\n",
    "Once \\(W\\), \\(B\\), and \\(X\\) are quantized, the computation of the output \\(Y_q\\) is performed using integer arithmetic:\n",
    "\\[\n",
    "Y_q = X_qW_q + B_q\n",
    "\\]\n",
    "   - This step is highly efficient as it avoids floating-point operations and relies solely on integer matrix multiplication.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Dequantization (Mapping Back to Floating-Point)**:\n",
    "   - After obtaining \\(Y_q\\), the result must be mapped back to the floating-point domain for interpretation:\n",
    "     \\[\n",
    "     Y_f = \\alpha_y \\cdot (Y_q - \\beta_y)\n",
    "     \\]\n",
    "     - Here, \\(\\alpha_y\\) and \\(\\beta_y\\) are the scale and zero-point for \\(Y\\).\n",
    "   - However, since \\(Y_q\\) is derived through integer arithmetic, its scale and zero-point parameters are **not pre-learned** during training. Instead, these parameters must be **calibrated**.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Calibration Process**:\n",
    "   - Calibration is a step in **Post-Training Quantization** where:\n",
    "     - The model is run on a few representative inputs.\n",
    "     - The typical output values are observed to calculate:\n",
    "       - The scale (\\(\\alpha_y\\)) based on the range of outputs.\n",
    "       - The zero-point (\\(\\beta_y\\)) for alignment.\n",
    "   - This ensures that the quantized outputs can be properly dequantized to closely approximate the original floating-point outputs.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Key Insights**:\n",
    "   - **Dynamic Quantization** is used for inputs (\\(X\\)) since their range varies.\n",
    "   - **Fixed Quantization** is applied to weights (\\(W\\)) and biases (\\(B\\)) since they are constant after training.\n",
    "   - The computation in the quantized model remains efficient due to integer-only operations.\n",
    "   - Calibration ensures that the dequantized outputs match the behavior of the original floating-point model.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary Workflow:\n",
    "1. **Quantization**:\n",
    "   - Quantize \\(X\\), \\(W\\), and \\(B\\) into integers.\n",
    "2. **Integer Arithmetic**:\n",
    "   - Perform \\(Y_q = X_qW_q + B_q\\).\n",
    "3. **Calibration**:\n",
    "   - Calculate \\(\\alpha_y\\) and \\(\\beta_y\\) using representative data.\n",
    "4. **Dequantization**:\n",
    "   - Map \\(Y_q\\) back to \\(Y_f\\) using \\(\\alpha_y\\) and \\(\\beta_y\\).\n",
    "\n",
    "This approach achieves a balance between computational efficiency and maintaining accuracy. Let me know if you'd like further clarification or examples!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s the updated explanation with Markdown-friendly LaTeX equations for use in Jupyter Notebooks:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **The Linear Layer Pre-Quantization**:\n",
    "   - The output of a linear layer is calculated as:\n",
    "\n",
    "     \\[\n",
    "     Y_f = XW + B\n",
    "     \\]\n",
    "\n",
    "     where:\n",
    "     - \\(X\\): Input (activations from the previous layer or input data).\n",
    "     - \\(W\\): Weight matrix (fixed after training).\n",
    "     - \\(B\\): Bias vector (also fixed after training).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Quantization Overview**:\n",
    "Quantization involves converting floating-point values into integers to reduce computation cost and memory usage. In this context, it includes:\n",
    "\n",
    "#### a. **Weight Quantization (\\(W\\))**:\n",
    "   - \\(W\\) is fixed (as the network is already trained).\n",
    "   - It can be quantized using symmetric or asymmetric quantization:\n",
    "     - **Symmetric Quantization**: Values are scaled by a factor (\\(\\alpha\\)), without a zero-point offset.\n",
    "     - **Asymmetric Quantization**: Uses a scale (\\(\\alpha\\)) and a zero-point (\\(\\beta\\)) to handle shifts in the value range.\n",
    "   - Example:\n",
    "     \\[\n",
    "     W_q = \\text{round}\\left(\\frac{W}{\\alpha}\\right)\n",
    "     \\]\n",
    "\n",
    "#### b. **Bias Quantization (\\(B\\))**:\n",
    "   - \\(B\\) is also fixed and can be quantized similarly using its own \\(\\alpha\\) and \\(\\beta\\). However, it is often represented in 32-bit integer format for better precision due to its small size.\n",
    "\n",
    "#### c. **Input Quantization (\\(X\\))**:\n",
    "   - Unlike \\(W\\) and \\(B\\), \\(X\\) depends on the runtime input data, so its range may vary.\n",
    "   - To handle this, **dynamic quantization** is applied:\n",
    "     - For each input batch, the scale (\\(\\alpha\\)) and zero-point (\\(\\beta\\)) are computed dynamically \"on-the-fly\".\n",
    "     - Example:\n",
    "       \\[\n",
    "       X_q = \\text{round}\\left(\\frac{X - \\beta}{\\alpha}\\right)\n",
    "       \\]\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Performing Quantized Operations**:\n",
    "Once \\(W\\), \\(B\\), and \\(X\\) are quantized, the computation of the output \\(Y_q\\) is performed using integer arithmetic:\n",
    "\n",
    "\\[\n",
    "Y_q = X_qW_q + B_q\n",
    "\\]\n",
    "\n",
    "   - This step is highly efficient as it avoids floating-point operations and relies solely on integer matrix multiplication.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Dequantization (Mapping Back to Floating-Point)**:\n",
    "   - After obtaining \\(Y_q\\), the result must be mapped back to the floating-point domain for interpretation:\n",
    "     \\[\n",
    "     Y_f = \\alpha_y \\cdot (Y_q - \\beta_y)\n",
    "     \\]\n",
    "     - Here, \\(\\alpha_y\\) and \\(\\beta_y\\) are the scale and zero-point for \\(Y\\).\n",
    "   - Since \\(Y_q\\) is derived through integer arithmetic, its scale and zero-point parameters are **not pre-learned** during training. Instead, these parameters must be **calibrated**.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Calibration Process**:\n",
    "   - Calibration is a step in **Post-Training Quantization** where:\n",
    "     - The model is run on a few representative inputs.\n",
    "     - The typical output values are observed to calculate:\n",
    "       - The scale (\\(\\alpha_y\\)) based on the range of outputs.\n",
    "       - The zero-point (\\(\\beta_y\\)) for alignment.\n",
    "   - This ensures that the quantized outputs can be properly dequantized to closely approximate the original floating-point outputs.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Key Insights**:\n",
    "   - **Dynamic Quantization** is used for inputs (\\(X\\)) since their range varies.\n",
    "   - **Fixed Quantization** is applied to weights (\\(W\\)) and biases (\\(B\\)) since they are constant after training.\n",
    "   - The computation in the quantized model remains efficient due to integer-only operations.\n",
    "   - Calibration ensures that the dequantized outputs match the behavior of the original floating-point model.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary Workflow:\n",
    "1. **Quantization**:\n",
    "   - Quantize \\(X\\), \\(W\\), and \\(B\\) into integers.\n",
    "2. **Integer Arithmetic**:\n",
    "   - Perform \\(Y_q = X_qW_q + B_q\\).\n",
    "3. **Calibration**:\n",
    "   - Calculate \\(\\alpha_y\\) and \\(\\beta_y\\) using representative data.\n",
    "4. **Dequantization**:\n",
    "   - Map \\(Y_q\\) back to \\(Y_f\\) using \\(\\alpha_y\\) and \\(\\beta_y\\).\n",
    "\n",
    "---\n",
    "\n",
    "This explanation should render cleanly in a Markdown cell within Jupyter Notebook. Let me know if you need additional tweaks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how gpu peforms matrix multiplication\n",
    "when we calculate XW+B in a linear layer,  this list  in alist of dot products betwenn each row of the matrix X and each column of the matrix W summing the corresponding elements of the bias vector B.\n",
    "\n",
    "\n",
    "The GPU can accelerate this matrix multiplication by using multiply-accumulate (MAC) block, which is physical unit in the GPU that works as follows\n",
    "\n",
    "\n",
    "\n",
    "suppose each vector is made up of 4 values, we load the vectori.e. first rowof X matrix and  first column of W matrixthan we ocmpute correspoding product i.e. X11 with W11 , x12 with w21, X13 with W31 and X14 with W41 and than we summ all these values into a register called `Accumulator`\n",
    "\n",
    "\n",
    "as both  and W are in quantizeed(int8)  but product of to 8-bit integer may exceede 8-bit. it can be 16-bit or more. for this reason we use accumulator register (ACC) here is 32-bit and this is also the reason  we quantize B in  vectWX+B as 32-bit . Accumulator is 32-bit and is initialized already with bias elemnt.\n",
    "the GPU will perform the operation in parallel for every row and column of the inital matrices using many Multiply-Accumulate (MAC blocks). and this is how GPu acceleration work for matrix multiplication.\n",
    "\n",
    "\n",
    "![](quant_11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process described here focuses on how GPUs accelerate matrix multiplication, specifically when performing operations like \\( XW + B \\) in a linear layer, typically used in neural networks. Let's break this down step by step:\n",
    "\n",
    "### 1. **Matrix Multiplication in a Linear Layer**\n",
    "   - **\\( X \\)**: This is the input matrix, typically of size \\( N \\times M \\) (N samples, M features).\n",
    "   - **\\( W \\)**: This is the weight matrix, typically of size \\( M \\times K \\) (M features, K outputs).\n",
    "   - **\\( B \\)**: This is the bias vector, typically of size \\( 1 \\times K \\) (a bias for each output).\n",
    "   \n",
    "   The operation \\( XW + B \\) is essentially performing a matrix multiplication followed by adding a bias term to each resulting output. In detail, for each row \\( i \\) in \\( X \\) and each column \\( j \\) in \\( W \\), we compute a dot product and then add the corresponding bias \\( B_j \\).\n",
    "\n",
    "### 2. **Dot Product Calculation**\n",
    "   To compute the dot product between the first row of \\( X \\) and the first column of \\( W \\), we calculate:\n",
    "\n",
    "   \\[\n",
    "   \\text{Dot product} = X_{i1} \\cdot W_{1j} + X_{i2} \\cdot W_{2j} + X_{i3} \\cdot W_{3j} + X_{i4} \\cdot W_{4j}\n",
    "   \\]\n",
    "\n",
    "   Each term \\( X_{ik} \\cdot W_{kj} \\) is a multiplication between an element from the input matrix \\( X \\) and an element from the weight matrix \\( W \\), and these products are summed together to produce a single value.\n",
    "\n",
    "### 3. **GPU's Multiply-Accumulate (MAC) Block**\n",
    "   - A **MAC block** is a specialized unit within the GPU designed to perform **Multiply-Accumulate** operations. A MAC operation involves multiplying two numbers and then adding the result to an accumulator. It’s the core of many linear algebra operations like matrix multiplication.\n",
    "   \n",
    "   In the case of \\( XW + B \\), the MAC block does the following:\n",
    "   - **Multiply** each corresponding element of the row in \\( X \\) and the column in \\( W \\).\n",
    "   - **Accumulate** the results of these multiplications (i.e., sum them) into an accumulator register.\n",
    "\n",
    "   Suppose each vector (a row of \\( X \\) and a column of \\( W \\)) is made up of 4 values, the GPU will load the first row of \\( X \\) and the first column of \\( W \\), and perform the following operations:\n",
    "\n",
    "   \\[\n",
    "   \\text{ACC} = X_{11} \\cdot W_{11} + X_{12} \\cdot W_{21} + X_{13} \\cdot W_{31} + X_{14} \\cdot W_{41}\n",
    "   \\]\n",
    "\n",
    "   Here, **ACC** stands for **Accumulator**, a register where the sum of the products is stored. The key here is that each MAC block performs this computation in parallel for multiple rows and columns of \\( X \\) and \\( W \\).\n",
    "\n",
    "### 4. **Quantization and the Use of the Accumulator Register**\n",
    "   - The matrices \\( X \\) and \\( W \\) are often **quantized** to **int8** (8-bit integers) to save memory and computational resources. This means that the values in the matrices are represented using 8 bits instead of the usual 32-bit floating point numbers.\n",
    "   \n",
    "   - However, the result of multiplying two 8-bit integers can exceed the range of an 8-bit number. The product might require more than 8 bits (e.g., 16 bits or more). To handle this, GPUs use an **Accumulator register** (ACC), which is typically 32 bits.\n",
    "   \n",
    "   - This accumulator ensures that even though the intermediate results of the multiplications may overflow the 8-bit range, the sum of these products can still be safely stored and processed in a larger register (e.g., 32 bits). This is why the **bias** vector \\( B \\) is also quantized to 32-bit integers, to match the precision of the accumulator.\n",
    "\n",
    "### 5. **Parallelism with Multiple MAC Blocks**\n",
    "   - Modern GPUs have **thousands of cores**, and each core can execute a MAC block. This means that multiple rows and columns of \\( X \\) and \\( W \\) can be processed simultaneously in parallel. Each MAC block computes a part of the overall matrix multiplication.\n",
    "\n",
    "   - For example, while one block of threads is working on the first row of \\( X \\) and first column of \\( W \\), another block may be working on the second row of \\( X \\) and second column of \\( W \\), and so on. The result of each block's computations is accumulated and stored.\n",
    "\n",
    "### 6. **The Complete Parallelized Process**\n",
    "   - The entire operation \\( XW + B \\) is divided into many small parallel tasks, with each task being handled by different MAC blocks. The result of each task is accumulated in an accumulator register, and after all tasks are completed, the final output matrix is formed.\n",
    "   \n",
    "   - By using **multiple MAC blocks**, the GPU can perform matrix multiplication very efficiently. This parallelization leads to significant performance improvements compared to a CPU, which might only have a few cores.\n",
    "\n",
    "### 7. **Final Steps**\n",
    "   - After all the partial results are accumulated, the bias vector \\( B \\) is added to the accumulated sums. Since the bias vector is quantized to 32 bits, it can be directly added to the accumulator without overflow, as both are in the same 32-bit format.\n",
    "   \n",
    "   - The final output matrix, which is the result of \\( XW + B \\), is then produced, and the GPU can continue with the next layer or operation in the neural network.\n",
    "\n",
    "### Summary of GPU Acceleration for Matrix Multiplication:\n",
    "- **MAC blocks** are used to perform the multiply-accumulate operations in parallel for each element of the resulting matrix.\n",
    "- **Quantization** ensures that the input matrices are represented in a compact format (e.g., int8), while the accumulator (ACC) handles larger intermediate results (e.g., 32-bit).\n",
    "- **Parallelism** across many MAC blocks enables the GPU to process large matrices quickly, with each block handling a part of the computation.\n",
    "- This method is highly efficient, significantly speeding up operations like \\( XW + B \\) in neural networks, compared to sequential CPU-based methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure! Let's go over the explanation again without using LaTeX for the equations, just using text.\n",
    "\n",
    "### 1. **Matrix Multiplication in a Linear Layer**\n",
    "In a linear layer, you perform the operation `XW + B`, where:\n",
    "\n",
    "- **X** is the input matrix (of size N x M), where N is the number of samples and M is the number of features.\n",
    "- **W** is the weight matrix (of size M x K), where M is the number of features and K is the number of outputs.\n",
    "- **B** is the bias vector (of size 1 x K), which is added to each output.\n",
    "\n",
    "The operation `XW + B` is a matrix multiplication followed by adding the bias. For each row `i` of matrix `X` and each column `j` of matrix `W`, you compute a dot product and then add the corresponding bias value from vector `B`.\n",
    "\n",
    "### 2. **Dot Product Calculation**\n",
    "To compute the dot product between the first row of `X` and the first column of `W`, you perform the following calculations:\n",
    "\n",
    "- Multiply `X11` with `W11`\n",
    "- Multiply `X12` with `W21`\n",
    "- Multiply `X13` with `W31`\n",
    "- Multiply `X14` with `W41`\n",
    "\n",
    "Then, you sum these products to get a single value for that element of the resulting matrix.\n",
    "\n",
    "### 3. **GPU's Multiply-Accumulate (MAC) Block**\n",
    "A **Multiply-Accumulate (MAC) block** is a special hardware unit in the GPU that performs the core operations in matrix multiplication. It works as follows:\n",
    "\n",
    "- It **multiplies** the corresponding elements of a row from matrix `X` and a column from matrix `W`.\n",
    "- It **accumulates** (sums) these products into an accumulator register.\n",
    "\n",
    "For example, for the first row of `X` and the first column of `W`, the MAC block computes:\n",
    "\n",
    "- `ACC = X11 * W11 + X12 * W21 + X13 * W31 + X14 * W41`\n",
    "\n",
    "Here, `ACC` is the accumulator register, where the result of the multiplication is stored. The MAC block does this for many rows and columns in parallel.\n",
    "\n",
    "### 4. **Quantization and the Use of the Accumulator Register**\n",
    "- The values in matrices `X` and `W` are often **quantized** to **int8** (8-bit integers) to save memory and improve computation speed. This means each element in `X` and `W` is represented by an 8-bit integer.\n",
    "- However, when you multiply two 8-bit integers, the product might exceed the range of an 8-bit number (for example, it could be 16-bit or more). To handle this, the GPU uses an **Accumulator register (ACC)**, which is typically 32 bits.\n",
    "  \n",
    "The accumulator ensures that even though the intermediate products may exceed 8 bits, they can still be stored and processed in a larger register (e.g., 32 bits). This is why the **bias vector** `B` is also quantized to 32 bits, so it can be safely added to the accumulated result without overflow.\n",
    "\n",
    "### 5. **Parallelism with Multiple MAC Blocks**\n",
    "- Modern GPUs have thousands of processing cores, and each core can handle a **MAC block**. This means that multiple rows and columns of `X` and `W` can be processed simultaneously.\n",
    "- For example, one block of threads might work on the first row of `X` and the first column of `W`, while another block works on the second row of `X` and the second column of `W`, and so on.\n",
    "- This parallelism leads to significant speedups, as the computation for different parts of the matrix can happen at the same time.\n",
    "\n",
    "### 6. **The Complete Parallelized Process**\n",
    "- The entire matrix multiplication (`XW + B`) is broken down into many small tasks, with each task handled by a separate MAC block. Each block accumulates its results into an accumulator register.\n",
    "- Once all the tasks are completed, the final result is a matrix, which is the output of the matrix multiplication.\n",
    "- After the matrix multiplication is done, the bias vector `B` is added to the accumulated results. Since both the accumulator and the bias are in 32-bit format, they can be added directly without overflow.\n",
    "\n",
    "### 7. **Final Output**\n",
    "- After all the partial results are accumulated, the bias is added, and the final output matrix is formed.\n",
    "- This output matrix is the result of the linear transformation `XW + B`, which can then be passed to the next layer in a neural network or used in further computations.\n",
    "\n",
    "### Summary of GPU Acceleration for Matrix Multiplication:\n",
    "- **MAC blocks** perform the multiply-accumulate operations in parallel for each element of the resulting matrix.\n",
    "- **Quantization** ensures that matrices `X` and `W` are stored in a compact format (e.g., int8), while the accumulator (ACC) handles larger intermediate results (e.g., 32-bit).\n",
    "- **Parallelism** across many MAC blocks allows the GPU to perform matrix multiplication much faster than a CPU, as each block works on a different part of the computation simultaneously.\n",
    "- This process accelerates matrix multiplication and operations like `XW + B` in neural networks, making them much more efficient on the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do we choose alpha and beta parameter for symmetric or asymmetric qunatization?\n",
    "\n",
    "### **Any value outside the range will be clipped to the range**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### for assymmetric qunatization, we can choose the alpha and beta parameter as the beta being the smallest number and alpha being the largest \n",
    "#### for symmetric qunatization, we can choose the alpha parameter as the biggest value in absolute terms \n",
    "#### **BUT THIS IS NOT THE ONLY STRATEGY AND THEY HAVE PROS AND CONS**\n",
    "\n",
    "Let's look into these strategies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Min-Max strategy: To convert the whole range of values, we can set\n",
    "    alpha = max(v)\n",
    "    beta = min(v)\n",
    "    sensitive to outliers\n",
    "\n",
    "\n",
    "    imageine we have a vector which is more and less distributed around +50 and -50 but then we have an outlier 10000.0. this outlier will increase quantization error\n",
    "\n",
    "![](quant_12.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization is a technique used to reduce the precision of numerical values, typically to compress data or make computational processes more efficient. The alpha and beta parameters play a crucial role in defining the range and mapping of these quantized values.\n",
    "\n",
    "Let's explore the key strategies and considerations:\n",
    "\n",
    "## Symmetric vs Asymmetric Quantization\n",
    "\n",
    "### Asymmetric Quantization\n",
    "In asymmetric quantization:\n",
    "- Beta is set to the smallest number in the dataset\n",
    "- Alpha is set to the largest number in the dataset\n",
    "- This approach tries to capture the full range of values in the original data\n",
    "\n",
    "### Symmetric Quantization\n",
    "In symmetric quantization:\n",
    "- Alpha is chosen as the largest value in absolute terms\n",
    "- This means the quantization range is centered around zero\n",
    "- It ensures that positive and negative values are treated symmetrically\n",
    "\n",
    "## The Min-Max Strategy\n",
    "\n",
    "The most straightforward approach to choosing these parameters is the Min-Max strategy:\n",
    "- Alpha = max(values)\n",
    "- Beta = min(values)\n",
    "\n",
    "### Potential Issue: Outlier Sensitivity\n",
    "\n",
    "Consider this example to understand the challenge:\n",
    "Imagine you have a dataset primarily distributed around +50 and -50, but there's an extreme outlier at 10000.0. \n",
    "\n",
    "The consequences of this outlier are significant:\n",
    "1. It will dramatically expand the quantization range\n",
    "2. Most of your data will be clustered in a small portion of the quantized range\n",
    "3. ## This leads to increased quantization error for the majority of your data points\n",
    "\n",
    "\n",
    "## Practical Recommendation\n",
    "\n",
    "While the min-max strategy is simple, more robust approaches might include:\n",
    "- Clipping extreme outliers\n",
    "- Using percentile-based ranges\n",
    "- Employing adaptive quantization techniques that can dynamically adjust to data characteristics\n",
    "\n",
    "The key is to experiment and find the approach that works best for your specific use case.\n",
    "\n",
    "Would you like me to elaborate on any part of this explanation or provide a more concrete example of how these quantization strategies might be implemented?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This explanation discusses the process of selecting **alpha** and **beta** parameters for quantization, particularly in symmetric and asymmetric quantization schemes. Here's a breakdown of the content:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Purpose of Alpha and Beta in Quantization**\n",
    "In quantization, the **alpha** and **beta** parameters define the range of values to be mapped to a smaller set of discrete levels (e.g., converting floating-point values to integers). Any value outside this range is clipped to avoid exceeding the representable range.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Asymmetric vs. Symmetric Quantization**\n",
    "\n",
    "- **Asymmetric Quantization:**\n",
    "  - **Alpha**: The largest value in the data range.\n",
    "  - **Beta**: The smallest value in the data range.\n",
    "  - This approach accommodates ranges that aren't centered around zero and handles positive and negative values separately.\n",
    "\n",
    "- **Symmetric Quantization:**\n",
    "  - **Alpha**: The largest absolute value (positive or negative) in the range.\n",
    "  - This method assumes the range is symmetric around zero (e.g., `-alpha` to `+alpha`).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Min-Max Strategy**\n",
    "This strategy determines **alpha** and **beta** using the maximum and minimum values in the dataset:\n",
    "- \\( \\alpha = \\text{max}(v) \\)\n",
    "- \\( \\beta = \\text{min}(v) \\)\n",
    "\n",
    "#### Pros:\n",
    "- It covers the entire range of data.\n",
    "\n",
    "#### Cons:\n",
    "- **Sensitive to outliers**: \n",
    "  - If there are extreme values (e.g., an outlier like `10000.0` in a dataset centered around `-50` and `50`), the quantization range becomes unnecessarily large. This reduces precision for the majority of values and increases the quantization error for typical values.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Trade-offs and Other Strategies**\n",
    "- The Min-Max strategy is one approach, but it is not always optimal.\n",
    "- Other strategies (e.g., clipping or ignoring outliers, percentile-based methods) may improve precision by reducing sensitivity to outliers.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "Choosing alpha and beta depends on the data distribution and the quantization scheme (symmetric or asymmetric). While the Min-Max strategy is straightforward, its sensitivity to outliers makes it less effective for skewed or non-uniform data distributions. Alternative strategies should be considered based on the use case and dataset characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy # 2 to choose alpha, beta: use Percentile\n",
    "set the range to the percentile of the distribution of V, to reduce sensitivity to outliers. \n",
    "in this case only outlier siffer alot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### beta would be at like 1percentile and alpga be at 99 percentile reslting in quantization error reduced for all terms but outliers will suffer alot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](quant_16.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th Percentile: 20700.0\n",
      "5th Percentile: 23500.0\n",
      "25th Percentile: 37500.0\n",
      "50th Percentile: 55000.0\n",
      "75th Percentile: 200000.0\n",
      "95th Percentile: 824999.9999999998\n",
      "99th Percentile: 964999.9999999999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90000.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def demonstrate_percentiles(data):\n",
    "    # Calculate different percentiles\n",
    "    percentiles = [1, 5, 25, 50, 75, 95, 99]\n",
    "\n",
    "    for p in percentiles:\n",
    "        value = np.percentile(data, p)\n",
    "        print(f\"{p}th Percentile: {value}\")\n",
    "\n",
    "\n",
    "# Example dataset\n",
    "salaries = [20000, 30000, 40000, 50000, 60000, 100000, 500000, 1000000]\n",
    "demonstrate_percentiles(salaries)\n",
    "sum(salaries) * 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th Percentile: 37500.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "percentile_25 = np.percentile(salaries, 25)\n",
    "print(\"25th Percentile:\", percentile_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what is quantile\n",
    "\n",
    "\n",
    "The median is a quantile because it splits the data into equal sized groups(same number of data points). This is called 0.5(since it splits the data in half) quantile or the 50% quantile(since 50% of the data is above it and 50% below it). As the median value is 4.5,  so, value at 0.5 quantile is 4.5\n",
    "\n",
    "\n",
    "now add two mote lines, so that these three lines divide data into 4 equal sized groups. THese new lines are quantiles becasue they divide the data into equally sized groups.\n",
    "\n",
    "\n",
    "below one is called 0.25 or 25 % quantile becasue 25% of data points are less than it. The value at 2.5 quantile is 2.5.\n",
    "\n",
    "\n",
    "Above one is called 0.75 or 25 % quantile becasue 75% of data points are less than it. The value at 75% or 0.75 quantile is 7.3\n",
    "\n",
    "![](quant_13.png)\n",
    "\n",
    "So, in genral quantiles are just the lines that divide the data into equal sized groups. \n",
    "Percentiles are jsut the quantiles that divide the data into 100 equal sized groups.\n",
    "\n",
    "\n",
    "However in practice,  the terminilogy is much more flexible. \n",
    "eventhough below data isn't large enough to be divided into 100 groups. we still call the median or 50th quantile, 50th percentile \n",
    "![](quant_14.png)\n",
    "\n",
    "\n",
    "often terms percentilee and quantile are used when we divide them in equally sized groups\n",
    "\n",
    "\n",
    "## for 15 data points are\n",
    "\n",
    "1. as lowest elemnt has no value baloe it, it's called 0th percentilt/quanitle\n",
    "\n",
    "\n",
    "2. the data point above it 1/15 = 7% quantile or 7th percentile  # 1/15 because because there is one data point less than it. \n",
    "\n",
    "3. for 3rd lowest data point, 1/15 = 20% quantile or 20th percentile\n",
    "\n",
    "|[](quant_15.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentiles are statistical measures that divide a dataset into 100 equal parts, indicating the relative position of a data point within a dataset. Each percentile represents a value below which a certain percentage of the data falls. \n",
    "\n",
    "### Key Concepts\n",
    "1. **Percentile Rank**: The percentage of data points below a given value.\n",
    "2. **Percentile Value**: The data value corresponding to a given percentile rank.\n",
    "\n",
    "For example:\n",
    "- The 25th percentile (P25) is the value below which 25% of the data lies.\n",
    "- The 50th percentile (P50) is the **median**, where 50% of the data is below it.\n",
    "- The 75th percentile (P75) is the value below which 75% of the data lies.\n",
    "\n",
    "---\n",
    "\n",
    "### Steps to Calculate Percentiles\n",
    "1. Sort the data in ascending order.\n",
    "2. Determine the rank of the desired percentile using the formula:  \n",
    "   \\[\n",
    "   R = \\frac{P}{100} \\times (N + 1)\n",
    "   \\]\n",
    "   where \\(P\\) is the percentile (e.g., 25 for the 25th percentile) and \\(N\\) is the number of data points.\n",
    "3. Locate the position \\(R\\):\n",
    "   - If \\(R\\) is an integer, take the value at that position.\n",
    "   - If \\(R\\) is not an integer, interpolate between the two closest data points.\n",
    "\n",
    "---\n",
    "\n",
    "### Example 1: Small Dataset\n",
    "**Dataset**: [5, 7, 8, 12, 14, 18, 20]  \n",
    "**Find the 25th percentile (P25):**\n",
    "\n",
    "1. **Sort the data**: Already sorted.\n",
    "2. **Calculate \\(R\\)**:  \n",
    "   \\[\n",
    "   R = \\frac{25}{100} \\times (7 + 1) = 2\n",
    "   \\]\n",
    "   \\(R = 2\\), so the 25th percentile is the 2nd value: **7**.\n",
    "\n",
    "---\n",
    "\n",
    "### Example 2: Interpolation\n",
    "**Dataset**: [3, 8, 12, 16, 24]  \n",
    "**Find the 40th percentile (P40):**\n",
    "\n",
    "1. **Sort the data**: Already sorted.\n",
    "2. **Calculate \\(R\\)**:  \n",
    "   \\[\n",
    "   R = \\frac{40}{100} \\times (5 + 1) = 2.4\n",
    "   \\]\n",
    "   \\(R = 2.4\\), so the 40th percentile lies between the 2nd and 3rd values (8 and 12).\n",
    "\n",
    "3. **Interpolate**:  \n",
    "   \\[\n",
    "   \\text{P40} = 8 + 0.4 \\times (12 - 8) = 8 + 1.6 = 9.6\n",
    "   \\]\n",
    "\n",
    "The 40th percentile is **9.6**.\n",
    "\n",
    "---\n",
    "\n",
    "### Real-Life Example\n",
    "**Exam Scores**: Suppose a student scores 85 on a test, and the 85th percentile of the test scores is 90. This means the student scored higher than 85% of the test-takers but lower than the top 15%.\n",
    "\n",
    "---\n",
    "\n",
    "Percentiles are widely used in fields like:\n",
    "- **Education**: To compare student performance.\n",
    "- **Health**: To assess growth charts (e.g., a baby in the 90th percentile for height is taller than 90% of peers).\n",
    "- **Business**: To analyze income distributions or customer satisfaction scores.\n",
    "\n",
    "Let me know if you'd like a deeper dive into any aspect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantilzation compare min-max and percentiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 117.3    94.2    46.27 ...   83.61   75.96 1000.  ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Suppress scientific notation\n",
    "np.set_printoptions(suppress=True)\n",
    "params = np.random.uniform(low=-50, high=150, size=10000)\n",
    "\n",
    "\n",
    "# introduce an outlier\n",
    "params[-1] = 1000\n",
    "\n",
    "\n",
    "# round up each number to the seconda devomal place\n",
    "params = np.round(params, 2)\n",
    "\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 comapre min-max and percentile range selection strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "[ 117.3    94.2    46.27 ...   83.61   75.96 1000.  ]\n",
      "\n",
      "Asymmetric (min-max) scale: asymmetric_scale=4.117647058823529, zero: asymmetric_zero=12.0\n",
      "asymmetric_q=array([ 40,  35,  23, ...,  32,  30, 255], dtype=int32)\n",
      "\n",
      "\n",
      "\n",
      "Asymmetric (percentile) scale: asymmetric_scale_percentile=0.7844509999976425, zero: asymmetric_zero_percentile=64.0\n",
      "asymmetric_q_percentile=array([214, 184, 123, ..., 171, 161, 255], dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "def clamp(params_q: np.array, lower_bound: int, upper_bound: int):\n",
    "    params_q[params_q < lower_bound] = lower_bound\n",
    "    params_q[params_q > upper_bound] = upper_bound\n",
    "    return params_q\n",
    "\n",
    "\n",
    "def asymmetric_quantization(params: np.array, bits: int) -> tuple[np.array, float, int]:\n",
    "    # find the range of floating points\n",
    "    alpha = np.max(params)\n",
    "    beta = np.min(params)\n",
    "\n",
    "    scale = (alpha - beta) / (2**bits - 1)\n",
    "    zero = -1 * np.round(beta / scale)\n",
    "\n",
    "    lower_bound, upper_bound = 0, 2**bits - 1\n",
    "\n",
    "    quantized = clamp(\n",
    "        np.round((params / scale) + zero), lower_bound, upper_bound\n",
    "    ).astype(np.int32)\n",
    "    return quantized, scale, zero\n",
    "\n",
    "\n",
    "def asymmetric_quantization_percentile(\n",
    "    params: np.array, bits: int, percentile: float = 99.99\n",
    ") -> tuple[np.array, float, int]:\n",
    "    # find the range of floating points\n",
    "    alpha = np.percentile(params, percentile)\n",
    "    beta = np.percentile(params, 100 - percentile)\n",
    "\n",
    "    scale = (alpha - beta) / (2**bits - 1)\n",
    "    zero = -1 * np.round(beta / scale)\n",
    "\n",
    "    lower_bound, upper_bound = 0, 2**bits - 1\n",
    "\n",
    "    quantized = clamp(\n",
    "        np.round((params / scale) + zero), lower_bound, upper_bound\n",
    "    ).astype(np.int32)\n",
    "    return quantized, scale, zero\n",
    "\n",
    "\n",
    "def asymmetric_dequantize(params_q: np.array, scale: float, zero: int) -> np.array:\n",
    "    return (params_q - zero) * scale\n",
    "\n",
    "\n",
    "def quantization_error(params: np.array, params_q: np.array):\n",
    "    return np.mean((params - params_q) ** 2)\n",
    "\n",
    "\n",
    "(asymmetric_q, asymmetric_scale, asymmetric_zero) = asymmetric_quantization(\n",
    "    params, bits=8\n",
    ")\n",
    "(asymmetric_q_percentile, asymmetric_scale_percentile, asymmetric_zero_percentile) = (\n",
    "    asymmetric_quantization_percentile(params, bits=8)\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Original:\")\n",
    "print(np.round(params, 2))\n",
    "print(\"\")\n",
    "print(f\"Asymmetric (min-max) scale: {asymmetric_scale=}, zero: {asymmetric_zero=}\")\n",
    "print(f\"{asymmetric_q=}\")\n",
    "print(\"\\n\\n\")\n",
    "print(\n",
    "    f\"Asymmetric (percentile) scale: {asymmetric_scale_percentile=}, zero: {asymmetric_zero_percentile=}\"\n",
    ")\n",
    "print(f\"{asymmetric_q_percentile=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:\n",
      "[ 117.3    94.2    46.27 ...   83.61   75.96 1000.  ]\n",
      " \n",
      "Dequantized (min-max):\n",
      "[ 115.29   94.71   45.29 ...   82.35   74.12 1000.59]\n",
      " \n",
      "Dequantized (percentile): only outlier suffers\n",
      "[117.67  94.13  46.28 ...  83.94  76.09 149.83]\n"
     ]
    }
   ],
   "source": [
    "# dequantizate back to 32 bits\n",
    "params_deq_asymmetric = asymmetric_dequantize(\n",
    "    asymmetric_q, asymmetric_scale, asymmetric_zero\n",
    ")\n",
    "params_deq_asymmetric_percentile = asymmetric_dequantize(\n",
    "    asymmetric_q_percentile, asymmetric_scale_percentile, asymmetric_zero_percentile\n",
    ")\n",
    "\n",
    "\n",
    "print(\"original:\")\n",
    "print(np.round(params, 2))\n",
    "print(\" \")\n",
    "print(f\"Dequantized (min-max):\")\n",
    "print(np.round(params_deq_asymmetric, 2))\n",
    "print(\" \")\n",
    "print(f\"Dequantized (percentile): only outlier suffers\")\n",
    "print(np.round(params_deq_asymmetric_percentile, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Error (min-max) excluding outlier: 1.41\n",
      " \tError (precentile) excluding outlier: 0.05\n"
     ]
    }
   ],
   "source": [
    "# evaluate quantization without outlier\n",
    "print(\n",
    "    f'{\"Error (min-max) excluding outlier: \":>40}{np.round(quantization_error(params[:-1], params_deq_asymmetric[:-1]),2)}'\n",
    ")\n",
    "\n",
    "\n",
    "print(\n",
    "    f'{\"\\tError (precentile) excluding outlier: \":>40}{np.round(quantization_error(params[:-1], params_deq_asymmetric_percentile[:-1]),2)}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without outlier, all other terms are scaled correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Error (min-max) excluding outlier: 1.41\n",
      " \tError (precentile) excluding outlier: 72.33\n"
     ]
    }
   ],
   "source": [
    "# evaluate quantization without outlier\n",
    "print(\n",
    "    f'{\"Error (min-max) excluding outlier: \":>40}{np.round(quantization_error(params, params_deq_asymmetric),2)}'\n",
    ")\n",
    "\n",
    "\n",
    "print(\n",
    "    f'{\"\\tError (precentile) excluding outlier: \":>40}{np.round(quantization_error(params, params_deq_asymmetric_percentile),2)}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# strategy no.3 to find alpha and beta : Mean Squared Error\n",
    "we choose beta and alpha such that mse between origin(floating_point) and quantization is minimized\n",
    "it is done using grid search Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# strategy no.4 :Cross entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

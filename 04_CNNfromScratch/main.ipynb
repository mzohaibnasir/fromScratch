{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In CNN, we have two fundamental components, Input and Kernel.\n",
    "\n",
    "Input in CNN is typically an image or a multidimensional array representing data.\n",
    "Kernel is basically a small matrix of weights that perform convolution operations on input data.\n",
    "\n",
    "Pretty sure you've a thought here, What is convolution??\n",
    "It is a sliding window operation that combines two pieces of information, input and kernel.\n",
    "This is very fundamental operation in convolution. We perform the same operation between input & kernel that will further produce the output (another matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolution** and **cross-correlation** are both mathematical operations that combine two signals to produce a third signal. They are widely used in signal processing, image processing, machine learning, and other fields. While they are similar, they have key differences in their definitions and applications.\n",
    "\n",
    "### 1. **Definition**\n",
    "\n",
    "- **Convolution:**\n",
    "  - Convolution is an operation that combines two functions (or sequences) to produce a third function (or sequence). It is defined as the integral (or sum, in the discrete case) of the product of the two functions after one is flipped and shifted.\n",
    "  - **Mathematically (continuous):**\n",
    "    \\[\n",
    "    (f * g)(t) = \\int_{-\\infty}^{\\infty} f(\\tau) \\cdot g(t - \\tau) \\, d\\tau\n",
    "    \\]\n",
    "  - **Mathematically (discrete):**\n",
    "    \\[\n",
    "    (f * g)[n] = \\sum_{m=-\\infty}^{\\infty} f[m] \\cdot g[n - m]\n",
    "    \\]\n",
    "  - **Key Point:** The second function (or signal) is flipped (time-reversed) before shifting and multiplying.\n",
    "\n",
    "- **Cross-Correlation:**\n",
    "  - Cross-correlation measures the similarity between two functions (or sequences) as one is shifted relative to the other.\n",
    "  - **Mathematically (continuous):**\n",
    "    \\[\n",
    "    (f \\star g)(t) = \\int_{-\\infty}^{\\infty} f(\\tau) \\cdot g(t + \\tau) \\, d\\tau\n",
    "    \\]\n",
    "  - **Mathematically (discrete):**\n",
    "    \\[\n",
    "    (f \\star g)[n] = \\sum_{m=-\\infty}^{\\infty} f[m] \\cdot g[m + n]\n",
    "    \\]\n",
    "  - **Key Point:** The second function (or signal) is shifted but not flipped.\n",
    "\n",
    "### 2. **Key Differences**\n",
    "\n",
    "- **Flipping:** \n",
    "  - In convolution, the second signal is flipped (reversed in time) before being shifted. In cross-correlation, there is no flipping; the signal is only shifted.\n",
    "\n",
    "- **Order of Operations:**\n",
    "  - For convolution, the order of the two functions matters because flipping one signal can produce a different result.\n",
    "  - For cross-correlation, the order typically does not matter, as both signals are treated symmetrically (no flipping).\n",
    "\n",
    "- **Usage in Convolutional Neural Networks (CNNs):**\n",
    "  - In CNNs, what is often called \"convolution\" is technically cross-correlation. The filters are not flipped; they are directly shifted across the input to produce the output.\n",
    "\n",
    "- **Mathematical Relationship:**\n",
    "  - Convolution can be seen as cross-correlation with one of the signals flipped. Specifically:\n",
    "    \\[\n",
    "    (f * g)(t) = (f \\star \\tilde{g})(t)\n",
    "    \\]\n",
    "    Where \\( \\tilde{g}(t) = g(-t) \\) is the time-reversed version of \\(g(t)\\).\n",
    "\n",
    "### 3. **Applications**\n",
    "\n",
    "- **Convolution:**\n",
    "  - Widely used in signal processing (e.g., filtering, linear systems) where the flipping operation is important.\n",
    "  - Used in differential equation solving and system response analysis.\n",
    "  - In image processing, convolution is used for operations like blurring, sharpening, edge detection, etc.\n",
    "\n",
    "- **Cross-Correlation:**\n",
    "  - Used in signal alignment, time delay estimation, and pattern recognition.\n",
    "  - In image processing, cross-correlation is used for template matching, where a small template is matched with a larger image to find regions that are similar.\n",
    "\n",
    "### 4. **Example in Image Processing**\n",
    "\n",
    "- **Convolution:**\n",
    "  - Applying a filter (e.g., Gaussian blur) to an image involves convolving the image with the filter kernel, which is flipped before the operation.\n",
    "  \n",
    "- **Cross-Correlation:**\n",
    "  - Matching a small template (e.g., a patch of an image) to different locations in a larger image involves cross-correlating the template with the image to find where the template best fits (no flipping involved).\n",
    "\n",
    "### 5. **Summary**\n",
    "\n",
    "- **Convolution** involves flipping one of the functions before shifting and combining, which makes it sensitive to the specific order of operations. It is essential in systems analysis and filtering.\n",
    "  \n",
    "- **Cross-correlation** measures the similarity between two signals by shifting one without flipping, making it useful in tasks like signal alignment and pattern recognition.\n",
    "\n",
    "In practice, especially in machine learning and image processing, the term \"convolution\" is often used interchangeably with \"cross-correlation,\" even though they are technically different operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## so conv(I,K) = I * rot180(K) where * is cross corelation\n",
    "\n",
    "\n",
    "\n",
    "1. (star) - ⋆ - cross correlation\n",
    "2. (aestrick) -  * - convoution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, **What is Real Convolution?**\n",
    "\n",
    "It is basically performing same operation by rotating the kernel by 180 degrees.\n",
    "\n",
    "i.e. new kernel matrix will be (rotating the previous matrix by 180 deg)\n",
    "\n",
    "| 0 | -1 |\n",
    "| --- | --- |\n",
    "| 2 | 1 |\n",
    "\n",
    "We can formulate convolution as :\n",
    "\n",
    "> conv(I, K) = I  *  rot180(K) OR   I * K = I  * rot180(K), where I*K represent the Convolution!\n",
    "> \n",
    "\n",
    "So, the Convolution between I and K is cross-correlation between I and rotated version of K.\n",
    "\n",
    "There are multiple ways to perform cross-correlation and hence Convolution.\n",
    "\n",
    "What we’ve seen above is called VALID Cross-Correlation!  It is basically calculating product by placing the kernel directly onto Input and start sliding when it hits the border of input.\n",
    "\n",
    "There is another way we can perform this operation called, FULL Cross-Correlation.\n",
    "\n",
    "In this version, we calculate the product as soon as there is intersection between kernel and input matrix. Obviously, in this case size of output matrix is bigger than previous one. \n",
    "\n",
    "One instance is shown here,\n",
    "![alt text](Untitled.png)\n",
    "\n",
    "We end this module here. I assume you’ve got a basic understanding of convolution.\n",
    "\n",
    "Let’s move forward to module 2, it is very interesting ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolurion layer takes  in #dimensional block of data as input: W x H x C where C is depth\n",
    "# the layer has trainsable parameters amongst them kernels\n",
    "# each kernel has same depth as input mean it entends to full depth of input\n",
    "# each layer can have multiple kernels :  out_channels=8 mean 8 kernels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a convolutional layer within a neural network, the depth of the kernels (also known as filters) must match the depth of the input. \n",
    "\n",
    "Here's a more detailed explanation:\n",
    "\n",
    "### Input Depth\n",
    "- The depth of the input refers to the number of channels in the input data. For example, an RGB image has a depth of 3 because it has three channels: Red, Green, and Blue.\n",
    "\n",
    "### Kernel (Filter) Depth\n",
    "- The kernels in a convolutional layer also have a depth dimension. Each kernel is applied to all the channels of the input.\n",
    "\n",
    "### Matching Depth\n",
    "- For the convolution operation to be valid, the depth of the kernel must be the same as the depth of the input. This allows the kernel to interact with each channel of the input. If the input has 3 channels, the kernel must also have 3 channels.\n",
    "- Each channel of the kernel is convolved with the corresponding channel of the input, and the results are summed to produce a single value in the output feature map.\n",
    "\n",
    "### Example\n",
    "- If you have an input with a size of \\( 32 \\times 32 \\times 3 \\) (e.g., a color image), and you use a kernel of size \\( 5 \\times 5 \\), the kernel's size would actually be \\( 5 \\times 5 \\times 3 \\).\n",
    "- The convolution operation would produce an output of size \\( 28 \\times 28 \\times \\text{number of kernels} \\), where the number of kernels determines the number of output channels (also known as the depth of the output feature map).\n",
    "\n",
    "### Why This Requirement?\n",
    "- The convolution operation computes a weighted sum across the spatial dimensions (height and width) and across the depth (channels). For this to work, the kernel must have the same depth as the input so that it can properly combine information from all channels.\n",
    "\n",
    "### Summary\n",
    "- Yes, in a convolutional layer, the depth of the kernels must be the same as the depth of the input to allow for proper convolution across all channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
